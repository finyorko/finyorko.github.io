<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[network]]></title>
    <url>%2Fnetwork.html</url>
    <content type="text"><![CDATA[计算机网络-自顶向下方法第一章 计算机网络和因特网什么是因特网因特网描述方式有两种： 描述因特网具体构成：构成因特网的硬件和软件。 分布式应用提供服务的网络基础设施。 具体构成描述 主机（host）：与因特网相连的计算机等设备，也称为端系统（end system）。 端系统通过通信链路（communication link）和分组交换机（packet switch）连接到一起。 通信链路由不同类型的物理媒介组成，链路传播速度以bps度量。 分组：当一个端系统向另一个端系统发送时发送端系统将数据进行分段，并为每段加上首部字节，由此形成的信息包被称为分组，这些分组通过网络发送到目的端系统，在那里被装成初始数据。 分组交换机从它的一条入通信链路接收达到的分组，并从它的一条出通信链路转发该分组。当前最主要的两种分组交换机是路由器（router）和链路层交换机（link-layer switch）。 路径：从发送端到接收端，一个分组所经历的一系列通信链路和分组交换机称为通过该网络的路径。 端系统通过因特网服务提供商（Internet Service Provider，ISP）接入因特网。每个ISP是一个由多个分组交换机和多段通信链路组成的网络。不同的ISP为端系统提供了各种不同类型的网络接入（各种调制解调器、高速局域网接入和无线接入）。底层ISP通过高层ISP互联。每个ISP独立管理，运行IP协议。 端系统、分组交换机和其他因特网部件都要运行控制中接收和发送信息的一系列协议。TCP（Transmission Control Protocol，传输控制协议）和IP（Internet Protocol，网际协议）是因特网中最重要的两个协议。IP协议定义了在路由器和端系统中发送和接受的分组的格式。因特网主要协议统称为TCP/IP。 公共因特网：特定网络，因特网。网络的网络，即将网络连接起来的网络。 内联网：专用网络，这些网络内的主机不能与专用网络外部的主机交换信息（除非这些信息通过了所谓的防火墙，否则防火墙一般会限制报文进入和流出网络）。 服务描述分布式应用程序：涉及多台相互交换数据的端系统的程序。因特网应用程序运行在端系统上，即它们并不在网路核心的分组交换机上。 与因特网相连的端系统提供了一个应用编程接口（Application Programming Interface，API），API规定了运行在一个端系统上的软件请求因特网基础设施向另一个端系统上的特定目的地软件交付数据的方式。因特网是一种基础设施，新应用程序正在其上不断地被发明和设置。 什么是协议网路协议类似于人类协议，不过交换报文和采取行动的是某些设备的硬件或软件组件。因特网的所有活动，凡是涉及两个或多个通信的远程实体都受协议限制。 一个协议定义了两个或多个通信实体之间交换的报文格式和次序，以及在报文传输或接收或其他事件方面所采取的动作。 网络边缘端系统位于网络的边缘。端系统包括桌面计算机、服务器和移动计算机，还包括越来越多的其他类型设备。主机=端系统。主机又被分为客户机和服务器。 客户机和服务器程序客户程序运行在一个端系统上，它发出请求，并从运行在另一个端系统的服务器程序接收服务。客户机-服务器应用程序是分布式应用程序，客户机和服务器通过因特网护发报文以交互。 对等（P2P）应用程序：用户端程序起着客户机程序和服务器程序的双重作用。当它向一个对等方请求文件时，起着客户机的作用，向另一个对等方发送文件时起着服务器的作用。 接入网接入网：端系统连接到其边缘路由器的物理链路。边缘路由器是端系统到任何其他远程端系统的路径上第一个路由器。 住宅接入：拨号调制解调器。 公司接入：局域网（LAN）。 无线接入：无线局域网（wireless LAN），广域无线网（wide-area wireless access network）。 物理媒介导引型媒体：电波沿着固体媒体被传导： 双绞铜线 同轴电缆 光钎 非导引型媒体：电波在空气或外层空间中传播： 陆地无线电信道 卫星无线电信道 网络核心网路核心：因特网端系统的分组交换机和链路的网状结构。 电路交换和分组交换通过网络链路和交换机移动数据有两种基本方法：电路交换和分组交换。 电路交换中，沿着端系统通信路径，为端系统之间通信所提供的资源（缓存、链路传输速率）在通信会话期间会被预留。代表为电话网络。 分组交换网络中，这些资源不会被预留；会话的报文按需使用这些资源，这将导致可能不得不等待（排队）接入通信线路。代表为互联网。 电路交换网络中的多路复用链路中的网络要实现多路复用（使得一条线路可以有多条连接）有两种方式： 频分多路复用（Frequency-Division Multiplexing，FDM）：链路的频谱由跨越链路创建的所有连接所共享。特别是，该链路在连续期间为每条连接专用一个频段。在电话网络中，这个频段通常是4kHz，该频段被称为带宽。调频无线电台也使用FDM来共享88~108MHZ的频谱，其中为每一个电台被分配一个特定的频带。 时分多路复用（Time-Division Multiplexing，TDM）：时间被划分为固定区间的帧，每帧又被划分为固定数量的时隙。当网络跨越一条链路创建一条连接时，该网络在每个帧中为该连接指定一个时隙。这些时隙专门由该连接单独使用，一个时隙可用于传输该连接（在每个帧内）的数据。 电路交换缺点： 效率低，因为在静默期专用电路空闲，不能被其他进行中的连接所使用。 创建端到端电路和预留端到端带宽是很复杂的，需要复杂的信令软件来协调沿端到端路径的交换机的操作。 分组交换源主机将长报文划分为较小的数据块，并称之为分组。在源和目的之间，这些分组中的每个都通过通信链路的分组交换机（路由器和链路层交换机）传送。 存储转发机制（store-and-forward transmission）：交换机能够开始向输出链路传输该分组的第一个比特之前，必须接收到整个分组。因此，存储转发式分组交换机沿着该分组的路径在每条链路的输入端引入存储转发时延。 输出缓存（output buffer）（也称输出队列（output queue））：每个分组交换机有多条链路与之相连，对于每一条相连的链路，该分组交换机具有一个输出缓存，它用于存储路由器准备发往那条链路的分组。如果到达的分组需要跨越链路传输，但发现该链路忙于其他分组，该到达分组必须在输出缓存中等待。因此除了存储转发时延以外，分组还要承受输出缓存的排队时延（queue delay）。由于缓存区大小有限，因此一个到达的分组可能发现该缓存被等待传输的分组完全占满了，此时将出现分组丢失或丢包（packet lost）——可能是到达的该分组也可能是已经排队的分组之一将被丢弃。 分组交换的缺点：其端到端时延是变动的和不可预测的（主要是因为排队时延的变动和不可预测），因此不适合实时服务（如电话）。 分组交换的优点： 提供了比电路交换更好的带宽。 以电路交换更简单、更有效，实现成本更低。 统计多路复用：按需共享资源。 分组如何通过分组交换形成其通路在因特网中，每个通过该网络传输的分组在它的首部包含了其目的地地址，该地址是一种层次结构。当分组到达网络中的一台路由器时，该路由器检查分组的目的地地址的一部分，并向相邻路由器转发该分组。更特别的，每台路由器具有一个转发表，用于将目的地地址（或其中一部分）映射到输出链路。当分组到达一台路由器时，该路由器检查目的的地址，并用这个目的的地址搜索转发表，以找到合适的输出链路。然后路由器将该分组导向输出链路。 ISP和因特网主干道第一层ISP的特性： 直接与其他每个第一层ISP相连。 与大量的第二层ISP和其他客户网络相连。 覆盖国际区域。 第一层ISP也被称为因特网主干道。第二层ISP通常具有区域性或国家线覆盖规模，并且非常重要的只与少数第一层ISP相连接。第二层ISP需要引导流量通过它所连接的第一层ISP。第二层ISP被他所连接的第一层ISP称为客户，第一层ISP是第二层ISP的供应商。第二层之下是较低层ISP，层次结构的底层是接入ISP。当两个ISP直接相连时，他们被称为是对等的。 一个ISP网络中，某ISP与其他ISP的连接点被称为汇集点（Point of Presence，POP）。POP就是某ISP中的一台或多台路由器组，通过他们能够与其他ISP的路由器连接。 分组交换网中的时延、丢包和吞吐量时延概述分组从一个节点（主机或路由器）沿着路径到后继节点（主机或路由器）时，该节点在沿途的每个节点都经受了几种不同的时延。主要包括：节点处理时延（nodal processing delay）、排队时延（queuing delay）、传输时延（Transmission delay）和传播时延（propagation delay），这些时延总体累加起来是节点总时延（total delay）。 处理时延：检测分组首部和决定将该分组导向何处所需时间是处理时延的主要部分。一般处理时延较短（微秒级或者更低）。 排队时延：在队列中，当分组在链路上等待传输时，经受排队时延。队列很空且没有其他分组在传输时，排队时延是0。流量很大时，排队时延就会比较大。实际排队时延在毫秒到微秒级。 传输时延：仅当分组的整体全部导到时，才能传输我们的分组。L表示分组的比特长度，R bps表示从路由器A到路由器B的传输速率。传输时延是L/R，即将所以比特推（传输）向链路所需要的时间。实际传输时延在好秒到微妙级。 传播时延：从该链路的起点到路由器B传播所需要的时间是传播时延。比特以该链路的传播速率传播。其速率范围是210^8 ~ 310^8，传播时延等于路由器间的距离除以传播速度。 传输时延是路由器将分组推出所需要的时间，它是分组长度和链路传输速度的函数，而于传输距离无关。传播时延是一个比特从一台路由器向另一台路由器传播所需要的时间，是距离的函数，与分组长度或链路的传输速度无关。$$d_{nodal} = d_{proc}+d_{queue}+d_{trans}+d_{prop}$$ 排队时延和丢包节点时延最复杂的就是排队时延。其取决于流量到达该队列的速率、链路的传输速率和流量到达性质。 流量强度：令a表示分组到达的平均速率（a的单位是每秒分组，即packet/s）；R是传输速率，即比特从队列中推出的速率，单位是bps；为了简化起见，假定所以分组是由L比特组成的，则比特到达队列的平均速率是La bps。此时La/R被称为流量强度。 如果流量强度大于1，则比特到达队列的平均速度超过该队列传输出去的速度，此时队列的增加趋于无界，且排队时延无限大。当流量强度小于1时，到达流量的性质影响排队时延，如果分组以突发形式到达而不是周期形式到达，则可能有很大的平均排队时延。 丢包的数量随着流量强度的增加而增加。 端到端时延Traceroute程序：其能够在任何因特网主机上运行。当用户指定一个目的主机名字时，源主机中的该程序朝着该目的地发送多个特殊的分组（默认30个）。当这些分组向着目的地传送时，他们通过一系列路由器。当路由器接收到这些特殊分组时，它向源回送一个短报文，该报文包括路由器名字和地址。 处理流程：假定在源与目的地之间有N-1台路由器，则源将向网络发送N个特殊的分组，其中每个分组地址指向最终的目的地。这N个特殊分组标识从1到N，第一个分组标识为1，最后的分组标识为N。当第n台路由器接收到第n个标识为n的分组时，该路由器不是向目的地转发，而是向源回送一个报文。当目的的主机接到第N个分组时，也会向源返回一个报文。该源记录了从它发送一个分组到它接收到对应返回报文所经受时间，也记录了返回该报文的路由器（或目的地主机）的名字和地址。以这种方式，源能够重建分组从源到目的地所采用的路由，并且能够获得到所有中间路由器的往返时延。Traceroute实际上对上述实验重复了三次，因此实际发送了3*N组数据。 traceroute输出有6列：第一列是前面描述的n值，即沿着路径上的路由器号码；第二列是路由器名字；第三列是路由器地址；最后三列是3次往返时延。如果源从任何给定的路由器接收少于三条报文（由于网络中丢包），则traceroute在该路由器号码后面放一个星号，并向那台路由器报告少于3次往返时间。例如： 1234567891011121314151617181920212223242526272829303132$ traceroute www.yinkuiwang.cntraceroute to www.yinkuiwang.cn (185.199.110.153), 30 hops max, 60 byte packets 1 _gateway (10.136.0.1) 2.857 ms 3.053 ms 3.157 ms 2 202.113.18.229 (202.113.18.229) 3.281 ms 3.390 ms 3.742 ms 3 202.113.18.102 (202.113.18.102) 2.748 ms 3.839 ms 3.804 ms 4 111.33.78.1 (111.33.78.1) 4.961 ms 4.929 ms 5.200 ms 5 117.131.131.13 (117.131.131.13) 4.239 ms 4.442 ms 117.131.131.9 (117.131.131.9) 4.587 ms 6 221.183.38.49 (221.183.38.49) 5.822 ms 2.652 ms 2.647 ms 7 * 221.183.8.150 (221.183.8.150) 15.551 ms * 8 221.176.21.146 (221.176.21.146) 10.094 ms 10.091 ms 221.176.21.186 (221.176.21.186) 25.060 ms 9 221.183.46.253 (221.183.46.253) 16.063 ms 16.178 ms *10 221.183.30.234 (221.183.30.234) 207.610 ms 221.183.30.230 (221.183.30.230) 198.938 ms 221.183.30.246 (221.183.30.246) 195.548 ms11 223.120.6.97 (223.120.6.97) 252.070 ms * 223.118.12.5 (223.118.12.5) 218.268 ms12 223.120.6.113 (223.120.6.113) 239.274 ms 223.120.6.26 (223.120.6.26) 237.843 ms *13 * * *14 lag-10.ear1.Madrid2.Level3.net (4.68.111.45) 238.222 ms 236.624 ms 243.475 ms15 * * *16 * * *17 * * *18 * * *19 * * *20 * * *21 * * *22 * * *23 * * *24 * * *25 * * *26 * * *27 * * *28 * * *29 * * *30 * * * 由于排队时延随时间变化，所以分组n发送到路由器n的往返时延可能大于分组n+1发送到路由器n+1的往返时延。比如上面2和3的第一个时延。 计算机网络中的吞吐量瞬时吞吐量：从主机A向主机B传输一个大文件，B接收该文件的速率（单位bps）。 平均吞吐量：该文件由F比特组成，而主机B接收到所以F比特使用了T秒，则平均吞吐量为F/T bps。 从端系统到另一个端系统的吞吐量取决于拼劲链路，即路径中链路速度最慢的那个链路。 协议层次和它们的服务模型分层的体系结构网络设计者以分层的方式组织协议以及实现这些协议的网络硬件和软件。每个协议属于一层，某层向其上一层提供服务（service），即所谓的层的服务模型，某层通过在该层中执行某些动作或者使用其直接下层的服务来提供它的服务。 一个协议层能够通过软件和硬件或两者的结合实现。应用层在端系统的软件中实现，运输层也是这样。物理层和链路层负责处理跨特定链路的通信，通常在与给定链路相关的网络接口卡中实现。网络层经常是软件和硬件的结合。层n协议的不同部分常常位于这些网络组件的各部分。 协议分层的优点是：概念化结构化；模块化使得更新系统组件更加容易。 缺点：某层可能重复其较低层的功能；某层的功能可能需要仅在其他某层才出现的信息，这违反了层次分离的目标。 应用层 应用层是网络应用程序及其应用层协议存留的地方。应用层包含很多协议：HTTP（web文档请求和传送）；SMTP（电子邮件报文传输）；FTP（两个端系统之间文件传送）。还有某些网络功能，如DNS（域名系统）将网址转换为32比特网络地址。 应用层协议分别在多个端系统中，一个端系统中的应用程序使用协议与另一个端系统中的应用程序交换信息分组。位于应用层的信息分组称为报文（message）。 运输层 运输层提供了在应用程序端点之间传送应用层报文的服务。因特网存在两个运输协议TCP和UDP。TCP向它的应用程序提供了面向连接的服务，这种服务包括了应用层报文向目的地的确保确保传递和流量控制。TCP将长报文换分为短报文，并提供阻塞控制机制，当网络阻塞时，源抑制其传输速率。UDP协议提供无连接服务，其不提供不必要的服务，不提供可靠性，没有流量控制，也没有拥塞控制。运输层分组称为报文段（segment）。 网络层 网络层负责将数据报的网络层分组从一台主机移动到另一台主机源主机的因特网运输层协议向网络层递交运输层报文段和目的地地址。 因特网网络层包括著名的IP协议，该协议定义了数据中各个字段以及端系统和路由器如何作用于这些字段。所有网络层的因特网组件都必须运行IP协议。因特网的网络层也包含决定路由的选路协议。IP是将因特网连接在一起的粘合剂。 链路层 为了将分组从一个节点移动到路径的下一个节点，网络层必须使用链路层服务。在每一个节点，网络层将数据报下传给链路层，链路层沿着路径将数据传输给下一个节点，在下一个节点，链路层将数据报上传给网络层。 链路层提供的服务取决于应用于该链路的特定链路协议。主要有以太网、WIFI和点对点协议（PPP）。链路层分组称为帧。 物理层 链路层是将帧从一个网路元素移动到临近的网络元素。物理层任务是将该帧中的一个一个比特从一个节点移动到下一个节点。 ISO模型 ISO多加了两层，表示层和会话层。表示层是使通信的应用程序能够解释交换数据的含义，提供的服务包括数据压缩、数据加密以及数据描述。会话层提供了数据交换的定界和同步功能，包括建立检查点和恢复方案的方法。 报文、报文段、数据报和帧 上图显示了一条物理路径：数据从发送端系统的协议向下，上下中间的链路层交换机和路由器的协议栈，进而向上到达接收端系统的协议栈。 上图也说明了封装这一重要概念。在发送主机，应用层报文（M）被传送给运输层；运输层收取报文并附上附加信息（运输层首部Ht），该首部将被被接收的运输层使用。应用层报文和运输层首部信息共同构成了运输层报文段。运输层报文段因此封装了应用层报文。运输层则向网络层传递该报文段，网络层增加了如源和目的地端系统地址等网络首部信息形成网络层数据报。该数据报接下来被传递给链路层，链路层添加自己的链路首部信息并创建链路帧。于是，在每一层，分组具有两种类型的字段：首部字段和有效荷载字段，有效荷载字段来自于上一层。 攻击威胁下的网络坏家伙能够经因特网将恶意软件放入你的计算机僵尸网络：被恶意软件感染的设备，受害主机还能征招网络上数以千计的类似受害设备。 自我复制：一旦恶意软件感染了一台主机，就会从那台主机进入到更多主机。 病毒：一种需要某种形式的用户交互来感染用户设备的恶意软件。 特洛伊木马：隐藏在有用软件的恶意软件。 坏家伙能够攻击服务器和网络基础设施拒绝服务攻击（Denial-of-Service，DoS）是一种宽泛的安全性攻击，其使得合法用户不能使用网络、主机或其他基础设施部分。DoS攻击主要分为三种： 弱点攻击：向目标主机上运行的易受攻击的应用程序或操作系统发送制作精细的报文。如果多个分组以适当的顺序发送给一个易受攻击的应用程序或操作系统，该服务可能停止运行，甚至导致主机奔溃。 带宽泛洪：攻击者向目标主机发送大量的分组，导致目标的接入链路变得拥塞，从而使合法的分组无法到达服务器。 连接泛洪：攻击者在目标主机中创建大量的半开或全开TCP连接。目标主机因这些伪造的连接而显然困境，从而停止合法的连接。 对于带宽泛洪，单一源可能无法产生足够大的流量来危害服务器，同时单一攻击可能被上游路由器检测出该攻击并在该流量靠近服务器前就将其阻挡下来。分布式DoS（distributed Dos，DDos）中，攻击者控制多个源并让每个源向目标猛烈发送流量。 坏家伙能嗅探分组在无线传输设备的附加放置一台被动接收机，该接收机就能得到传输的每个分组的拷贝。记录每个流经分组拷贝的被动接收机被称为分组嗅探器。 嗅探器也可用于有线环境，如在有线广播中。嗅探器是被动接收设备，很难被发现，因此最后的防御手段是密码学方式。 坏家伙能够伪装成你信任的人生成具有任意原地址、分组内容和目的地址的分组，然后将这个人工制作的分组传输到因特网中是十分容易的。将虚假源地址的分组注入因特网的能力被称为IP哄骗（IP spoofing），这只是一个用户能够冒充另一个用户的多种形式之一。 为解决这个问题，需要采用端点鉴别（end-point authentication）机制，即确保报文源自我们认为应该来自的地方的机制。 坏家伙能够修改或删除报文坏家伙插入到两个通信实体之间，危及发送信息的完整性。 第二章 应用层应用层协议原理网络应用程序体系结构从应用程序研发者角度来看，网络体系结构是固定的，并为应用程序提供了特定的服务集合。现代网络应用程序所使用的两种主流体系结构：客户机/服务器体系结构或对等（P2P）体系结构。 在客户机/服务器体系结构中，有一个总是打开的主机被称为服务器，它服务来自许多客户机的主机请求。典型例子为Web应用程序。在这个结构中，客户机之间不之间相互通信，服务器有固定的、周知的地址，称为IP地址。 在P2P体系结构中，对总是打开的基础设施服务器有最小的（或者没有）依赖。任意间断连接的主机对——称为对等方，直接通信。P2P协议最突出的特性之一是它的自扩展性。 某些应用具有混合的体系结构，由客户机/服务器和P2P元素结合而成，往往服务器场用于跟踪用户的IP地址，但用户到用户的报文在用户主机之间直接发送。 进程通信网络应用程序是由成对的进程组成，这些进程通过网络相互发送报文。在给定的一对进程中之间的通信会话中，发起通信（即在该回话开始时与其他进程联系）的进程被标示为客户机，在会话开始时等待联系的进程是服务器。 进程通过套接字软件接口在网络上发送和接收报文。应用程序开发者可以控制套接字在应用层端的所以东西，但是对套接字的运输层端几乎没有控制。应用程序开发者对于应用层端的控制仅限于： 选择运输协议。 设定部分运输层参数，如最大缓存、最大报文长度等。 可供应用程序使用的传输协议可靠传输数据 第一章讨论过，分组可能会存在丢包，部分程序要保证数据完整性。如果一个协议提供了确保数据交付服务，就提供了可靠数据传输。运输层协议能够潜在的向应用程序提供的一个重要服务是进程到进程的可靠数据传输。此时，发送进程只要将数据传递给套接字，就可以相信数据被无差错到达接收进程。 部分程序运行存在部分丢包，即为容忍丢失的应用。 吞吐量 具有吞吐量要求的应用程序，被称为带宽敏感应用。弹性应用根据需要充分利用可供使用的吞吐量。 定时 部分应用为了有效性而对数据交付有严格的时间限制。 安全性 运输层协议能够为应用程序提供一种或多种安全性服务。 因特网的运输服务因特网（TCP/IP网络）上的应用使用了两个运输层协议：UDP和TCP。创建应用时首先要决定使用哪一个。 TCP服务TCP服务模型包括面向连接服务和可靠数据传输服务。 （1）面向连接服务：使用TCP协议时，在应用层数据报文开始流动之前，其客户机程序和服务器程序之间互相交换运输层控制信息。即为握手过程，此过程提示客户机和服务器之间建立了一个TCP连接。这个连接是双全工的，即两个进程可以同时进行报文的收发。当应用程序结束报文发送时，必须拆除该连接。 （2）可靠数据服务：进程通信的进程依靠TCP协议，无差错、按适当顺序交付发送的数据。没有子节的丢失和冗余。 （3）拥塞控制机制：这种机制不为通信进程带来直接好处。但能够为因特网带来整体好处。当发送方和接收方之间网络发生拥塞时，TCP协议的拥塞控制机制会抑制发送进程。此机制对带宽敏感的应用有害。 UDP服务UDP是一种不提供不必要服务的轻量级运输层协议，它仅提供最小服务。UDP是无连接的，因此两个进程之间没有握手的过程。UDP协议提供的是不可靠数据传输服务，即不保证一定能收到，也不保证顺序。 UDP没有拥塞控制机制。 因特网运输层不提供的服务目前因特网不提供吞吐量和定时的保证。下面列出了一些流行因特网应用使用的运输层协议： 应用 应用层协议 运输层协议 电子邮件 SMTP TCP 远程终端访问 Telnet TCP Web HTTP TCP 文件传输 FTP TCP 流媒体 HTTP、RTP TCP或UDP 因特网电话 SIP、RTP或专用（如Skype） 通常用UDP 进程寻址为了识别接收进程，需要定义两种信息：（1）该主机的名称或地址，（2）用来指定目的主机上接收进程的标识。 在因特网中，主机使用IP地址进行标识（第四章深入探究）。此时，我们只要知道IP地址是用来唯一标识主机的32比特数就足够了。 发送程序也必须识别运行在主机上的接收进程，目的地端口服务于此目的。已经给流行的应用程序分配了特定的端口号。如Web是80号。这是为了特定应用程序开发时大家统一，可以直接进行通信。 应用层协议应用层协议定义了运行在不同端系统上的应用程序进程如何相互传递报文。其主要定义了如下内容： 交换的报文类型，如请求报文和响应报文。 各种类型的语法，如报文中的各个字段及其详细描述。 字段的语义，即包含在字段中的信息含义。 进程何时、如何发送报文以及对报文响应的规则。 网络应用和应用层协议的区别：应用层协议只是网络应用的一部分，只是定义了应用程序之间沟通的协议。 Web应用与HTTP协议HTTP概况Web应用层协议是超文本传输协议（HyperText Transfer Protocol，HTTP）。HTTP协议有两部分程序实现：客户机程序和服务器程序，它们运行在不同的端系统中，通过交换HTTP报文进行会话。HTTP定义了这些报文的格式以及客户机和服务器是如何进行报文交换的。 Web页面（Web page，也叫文档）是由对象组成的。对象简单来说就是文件，如HTML文件，JPEG图片文件、Java小程序或视频文件，这些文件可以通过一个URL地址寻址。多数Web页面含义一个基本的HTML文件以及几个引用对象。如一个Web页面包括一个HTML文件和5个JPEG图形文件，那这个Web页面有六个对象。每个URL地址由两部分组成：存放对象的服务器主机名和对象的路径名。如：http://www.someschool.edu/someDepartment/picture.gif中的www.someschool.edu即为主机名，/someDepartment/picture.gif即为路径。 HTTP定义了Web客户端如何向Web服务器请求Web页面，以及服务器如何将Web页面传送给客户端。 HTTP使用TCP作为支撑运输层协议。HTTP客户机发送一个与服务器的TCP连接，建立连接后，客户端和服务器就可以进行通信了。 服务器向客户机发送请求的文件时，并不存储任何关于该客户机的状态信息。由于HTTP服务器不存储关于客户机状态的信息，使用说HTTP是一个无状态协议。 非持久连接和持久连接当客户机/服务器的交互运行于TCP之上时，应用程序开发者需要确定每个请求/响应是经过单独的TCP连接发送还是所以请求及响应经相同的TCP连接发送。前者称为非持久连接，后者称为持久连接。HTTP两者都支持，默认使用持久连接。非持久连接每个TCP连接只传输一个请求报文和一个响应报文。 往返时间（Round-Trip Time，RTT）：即一个小分组从客户机到服务器再回到客户机所花费的时间。一个RTT等于三次握手中前两个部分所消耗的时间。 非持久连接缺点： 必须为每一个请求的对象建立和维护一个全新的连接，对于每个这样的连接，在客户机和服务器都要分配TCP的缓冲区和变量，这给服务器带来严重负载。 每个对象的传输时延为两个RTT（三次握手前两部分为一个，第三次握手（确认）同时发送请求，因此只有两个RTT）。 HTTP报文格式HTTP有两种报文：请求报文和响应报文 请求报文下面是一个典型的请求报文： 12345GET /somedir/page.html HTTP/1.1Host: www.someschool.eduConnection: closeUser-agent: Mozilla/4.0Accept-language: fr HTTP请求第一行叫做请求行，其后继的行叫做首部行。请求行有三个字段：方法字段、URL字段和HTTP协议版本字段。方法字段可以取值GET、POST、HEAD、PUT和DELETE。 首部行Host:www.someschool.edu定义了目标所在主机。Connection:close首部行，告诉服务器不希望麻烦的使用持久连接，要求服务器发送完请求的对象后就关闭连接。User-agent:首部行用来定义用户代理，即向服务器发送请求的浏览器类型。Accept-language表示用户想要得到该对象的语法版本。Accept-language:是可选内容协商首部之一。 下图展示了请求报文的通用格式： 在首部行和附加回车换行后有一个实体主体（Entity body）。使用GET方法时实体主体为空，使用POST方法时才使用。使用POST方法的报文中，用户依然可以请求一个Web页面，但Web返回的内容依赖于POST方法的报文中。当方法字段值为POST时，实体主题中包含的就是用户在表单字段中输入的内容。 HTML表单经常使用GET将输入数据（在表单字段中）传送到正确的URL。如，一个表单使用GET方式，它有两个字段，分别填写的是monkey和bananas，那么得到的URL结构为：www.somesite.com/animalsearch?monkey&amp;bananas。 HEAD方法类似于GET。当服务器收到使用HEAD方法的请求时，会用一个HTTP的报文进行响应，但是并不返回请求对象（用于调试）。PUT方法用来向Web服务器上传对象。DELETE方法，用来删除Web服务器上的对象。 HTTP响应报文典型响应报文格式： 123456789HTTP/1.1 200 OKConnection: closeDate: THu,03 Jul 2003 12:00:15 GMTServer: Apache/1.3.0(Unix)Last-Modified: Sun,6 May 2007 09:23:24 GMTConnect-Length: 6821Content-Type: text/html(data data ...) 响应分三部分：一个初始状态行，首部行和实体主体。实体主体是报文的主体，它包含一个所请求对象本身。状态行有三个字段：协议版本、状态码和相应状态信息。 Connection:close首部行告诉客户机发送完毕后关闭连接。Date首部行指示服务器产生并发送该响应报文的日期和时间。时间是指服务器从它的文件系统中检索到该对象，插入到响应报文的时间。Server报文指示服务器类型，类似与请求报文中User-agent首部行。Last_Modified首部行指示了对象穿件或最后修改的日期和时间。Content_Length表明被发送对象的字节数。Content_Type指示了实体主体原本的类型（HTML还是图片等）。 下图展示了响应报文的通用格式： 一些常见的状态码： 200 OK 请求成功 301 Moved Permanently 请求的对象已经被永久转移了，新的URL定义在响应报文的Location：首部行中。客户机软件自动用新的URL获取该对象。 400 Bad REquest 一个通过错误代码，指示请求不能被服务器理解。 404 NOT Found 请求的文档不在服务器上。 505 HTTP version not supported 服务器不支持请求报文使用的HTTP协议版本。 可以使用telnet来观察真实的HTTP响应报文。使用telnet site 80即建立了一个本地到指定Web服务器的TCP连接，之后输入请求即可，如下： 12345678910111213141516171819202122232425262728293031$ telnet www.yinkuiwang.cn 80Trying 185.199.111.153...Connected to chst1.github.io.Escape character is &apos;^]&apos;.GET /2019/06/16/KMP/ HTTP/1.1Host:www.yinkuiwang.cnHTTP/1.1 200 OKContent-Type: text/html; charset=utf-8Server: GitHub.comLast-Modified: Mon, 02 Dec 2019 08:16:22 GMTETag: &quot;5de4c856-67bd&quot;Access-Control-Allow-Origin: *Expires: Wed, 18 Dec 2019 01:39:45 GMTCache-Control: max-age=600X-Proxy-Cache: MISSX-GitHub-Request-Id: B9A8:56A3:1F39F4:214343:5DF98109Content-Length: 26557Accept-Ranges: bytesDate: Wed, 18 Dec 2019 01:29:45 GMTVia: 1.1 varnishAge: 0Connection: keep-aliveX-Served-By: cache-hnd18746-HNDX-Cache: MISSX-Cache-Hits: 0X-Timer: S1576632586.764452,VS0,VE186Vary: Accept-EncodingX-Fastly-Request-ID: cf573b3feb014acb04fd481fecf2de696fde337e&lt;!DOCTYPE html&gt; 后面的实体主体没有全部展示。注意，在敲下Host首部行之后要连击两下回车，表示输入请求完成。 用于与服务器的交互：cookie前面提到，HTTP是无状态的，然而一个Web站点通常希望能够识别用户，即可能是为了服务器限制用户访问，也可能是它想把内容与用户身份联系起来。为此，HTTP使用了cookie，它允许站点跟踪用户。 如上图所示，cookie由四部分组成： 在HTTP响应报文中有一个cookie首部行； 在HTTP请求报文中有一个cookie首部行； 在用户端系统保留一个cookie文件，由用户的浏览器管理； 在Web站点有一个后端数据库。 cookie可以在无状态的HTTP上建立一个用户层会话。例如，基于Web的电子邮件系统，浏览器向服务器发送一个cookie信息，运行该服务器通过用户与应用程序之间的会话对用户进行验证。 Web缓存Web缓存器（Web cache）也叫代理服务器（proxy server），它是能够初始Web服务器来满足HTTP请求的网络实体。Web缓冲器有自己的磁盘存储空间，并在该存储空间中保存最近请求的对象的拷贝。 一旦配置了浏览器，每个浏览器对对象的请求首先被定向到Web缓存器。其请求所经历流程大致如下： 浏览器建立一个到Web缓存器的TCP连接，并发送请求。 Web缓存器检测本地是否存储了该对象的拷贝。如果有，Web缓存器就用HTTP响应报文回复。 如果Web缓存器没有该对象，它就与该对象的初始服务器打开一个TCP连接，并发送请求。 当Web缓存器接收到该对象时，在本地存储一份拷贝，并用HTTP响应报文向客户端发送报文。 Web缓存器的好处： 大大减少客户机请求响应时间，尤其在客户机与初始服务器之间的瓶颈带宽远低于客户机与Web服务器瓶颈带宽时。 可以大大减少一个机构内部网与因特网接入链路上的通信量，降低费用。 整体上大大降低因特网上的Web流量，从而改善所以应用的性能。 条件GET方法条件GET方法是一种机制，允许缓存器证实它的对象是最新的。如果（1）请求报文使用GET方法；（2）请求报文包含一个if-modified-since首部行，那么这个HTTP请求报文就是一个条件GET请求报文。 缓存器发送一个条件GET，执行最新检查，例如： 123GET /fruit/kiwi.gif HTTP/1.1Host: www.somesite.comIf-modified-since: Wed,4 Jul 2007 09:23:24 该条件GET报文告诉服务器，仅当自指定日期之后修改过该对象才发送该对象。如果未改动过该对象，初始服务器响应报文可能是： 1234HTTP/1.1 304 Not ModifiedDate: Sat,14 Jul 2007 15:39:29Server: Apache/1.3.0(Unix)(实体主体为空) 文件传输协议：FTP FTP用于向一台远程主机上传或下载其文件。为了使用户能够访问远程主机，用户必须提供一个用户标识和口令。 HTTP和FTP都是文件传输协议，存在很多异同。相同点都是使用TCP作为运输层协议。主要区别是FTP使用两个并行的TCP连接来传输文件，一个是控制连接，一个是数据连接。控制连接用于在两个主机之间传输控制信息，如用户标识、口令、改变远程目录的命令以及“put”和“get”命令。数据连接用于实际传输一个文件。FTP使用一个分离的控制连接，所以我们称其控制信息是外带传送的。HTTP是内带的。 下图展示了FTP控制连接和数据连接： 当用户主机与远程主机开始一个会话前，FTP的客户机首先在21号端口上发起一个用于控制的与服务器的TCP连接。FTP客户机通过该控制连接发送用户标识与口令，也改变远程目录的命令。当FTP服务器端从该连接上收到一个文件传输的目录后，就发起一个客户端的数据连接。FTP在该连接上准确地传送一个文件并关闭该连接。如果还要传输别的文件，FTP则另打开一个连接。FTP控制连接贯彻了整个用户会话期间，但文件传输连接只在每次需要时才建立。 FTP服务器必须在整个会话期间保存用户的状态。服务器必须把特定用户账户与控制连接联系起来，随着用户在远程目录树上移动，服务器必须追踪用户在目录树上的当前位置。而HTTP是无状态的，不必对用户行为进行追踪。 一些常用FTP命令有： USER username：用于向服务器传送用户标识。 PASS password：用于向服务器传送用户口令。 LIST：用于请求服务器返回远程主机当前目录的所有文件列表。文件列表将在数据连接上传送。 RETR filename：用于从远程主机的当前目录检索文件。该命令触发远程主机发起一个数据连接，并发送文件。 STOR filename：用于向远程主机的当前目录存放文件。 常见回答为： 331 Username OK，password required 125 Data connection already open；transfer starting 425 Can’t open data connection 452 Error writing file 因特网中的电子邮件 上图展示了因特网电子邮件的总体情况，其主要由三部分组成：用户代理（user agent）、邮件服务器（mail server）和简单邮件传输协议（Smiple Mail Transfer Protocol，SMTP）。 用户代理允许用户阅读、回复、转发、保存和撰写报文（用户代理也叫邮件阅读器）。邮件代理向其邮件服务器发送邮件，并且该邮件被放在邮件服务器发送报文列中。当用户想要获取邮件时，其邮件代理从他的位于邮件服务器的邮箱中获取该报文。 邮件服务器组成了电子邮件系统的核心。每个接收方在其中的某个服务器上有一个邮箱。 邮件发送过程为：从发送方的用户代理开始，传输到发送方的邮件服务器，再传输到接收方的邮件服务器，然后在这里被分发到接收方的邮箱中。在传递到接收方的邮件服务器时，发送方邮件服务器还要处理接收方服务器故障的问题：当发送方发送失败时，发送方邮件服务器在一个报文列表中保持该报文并在以后尝试再次发送，一般半个小时尝试一次，如果几天依然不能成功，会删除该报文并通知发送方。在接收方查看邮件时，接收方服务器会首先鉴别其身份。 SMTP是因特网电子邮件中主要的应用层协议。它使用TCP可靠传输服务。 SMTPSMTP用于从发送方的邮件服务器发送报文到接收方的邮件服务器。SMTP邮件的主体部分（不止其首部）只能采用简单的7位ASCII码表示。 当A给B发送一封简单的ASCII报文时，其流程如下： 1）A调用他的邮件代理程序并提供B的邮件地址，撰写邮件，然后通过用户代理发送该邮件。 2）A的用户代理把报文发送给A的邮件服务器，在那里该报文被放在报文发送队列中。 3）运行在A邮件服务器上的SMTP客户机端发现报文队列中这个报文，就创建一个到运行在B的邮件服务器上的STMP服务器的TCP连接。 4）在经过一些初始SMTP握手后，SMTP客户机通过该TCP连接发送A的报文。 5）在B的邮件服务器上，SMTP的服务器端接收该报文，B的邮件服务器然后将该报文放入B的邮箱中。 6）在B方便的时候，调用用户代理阅读报文。 下图展示了该过程： SMTP一般不使用中间邮件服务器发送邮件。 SMTP客户机（运行在发送方邮件服务器上）在25号端口建立一个到SMTP服务器的TCP连接。一但建立连接，服务器和客户机就执行一些应用层的握手，在握手阶段，，SMTP客户机指定发送方的邮件地址和接收方的邮件地址。之后发送报文。 下面是SMTP服务器（S,主机名是server）和SMTP客户机（C，主机名是client）之间交换报文脚本的例子，一旦创建了TCP连接，就开始下列过程： 123456789101112131415S: 220 serverC: HELO clientS: 250 Hello client pleased to meet youC: MALL FROM: &lt;alice@crepes.fr&gt;S: 250 alice@crepes.fr ... Sender okC: RCPR TO: &lt;bob@hamburger.edu&gt;S: 250 bob@hamburger.edu ... Recipient okC: DATAS: 345 Enter mail, end with &quot;.&quot; on a line by itselfC: Do you like ketchup?C: How about pickles?C: .S: 250 Messgae accepted for deliveryC: QUITS: 221 server closing conncetion 上例中，客户机程序从邮箱服务器client向邮箱服务器server发送了一个报文（Do you like ketchup？How about pickles？）。客户机发送了五条命令：HELO（hello的缩写）、MALL FROM、RCPT TO、DATA以及QUIT。这些命令是自解释的。客户机通过发送一个只包含句点的行，告诉服务器该报文结束了。（按照ASCII码，每个报文以CRLF.CRLF结束，其中CR和LF分别表示回车和换行）。应达250表示正常。SMTP使用持久连接：如果发送邮件服务器有几个报文发往同一个接收服务器，可以通过一个TCP连接发送所有这些报文。对每个报文，客户机都用一个新的MALL FROM开始，仅当所以邮件全部发送完全才发送QUIT。 与HTTP的对比相同点：都是使用了持久连接。 不同点： HTTP是一个拉协议，即人们可以在方便的时候装载Web信息，即用户使用HTTP从该服务器拉取信息。TCP连接是由想获取文件的机器发起的。 SMTP是一个推协议，即发送邮件服务器把文件推到接收邮件服务器，TCP连接是由要发送的机器发起的。 SMTP要求每个报文使用7位ASCII格式。如果某报文包含了非7位ASCII字符或二进制数据，则该报文必须按照7位ASCII进行编码。 邮件报文格式和MIME邮件报文要包含环境信息，这些环境信息包含在首部行中。每个首部行包含一个From首部行和一个To首部行，可以包含一个Subject首部行或其他可选的首部行。这些首部行不同于在之前所学的SMTP命令，之前的命令是SMTP握手协议的一部分，而首部行是邮件报文的一部分。但是邮件发给谁和从哪里来不是由首部行决定的，而是由SMTP命令决定的。下面展示了一个典型的报文首部： 123From: aTo: bSubject: Searching for the meaning oof file 在报文首部之后，紧接着是空白行，然后是以ACSII格式表示的报文主体。 非ASCII码数据的MIME扩展为发送非ASCII文本的内容，发送方必须在报文中使用附加的首部行。多用途因特网邮件扩展（Multipurpose Internet Mail Extension，MIME）。支持多媒体的量关键字MIME首部为Content-Type:和Content-Transfer-Encoding：。前者允许接收用户代理采取适当的动作，后者提示接收用户代理该报文已经使用了ASCII编码，并指出了使用的编码类型。当用户代理接收到包含这两个首部行的报文时，会根据Content-Transfer-Encoding的值将报文编码为非ASCII格式，然后根据Content-Type首部行决定它应该采取何种动作来处理报文。 接收的报文接收器一旦接收到具有RFC 822和MIME的首部行，就在该报文的顶端添加一个Received:首部行。该首部行定义了发送该报文的SMTP服务器的名称，接收该报文的SMTP服务器名称和接收时间。例如：Received: from server by client; 12 Oct 98。 邮件访问协议之前我们只考虑了邮件服务器之间使用SMTP进行传输报文，现在考虑用户代理与邮箱服务器之间如何传递报文。在发件方来看，从用户代理到邮箱服务器是一个推过程，需要推协议，SMTP刚好可以按照，因此，在发送方这两者使用SMTP协议。在来看接收方，接收方是在有时间的时候去读邮件，因此是一个拉过程，需要拉协议来支持，因此不能使用SMTP。与之对应的，可以使用的协议有三种：第三版邮局协议（Post Office Protocol-Version 3，POP3）、因特网邮件访问协议（Internet Mail Access Protocol，IMAP）以及HTTP。 POP3当用户代理（客户机）打开一个到邮件服务器（服务器）端口110上的TCP连接后，POP3就开始工作了。POP3按照三个阶段进行工作：特许（authorization）、事物处理以及更新。 第一阶段（特许）：用户代理发送（以明文形式）用户名和口令以鉴别用户。 第二阶段（事务处理）：用户代理取回报文。同时还可以进行：对报文做删除标记，取消报文删除标记，以及获取邮件的统计信息。 第三阶段（更新）：出现在客户机发出了quit命令后，目的是结束该POP3会话，这时，邮件服务器删除那些被标记为删除的报文。 在POP3事物处理阶段，用户代理发送一些命令，服务器对每个命令做出回答。回答有两种：+OK（有时后面会有说明文字），服务器用它来指示前面的命令是正常的；-ERR，服务器用它来指示前面的命令出现错误。 特许阶段主要有两个命令：user username和pass password。下面展示了这个的使用： 12345678910$ telnet pop.qq.com 110Trying 59.37.97.57...Connected to pop.qq.com.Escape character is &apos;^]&apos;.+OK QQMail POP3 Server v1.0 Service Ready(QQMail v2.0)user 2322253097+OKpass ********-ERR Please using authorized code to login. More information at http://service.mail.qq.com/cgi-bin/help?subtype=1&amp;&amp;id=28&amp;&amp;no=1001256Connection closed by foreign host. 这里使用的是qq邮箱的POP3服务器。但是由于腾讯做了一个优化，输入密码时，不是之间输入qq密码，而是输入一个授权码，所以这里就报错了。 事物处理过程中。POP3用户代理发出的命令通常由用户配置为“下载并删除”或者“下载并保留”。主要有四个命令list、retr、delete和quit。命令的语法在RFC 1939中定义。大概使用如下图： IMAPIMAP服务器把每个报文与一个文件夹联系起来，当报文第一次到达服务器时，它被放到收件箱文件夹中。收件人可以把邮件移到一个新的、用户创建的文件夹中，或阅读邮件、删除邮件等。IMAP为用户提供了创建文件夹以及在文件夹中移动邮件的命令。IMAP还为用户提供了在远程文件夹中查询邮件的命令，按指定条件去查询匹配的邮件。IMAP服务器维护了IMAP会话的用户状态信息。 IMAP运行用户代理获取报文组件的命令。 DNS，因特网的目录服务主机使用IP地址进行标识。一个IP地址由4个字节组成，并有着严格的层次结构。如想127.7.106.83这样，每个字节都被句点分隔开，表示了0~255的二进制数。IP地址具有层次结构是因为我们从左向右扫描时，会得到越来越细的关于主机位于因特网何处的信息。 主机也可以使用主机名进行标识。不过主机名只有在DNS中注册才有用，别人才能通过DNS获得主机名，因此在DNS中，主机名一定是互异的。 DNS提供的服务域名系统（Domain Name System，DNS）提供进行主机名到IP地址转换的目录服务。 DNS是：1）一个由分层的DNS服务器实现的分布式数据库；2）一个运行主机查询分布式数据库的应用层协议。DNS协议运行在UDP之上。 DNS通常由其他应用层协议（如HTTP、SMTP和FTP）所使用，用于将用户提供的主机名解析为IP地址。例如，当请求URL www.someschool.edu/index.html页面时，为了使用户的主机能够将一个HTTP请求发送到Web服务器www.someschool.ed，该用户主机必须获得www.someschool.edu的IP地址。其做法为： 同一台用户主机上运行着DNS应用的客户机端。 该浏览器从上述URL中抽取出主机名www.someschool.edu，并将这个主机名传给DNS应用的客户机端。 该DNS客户机向DNS服务器发送一个包含主机名的请求。 该DNS客户机最终会收到一份回答报文，包含对于主机名的IP地址。 一旦浏览器接收到来自DNS的IP地址，它就可以向该IP地址定位的HTTP服务器发起一个TCP连接。 除了进行主机名到IP地址的转换外，DNS还提供了一些重要服务： 主机别名（host aliasing）：有着复杂主机名的主机可以用于一个或者多个别名。原始主机名叫做规范主机名（canonical hostname）。应用程序可以调用DNS来获得主机别名对于的规范主机名已经主机的IP地址。 邮件服务器别名（mail server aliasing）：电子邮件应用程序调用DNS，对提供的邮件服务器别名进行解析，以获得该主机的规范主机名以及IP地址。事实上，MX记录允许一个公司的邮件服务器和Web服务器使用相同的（别名化的）主机名。 负载分配（load distribution）：DNS也用于在冗余的服务器之间进行负载分配。繁忙的站点被冗余分别在多台服务器上，每台服务器均运行在不同的端系统上，有着不同的IP地址。对于这些冗余的服务器，一个IP地址集合对应于同一个规范主机名。DNS数据库存储着这些IP地址集合。当客户机为映射到这个IP地址集合的名字发出一个DNS请求时，该服务器用包含全部这些地址的报文进行回答，但每个回答中旋转这些地址的顺序。客户机通常总是向IP地址排在最前面的服务器发送请求，所以DNS就在所有冗余的服务器之间旋转分配负载。 DNS工作机理应用程序调用DNS的客户机端，并指明要转换的主机名，用户主机上的DNS接收到后，向网络中发送一个DNS查询报文。所有DNS请求和回答报文使用UDP数据报经端口53发送。经过若干毫秒时延后，用户主机上的DNS接收到一个DNS回答报文，这个结果被递送到调用DNS查询的应用程序中。 DNS的一种简单设计方式是在因特网上只使用一个DNS服务器，该服务器包含所有映射。但是这样会有很多问题： 单点故障：如果该服务器崩溃，整个因特网随之瘫痪。 通信容量：单个DNS服务器不得不处理所有DNS查询。 远距离的集中式分布：单个服务器不可能接近所有查询的客户机，因此会造成严重的时延。 维护：单个服务器将不得不为所以的因特网主机保留记录。使得整个中央数据库非常庞大，而且不得不解决为每个新添加的主机而频繁更新。 为此，DNS采用了分布式设计方案，DNS是因特网上实现分布式数据库的典范。 分布式、层次数据库有三类DNS服务器：根DNS服务器、顶级域（Top-Level Domain，TLD）DNS服务器和权威DNS服务器。他们以上图这样组织（有点像HASH的感觉）。此时查询过程为，以www.Amazon.com举例。首先客户机联系根DNS服务器之一，它返回顶级域名com的TLD服务器IP地址。该客户与这些TLD之一联系，它将为amazon.com返回权威服务器的IP地址。最后，该客户家联系权威服务器，它为www.Amazon.com返回IP地址。 根服务器：因特网上存在13个根服务器（标号A到M）。尽管我们将这13个每个视为单独的服务器，但每台“服务器”实际上是冗余服务器集群，以提供安全性和可靠性。 顶级域服务器：这些服务器负责顶级域名如（com、org、net、edu和gov）和所有国家的顶级域名。 权威DNS服务器：在因特网上具有公共可访问（如Web服务器和邮件服务器）的每个组织机构必须提供公共可访问的DNS记录，这些记录将这些主机的名字映射为IP地址。由组织机构的权威DNS服务器来保持这些记录，或者支付费用将这些记录存储在某个服务提供商的权威DNS服务器中。 除了上面三种以外，还有一类重要的DNS，称为本地DNS服务器。本地DNS服务器严格来说不属于DNS服务器的层次结构。当主机发出DNS请求时，该请求首先被发往本地DNS服务器，它起着代理的作用，并将该请求转发到DNS服务器层次结构中。本地DNS服务器工作方式如下图： 主机发送请求后，首先定向的本地DNS中，本地DNS联系根DNS，获得对应的TLD，在联系对应的TLD，获得权威服务器，再联系权威服务器，获得IP，返回给请求主机。 TLD服务器不一定知道每台主机的权威DNS服务器的IP地址。TLD服务器只知道中间的某个DNS服务，该中间服务器依次才能知道用于该服务器的权威DNS服务器。 上图展示的例子是递归查询（recursive query）和迭代查询（iteration query）。主机到本地服务器是递归，本地到后面的三个查询是迭代。理论上将，查询可以是完全递归的，如下图： DNS缓存为了改善时延性并减少在因特网上到处传输的DNS报文数量，DNS广泛使用了缓存技术。DNS缓存（DNS caching）原理十分简单：在请求链中，当一个DNS服务器接收到一个DNS回答时，DNS将回答中的信息缓存在本地存储器中。由于主机和主机名与IP地址映射不是永久的，所以DNS服务器在一段时间后将丢弃缓存信息。 DNS记录和报文实现DNS分布式数据库的所有DNS服务器共同存储着资源记录（Resource Record，RR），RR提供了主机名到IP地址的映射。每个DNS回答报文包含了一条或多条资源记录。 资源记录是一个包含了下列字段的4元组： 1(Name, Value, Type, TTL) TTL是该记录生存时间，它决定了资源记录应当从缓存中删除的时间。Name和Value的值取决于Type： Type Name含义 Value含义 A 主机名 IP地址。 NS 域（如foo.com） 知道如何获得该域中主机IP地址的权威DNS服务器主机名。 CNAME 别名 规范主机名 MX 别名 邮件服务器的规范主机名 为了获得邮件服务器的规范主机名，应该请求一条MX记录，为了获得其他服务器主机名应该请求一条CNAME记录。 如果一台DNS服务器是指定某特定主机的权威DNS服务器，那么该DNS服务会有一条包含该主机名的A记录。如果DNS服务器不是某个主机名的权威DNS服务器，那么该服务器包含一条NS记录（我觉得NS记录应该不是在服务器中存储的，应该是更具请求生成的），该记录对应于包含主机名的域；还有一条A记录，该记录提供了在NS记录中的Value字段中DNS服务器的IP地址。 DNS报文DNS只有两种报文，并且查询和回复有着相同的格式，如下图： DNS报文中各字段语义如下 1）前12个字节是首部区域，其中有几个字段。第一个字段是16比特的数，用于标识该查询。这个标识符会被复制到对查询的回答的报文中，以便让客户机用它来匹配发送的请求和接收到的回答。标识字段中有多个标志。1比特的“查询/回答”标识位指出是查询报文（0）还是回答报文（1）。当某DNS服务器正好是被请求主机的权威DNS服务器时，1比特的“权威的”标识位被置位在回答报文中。如果客户机（主机或者DNS服务器）希望DNS服务支持递归查询，将设置1比特的“希望递归”标志位。如果该DNS服务器支持递归查询，则回答报文中会对1比特的“递归可以”标志位置位。在该首部还有4个“数量”字段，指出在首部后四类数据区出现的数量。 2）问题区域包含着正在进行的查询信息。该区域包括：1.名字字段，用于指出正在被查询的主机名字。2.问题字段，用于指出正被查询的问题类型（A、MX等）。 3）来自DNS服务器的回答报文中，回答区域包含了对最初请求的名字的资源记录（RR）。一个回答报文的回答区域可能有多条RR，因为一个主机名可能对应多个IP地址。 4）权威区域包含了其他权威DNS服务器的记录。 5）附加区域包含了一些有帮助的信息。 可以使用nsloopup程序来进行DNS查询。该程序的使用命令是： 123nslookup -qt=type domain [DNS-server];//例如nslookup -qt=mx baidu.com 8.8.8.8 在DNS数据库中插入记录当向某些注册登记机构注册域名networkutopia.com时，需要向该机构提供基本权威DNS服务器和辅助权威DNS服务器的名字和IP地址（不是域名本身的IP地址）。假定该名字和IP地址是dns1.networkuptopai.com和dns2.networkuptopai.com已经212.212.212.1和212.212.212.2。对这两个权威DNS服务器的每一个，该注册机构确保将一个类型NS和一个类型A的记录输入到TLD com服务器。如： 12(networkuptopia.com,dns1.networkuptopai.com,NS)(dns1.networkuptopai.com, 212.212.212.1, A) 此时查询时，首先TLD com回复本地DNS一个NS信息，而后本地DNS再次查询TLD com获取含义networkuptopia.com的权威服务器地址，这里是212.212.212.1。而后查询权威DNS服务器来获取IP地址。 P2P应用P2P文件分发在P2P文件分发中，每个对等方都能够重新分发其所有的该文件的任何部分，从而协助服务器进行分发。 P2P体系结构的扩展性下图展示了文件分发的示意图，其中所有字母的含义如图所示： 对于客户机/服务器的体系结构来说，将文件传输给所有客户机总时间受两个限制，一个是服务器上传N份文件所需要的总时间，另一个是下载最慢的服务器下载整个文件所需时间，因此客户机/服务器体系结果总的分发时间满足：$$D_{cs} &gt;= max{\frac{NF}{u_s}, \frac{F}{d_{min}}}$$对于P2P体系结构来说，分发总时间受三方面限制，第一是服务器发送一份完整的文件出去的时间，第二是下载最慢的主机下载完文件的时间，第三是所有主机上传N份文件的时间。因此P2P文件分发时间满足：$$D_{P2P} &gt;= max{\frac{F}{u_S},\frac{F}{d_{min}}, \frac{NF}{u_s+\sum_i^N{u_i}}}$$ BitTorrentBitTorrent是一种用于文件分发的流行P2P协议。用BitTorrent的术语来说，参与一个特定文件分发的所有对等方的集合称为一个洪流（torrent）。每个洪流具有一个基础设施节点，称为追踪器。当一个对等方加入洪流时，它向追踪器注册，并周期性的通知追踪器它任然在洪流中。追踪器以这种方式跟踪洪流中的对等方。 当新对等方加入洪流时，追踪器随机的从对等方集合中选择一些对等方，如50个，并将这50个对等方的IP地址发送给新的对等方。新的对等方持有对等方的这张列表，试图与该列表上的所有对等方创建并行的TCP连接。我们称所有与新对等方成功建立TCP连接的对等方为“邻近对等方”。 这里新的对等方为Alice。Alice周期性地询问每个邻近对等方它们所具有的块列表。如果Alice有L个邻近对等方，那么将会获得L个块列表，此时其就可以对自己当前还没有的块发出请求。 Alice将做两个决定，第一，她应该向她的邻居请求那些块？第二，她所拥有的块应该发送给哪个邻居。 对于请求哪个块，Alice采用一种称为最罕见原则（rarest first）。该原则思想是，根据她没有的块从她的邻居中确定那些最稀缺的块（即L列表中出现最少的块），并优先请求最稀缺的块。这样，最稀缺的块更迅速地重新分发，其目标是均衡每个块在洪流中拷贝数量。 为了决定她响应哪个请求，基本想法是Alice确定其邻居的优先权，这些邻居是那些当前能够以最高的速率供给它数据的。特别的，Alice对于她的每个邻居都持续地测量接收到比特的速率，确定以最高速率流入的四个邻居，然后，她将数据发给这4个邻居。每过10秒，她重新计算该速率并可能修改这四个对等方。更重要的是，每过30秒，她要随机地选择一个另外的邻居并向他发送块。我们将这个随机的对等方称为Bob。因为Alice给Bob发送数据，所以她可能成为Bob前4位上载者之一，这样Bob向Alice传输数据。如果Bob向Alice发送数据速率足够高，他也可能成为Alice的前四个上载者之一。换言之，每过30秒，Alice随机选择一个新的对等方并开始传输数据。如果这两个对等方都满足此对换要求，那么会将对方放入到其前四位列表中并继续与对方进行对换，直到对等方之一发现更好的伙伴为止。 在P2P区域中搜索信息集中式索引在集中式索引中，由一台大型服务器（或服务器场）来提供索引服务。该方法存在几个缺点： 单点故障：服务器崩溃，整个P2P崩溃。 性能瓶颈好基础设施费用。 侵犯版权。 查询洪泛查询洪泛是建立在Gnutella协议之上的。在Gnutella中，对等方形成一个抽象的逻辑网络，该网络被称为覆盖网络。如果对等方X和对等方Y维护了一个TCP连接，那么我们说X和Y之间有一条边。在这种设计中，对等方通过已经存在的TCP连接，向覆盖网络中相邻的对等方发送报文。当Alice要定位一个文件位置时，她向所有邻居发送一条查询报文。Alice的邻居向它们的所有邻居转发该报文，邻居的邻居会接着转发。当一个对等方接收到查询报文时，将检测查询内容是否与可供共享的任何文件相匹配，如果存在匹配，则按查询的路径反向传播回去，向Alice回送一条查询命中（递归式）。、 该方法会在网络中产生大量流量，为解决该问题使用了范围受限查询洪泛。具体来说，就是在查询时添加一个计数，每到下一层就将计数减一。如果到0了，即使没有查到也不再向外扩散。 这里讨论当X加入覆盖网络的过程： 1）对等方要首先发现某些已经位于覆盖网络的其他对等方。解决这种引导跨接问题的方法之一是，让X维护一张对等方列表（IP地址），这些对等方常在覆盖网络中开机；另一种方法是，X能够联系维护这种列表的跟踪站点。 2）一旦访问了这样一张表，X接下来试图与该表上的对等方建立一个TCP连接，直到与某个对等方Y创建连接为止。 3）对等方向Y发送一个Ping报文，该ping报文包括对等方计数字段。Y接收到Ping后转发ping，直到Ping等于0. 4）只要一个对等方Z接收到ping，它通过覆盖网络向X发送一个pong报文，该报文包含Z的IP地址。 5）当X接收到pong报文后，就知道到了网络中许多的IP地址，可以建立连接。 层次覆盖层次覆盖结合了上述两种方法的优秀特征。层次覆盖不使用专用的服务器来跟踪和索引文件。在层次覆盖中并非所有对等方是平等的，具有高速连接并具有高可用性的对等方被指定为超级对等方。每个非超级对等方都被指定为一个超级对等方的子对等方。一个新的对等方与超级对等方建立一个TCP连接，新对等方将可共享文件告诉超级对等方。这样，每个超级对等方就成为一个小的索引。超级对等方之间互相建立TCP连接，从而形成覆盖网络。超级对等方可以向其邻居超级对等方转发查询。该方法类似于查询洪泛，但覆盖网络中超级对等方仅使用了受限查询洪泛。 分布式散列表在该书第六版中将前一节的三部分全部删除了，添加了一个分布式散列表用来P2P区域中搜索。说明该方法应该是当前最好使的，使用最广泛的，前三个可能已经弃用了。但是第七版又把这个也删了，表示很迷。 分布式散列表（Distributed Hash Table，DHT）是一个分布式数据库，在数以万计的对等方中存储（键，值）对。在每个对等方将保持（键，值）对仅占总体的一个小子集，允许任何对等方使用一个特别的键查询该分布式数据库。分布式数据库则能够定位拥有该相应（键，值）对的对等方，然后向查询的对等方返回该（键，值）对。任何对等方也将允许在数据库中插入新键值对。 首先为每个对等方分配一个标识符，其中每个标识符是一个[0, 2^n-1]范围内的整数，n取某些固定的值。我们也要求键是同一范围内的一个整数。通过散列函数将键映射到该范围。 现在考虑DHT中存储（键，值）对问题，该问题核心是对等方键的分配。给定每一个对等方一个整数标识符，每个键也会被映射到标识符对应的范围。这里需要定义“最近邻”，最近邻是指键的最邻近后继。假设n是4，键都落在[0,15]之内，假设该对等方存在8个对等方，标识符分别为1、 3、 4、 5、 8、 10、 12和15，此时要存储（11，something）时，就一个存储在标识符为12的对等方上。 当我们要插入一个键值对时，之间通过计算该存储放到哪个对等方（假如可以获得），然后之间联系该对等方是可以的，但是这有个规模的问题，这样的话要求每个对等方存储所有其他对等方的IP，这是不合理的。为此，我们设计了环形DHT。 环形DHT 这里我们将对等方组织成一个环，每个对等方只需要与它的直接后继和直接前驱联系（环状双向链表）。当对等方3要确定谁复制11时，首先其生成一个报文传递给其后继，该报文沿顺时针方向传输。每个接收到该报文的对等方，由于知道其前驱节点和后继节点因此知道是否该由自己负责该键值对，如果不负责，则将报文传递给后继节点。直到找到该负责次节点的对等方为止。（问题1：如果DHT中没有大于该键的最近邻咋办？可能进入DHT的第一个对等方与服务器连接时，被分配为标识符为2^n-1） 只有前驱和后继也造成了一个问题是，每次查询和插入的平均发送N/2条报文。这也是不太合理的，因此每个对等方要跟踪的邻居数量与DHT为解析一个查询而需要发送的 报文数量之间存在着折中。细化方案之一是以环形网络为基础，但添加捷径，使每个对等方不仅联系其直接前驱和直接后继，而且联系分部在环上的捷径对等方。如上图的b，此时当某个对等方收到报文时，不仅传输给后继报文，也传递给与其相连的捷径上。 研究表明，DHT能够被设计成每个对等方的邻居数量以及每个请求报文数量均为O(logN)。这是一种比较令人满意的折中。问题2：哪些对等方被选则为捷径的目标节点，以及如何获取这些对等方的IP） 对等方的扰动在DHT中，对等方可以不加警示的到来和离开，为了处理这个问题，我们要求对等方要知道其第一个和第二个后继，以及要周期性的证实它的两个后继是否存活（如周期性发送ping报文并寻求响应）。现在假设上图a中5突然离开，此时,5将不在响应ping报文，在离开之前的对等方3和4知道了5离开，此时4和3将更新其后继信息。(4先更新，再更新3）问题3：离开的对等方里面存储的键值对如何再被重新分配，还有以该对等方为捷径的对等方如何更新捷径 下面讨论一个对等方加入时发送的事情，新的对等方加入时，会知道编号最小的已经存在的对等方的IP，这里是1（应该是有一个服务器来维护这个信息，每个对等方进入DHT时，首先联系该服务器）。然后向该对等方发送查询信息，获得其前驱和后继（可能这个时候也可以创建捷径，但具体操作呢）。而后插入进去，即可。 更多关于DHT的内容可以查看Kademlia相关内容。 第三章 运输层概述和运输层服务运输层协议为运行在不同主机上的应用进程提供了逻辑通信。运输层在端系统中实现而不是在网络路由器中实现。在发送方，运输层接收来自上层的的报文转换成运输层分组：将应用报文换分为较小的块，并为每一块加上运输层首部来创建运输层报文段。在发送方体统中，运输层将这些报文段传输给网络层，网络层将其分装进网络层分组并向目的地发送。网络路由器只作用于数据报的网络层字段，即他们不检查分装在该数据报的运输层报文段的字段。 运输层与网络层的关系运输层为运行在不同主机上的进程之间提供逻辑通信，而网络层提供了主机之间的逻辑通信。运输层协议只工作在端系统。运输层协议所能提供的服务也受到底层网络层协议的服务模型的限制，然而，即使网络层不提供响应的服务，运输层协议也能提供某些服务。 因特网运输层概述运输层为应用层提供了两种截然不同的协议：UDP（用户数据报协议）和TCP（传输控制协议），前者提供一种不可靠的无连接服务，后者提供了一种可靠的面向连接的服务。 网络层协议叫IP（网际协议），IP为主机之间提供了逻辑通信。IP的服务模型是尽力而为交付服务（best-effort delivery service）。即IP尽最大努力交付报文段，但不作任何保证。特别的，它不确保报文段的交付，不确保报文段的按序交付，不确保报文段的完整性。因此IP被称为不可靠服务。每台主机至少有一个网络层地址，即所谓的IP地址。 TCP和UDP的基本任务：将两个端系统间IP的交付服务扩展到运行在两个端系统的进程之间的交付服务。将主机间交付扩展到进程间交付，称为运输层的多路复用与多路分解。UDP和TCP还通过在其报文段首部添加差错检测字段而提供完整性检查。进程数据交付和差错检测是两种最低限度的运输层服务，也是UDP所提供的仅有的两种服务。 TCP还提供几种附加的服务，首先提供了可靠数据传输。通过使用流量控制、序号、确认和定时器等技术。TCP确保正确的、按序的将数据从发送进程交付到接收进程，这样TCP将两个端系统之间不可靠的IP服务转换为一种可靠的进程间数据传输服务。TCP还提供拥塞控制，TCP拥塞控制防止任何一条TCP连接用过多流量来淹没通信主机之间的链路和交换设备。 多路复用与多路分解进程有一个或多个套接字，它相当于从网络向进程传递数据和从进程向网络传递数据的门户。 首先考虑接收主机如何如何将一个收到的运输层报文定向到合适的套接字。为实现这一要求，每个运输层报文段中设置几个字段，在接收端，运输层检测这些字段并标识出接收套接字，然后将报文段定向到该套接字。将运输层报文段中的数据交付到正确的套接字的工作称为多路分解。从源主机的不同套接字中收集数据块，并为每一个数据库封装上首部信息从而生成报文段，然后将报文段传递到网络层的工作叫做多路复用。 运输层多路复用的要求： 套接字有唯一标识符。 每个报文段有特殊字段来指示该报文段要交付的套接字。 端口号是一个16比特的数字，其大小在0~65535之间。[0,1023]的端口被称为周知端口，是受严格限制的。 无连接的多路复用与多路分解创建UDP套接字时，运输层自动为套接字分配一个端口号（也可以自己指定）。 一个UDP套接字是由一个包含目的IP地址和目的端口号的二元组来全面标识。 面向连接的多路复用与多路分解TCP套接字是由一个四元组（源IP地址，源端口号，目的IP地址，目的端口号）来标识的。特别的，两个具有不同源IP地址或源端口的到达的TCP报文段将被定向到两个不同的套接字，除非TCP请求了初始创建连接的请求。 无连接传输：UDPUDP只做了运输协议能够做的最少工作。除了多路复用/多路分解功能以及一些轻型的差错检验外，几乎没有对IP增加别的东西。使用UDP时，在发送报文段之前，发送方和接收方的运输层实体之间没有进行握手，因此UDP被称为无连接的。 使用UDP的原因： 应用层可以更好的控制要发送的数据和发送的时间。UDP不提供拥塞控制，数据传递给UDP后会立即打包并传递给网络层。 无需建立连接：因此不会引入建立连接的时延。 无连接状态：TCP需要在端系统中维护连接状态，UDP不维护连接状态，某些应用专门使用UDP以便能够支持更多的活动客户机。 分组首部开销小。 UDP报文段结构 应用数据是应用层传递来的数据。通过端口号可以使目的主机将应用数据交付到运行在目的端系统的相应进程。接收主机使用校验和来检查报文段中是否存在差错。 UDP校验和UDP校验和提供了差错检验功能，即检验和用于确定当UDP报文段从源主机到达目的时，其中的比特是否发送变化（例如，由于链路中或者路由器中存储数据时的噪声干扰）。发送方的UDP对报文中的所有16比特字的和进行反码运算，求和时遇到的所有溢出都要被回卷，得到的结果放到UDP报文段中的校验和字段。 举例： 假定我们有3个16比特字： 123011001100110000001010101010101011000111100001100 此时求和过程为： 123456701100110011000000101010101010101 +----------------------10111011101101011000111100001100 +----------------------0100101011000010 注意，这里第二次相加时，最高位溢出，回卷加到最低位。反码是将所有0换成1，1换成0。所以此时该UDP报文的校验和是1011010100111101。在接收方将全部4个比特字（包括校验和）一起相加。如果分组中无差错，则这个和全是1，否则存在一个0就表面分组中出现错误。 某些UDP实现只是丢弃受损的报文段，其余实现是将受损的报文段交给应用程序并警告。 可靠数据传输原理 上图说明了我们数据传输的接口。通过rdt_send()函数，可以调用数据传输协议的发送方。它将要发送的数据交付给接收方上层（rdt表示可靠数据传输协议，_send表名发送方被调用）。在接收方，当分组从信道的接收端抵达时，调用rdt_rcv()。当rdt协议想向上层交付数据时，通过调用deliver_data()完成。 本节中，只考虑单向数据传输的情况，从发送方到接收方。可靠的双向数据传输的情况从概念上讲不会更难。rdt的发送和接收方都需要通过调用udt_send()发送分组给对方（其中udt表示不可靠传输协议）。 构造可靠传输协议完全可靠信道上的可靠数据传输协议：rdt1.0首先考虑最简单的情况，即底层信道是完全可靠的。下图展示了rdt1.0发送方和接收方的有限状态机(FSM)定义： FSM箭头指示了从一个状态变迁到另一个状态。上图发送方和接收方都只有一个状态。此时，有完全可靠的信道，接收方就不需要提供任何反馈给发送方了。 具有比特差错信道上的可靠数据传输：rdt2.0更底层信道模型是分组中比特可能受损。 首先考虑人们对于该问题的处理。通常情况下，接收者听到、明白、记下每句话可以说“OK”。如果消息接收者听到一句含糊不清的话，可能请求重复那句话。这种口头消息协议使用了肯定确认（positive acknowledgment）与否定确认（negative acknowledge）。在计算机网络中基于这种重传机制的可靠数据传输协议称为自动重传请求（Automatic Repeat reQuest，ARQ）协议。 一般来说，ARQ协议中需要另外三种协议来处理存在的比特差错： 差错检测：运输层添加的校验和字段。还有别的方式。 接收方发送反馈：回复肯定确认（ACK）还是否定确认（NAK）。 重传：接收方收到有差错的分组，发送方重传。 注意，当发送方在wait-for-ACK-orNAK状态时，它不能从上层获得更多的数据，也就是说，rdt_send()不会出现，仅当收到ACK并离开该状态时才能继续获得数据。因此发送方不会发送一块新数据，直到发送方确信接收方已经正确接收到当前分组为止。由于这种行为，类似于rdt2.0的协议被称为停等（stop-and-wait）协议。 rdt2.0存在一个致命的缺陷，即没有考虑到ACK或NAK分组受损的可能性。处理ACK与NAK受损时要考虑以下三种可能解决方案： 接收到ACK或NAK受损的一方，再次发送NAK，即数据受损，但这样会无线循环下去，该方式不行。 增加足够的检验和比特使发送方不但能够检测比特受损，还可以恢复当前分组。 当发送方收到含糊不清的ACK或NAK时，只用重发当前数据分组即可。但这种方法在接收方到发送方中引入了冗余分组（duplicate packet）。冗余分组的根本困难在于接收方不知道它上次发送的ACK或NAK是否被发送方正确地收到，因此它无法事先知道接收到的分组是新的还是一次重发的。 现在普遍采用的是方法三，这里解决冗余分组的方法是在数据中添加一个新字段，让发送方对其数据分组进行编号，即将发送的数据分组序号放在该字段。此时接收方只需检查序号即可知道是重传的一个还是新发的一个。对于停等协议，只需要1比特序号就足够了。 对于发送方来说，发送完成之后等待对该次分组的确认，如果接收到的确认消息被损坏或者是NAK则重发，直到收到未被损坏的确认消息且确认消息为ACK，则进入下一个状态（等待下一次调用）。 对于接收方来说，接收到数据被损坏就会发送NAK并等待重发的数据。直到重发的数据没有被损坏，则发送ACK确认，并进入下一个状态（等待接收下一个分组）。如果接收到的分组不是现在等待的分组，则说明前一个ACK消息被损坏，发送方又重发了一个已经接收到的消息，且发送方未正确进入到下一个状态（因为没有正确接收到ACK），于是接收方此时应该再次发送ACK确认信息即可，直到发送方正确接收到ACK并进入了下一个状态发送了分组。 再进一步，我们希望只有ACK确认信号而没有NAK信号，此时我们只需要在ACK信号上再绑定应该序号即可，此时也能实现上面的要求，此时在发送方如果收到了要等待的ACK对应的编号与实际收到的不一致时，等同于收到了NAK信号（发送的ACK信号对应编号是已经确认收到的信号，与要等待的不一致说明当前这次发送的分别没有被正确接收），需要重复。 具有比特差错的丢包信道上的可靠数据传输：rdt3.0现在假定处理比特受损外，底层信道还有可能丢包。这里，我们让发送方负责检测和恢复丢包。假设发送方传输一个数据分组，分组本身丢包或者接收分组后确认分组的ACK发生丢失。这两种情况下，发送方都收不到应当到来的响应。如果发送方愿意等待足够长时间以便确认分组已丢失，则只需要重传该分组即可。 上图的接收到即适合与rdt2.2也适合与接下来的rdt3.0。 从发送方角度来看，重传是万能的，发送方不知道一个数据分组丢失、一个ACK丢失，还是该分组或ACK只是过度迟延。在所有情况下采用相同动作，即重传。为实现基于时间的重传机制，需要一个倒数计时器（countdown time），在一个给定的时间过期后，可中断发送方。因此发送方需要能做到： 每次发送一个分组（即第一次分组和重传分组）时便启动一个定时器。 响应定时器中断（采取适当的动作）。 终止定时器。 这里在等待上层调用时会收到ACK是因为冗余数据导致的，因此可直接忽略。 下图展示了rdt3.0所遇到各种情况是如何工作的： 流水线可靠数据传输协议rdt3.0是一个功能正确的协议，但并非人人都能满足其性能，rdt3.0的核心问题是其为停等协议，会遭到带宽利用率底下。 解决这种性能问题的一个简单方法是：不使用停等方式运行，运行发送方发送多个分组而无需等待确认。流水线技术可对可靠数据传输协议带来如下影响： 必须增加序号范围。 协议的发送方与接收方必须缓存多个分组，发送方最低限度应当缓存那些已经发送但未确认的分组。 所需序号范围和对缓冲的要求取决于数据传输协议处理丢失、损坏以及过度延时分组的方式。 解决流水线差错恢复有两种基本方法：回退N步（Go-Back-N）和选择重传。 回退N步在回退N步（GBN）中，允许发送方发送多个分组（当有时）而不需要等待确认，但也受限于在流水线中未确定的分组数不能超过某个最大允许数N。 上图展示了GBN协议的序号范围。将基序号（base）定义为最早的未确认分组的序号，将下一个序号（nextseqnum）定义为最小的未使用（即下一个待发送）序号，则可将序号范围分成四部分。那些已发送而未被确认的分组的许可序号范围可以被看成是一个在序号范围内长度为N的窗口。随着协议的运行，该窗口向前滑动。N被称为窗口长度，GBN协议常被称为滑动窗口协议。 一个分组的序号承载在分组首部的一个固定长度的字段中。如果字段长度是K，则序号范围是[0,2^k-1]。所有涉及序号的运算必须使用摸2^k运算。 对于发送方来说：首先上层调用时，判断是否是超过了N，如果没有，则发送数据，并且判断该发送是否为唯一一个未被确认的发送，如果是，启动计时器。而后更新nextseqnum，如果超过N了，则拒绝发送数据。当收到ACK时，ACK传递的编号是接收方已确定接收到的值。此时即可更新base值。如果更新后的base值与nextseqnum值一致，说明所有传输的分组都已经确认了，此时关闭计时器，否则重新开始计时。当计时器超时时，将base到nextseqnum-1之间已经传输的数据重传。其他情况忽略（不采取动作）。 对于接收方来说：当接收到数据且没有被损坏且是期望到底的组，就接收该组，并发送ACK数据，报告已经接收到的组编号到了哪，并将期望到达的组编号加一。因此对于接收方来说，其期望数据是按序到达的，如果无效将导致发送方的重传。其他情况下，将发送之前的ACK确认信息。 GBN期望传输时是有序到达的，该方法的优点是：接收方缓存简单，接收方不用缓冲任何失序分组。因此，虽然发送方必须维护窗口的上下边界及nextseqnum在该串口的位置，但接收方只需要维护下一个按序接收的分组序号（exceptedseqnum）。该方法的缺点是：随后对该分组的重传也许会丢失或出错，因此甚至需要更多的重传。 选择重传选择重传（SR）协议通过让发送方仅重传那些它怀疑在接收方出错（即丢失或受损）的分组而避免不必要的重传。 SR发送方所采取的各种动作： 从上层收到数据：当从上层收到数据时，SR发送方检测下一个可用于该分组的序号，如果序号在发送方的窗口内，则将数据打包并发送，否则像GBN一样，要么返回上层要么缓冲起来。 超时：定时器再次被用来防止超时，不过对于每个分组必须用于自己的逻辑定时器。因为超时后只能发送一个分组。 收到ACK。如果收到ACK，且该分组在窗口内，则SR发送方将那个被确定的分组标记为已接收。如果该分组等于send_base，则窗口基序号向前移动到具有最小序号的未确定分组处。如果窗口移动了，并且有序号落在窗口内的未发送分组，则发送该分组。 SR接收方所采取的各种动作： 序号在[rcv_base, rcv_base+N-1]内的分组被正确接收。此时，收到的窗口落在接收方的窗口内，一个选择ACK分组被回送给发送方。如果该分组是以前没有收到的分组，则被缓存。如果该分组序号等于接收窗口的基序号rcv_base，则该分组以及以前缓冲的序号连续的分组（起始于rcv_base）交付给上层。然后，接收窗口按向上交付的分组数量向前移动。 序号在[rcv_base-N, rev_base-1]内的数据被正确接收到。此时说明之前对该序号分组的ACK未被发生方正确接收，此时必须产生一个ACK信号。 其他情况，忽略该分组。 上图展示了一个SR的实例。 对SR协议来说，发送方与接收方的窗口并不总是一致。当我们面对有限序号实现时，不同步的窗口将会导致严重后果。如，对于一个有4个分组序号0,1,2,3的有限范围且窗口长度为3，假定发送了分组0到2，接收方也正确接收了它们。此时接收窗口落到了4,5,6个分组上，其序号为3,0,1。此时考虑两种情况，情况1如下图a，对前三个分组的ACK丢失，发送方要重传这些分组，因此接收方下一步要接收序号0的分组，即第一个发送分组的拷贝。第二种情况如下图b所示，前三个分组被正确交付，因此发送方向前移动窗口并发送4,5,6个分组，其序号是3,0,1。序号3的分组丢失，但序号0的分组到达。 上述两种情况对于接收者来说是无法分辨的。显然窗口大小是有限制的，实际窗口长度必须小于或等于序号空间大小的一半。 下表展示了可靠数据传输机制及其用途的总结： 机制 用途和说明 检验和 用于检测在一个传输分组的比特错误。 定时器 用于检测超时/重传一个分组，可能由于该分组（或其ACK）丢失，可能传输超时。 序号 用于从发送方流向接收方的数据分组按序排号。所接收分组的序号间的空隙可使该接收方检测出丢失的分组。具有相同序号的分组可使接收方检测出一个分组的冗余拷贝。 确认 接收方用于告知发送方一个分组或一组分组已经被正确地接收到。 否定确认 接收方用于告知发送方某个分组未被正确接收。 窗口、流水线 发送方也许被限制仅发送那些序号落在一个限定范围内的分组。通过允许一次发送多个分组但未被确认，发送方的利用率可在停等等操作模式的基础上增加。 面向连接的运算：TCPTCP连接TCP是面向连接的（connection-oriented），在进程间可以开始与另一个进程发送数据之前，这两个进程必须先相互“握手”，即互相发送预备字段，以建立确保数据传输的参数。作为TCP连接建立的一部分，连接的双方都会初始化与TCP连接相关的许多TCP状态变量。 TCP协议只在端系统中运行，而不会在中间的网络元素（路由器和链路层交换机）中运行，所以网络元素不会维持TCP连接状态。 TCP是全双工服务，也是点对点服务。在三次握手中，前两次不能存在有效载荷，第三次可以。 对于发送方，TCP将数据引导到连接的发送缓存里，发送缓存是三次握手初期设置的缓存之一。TCP可以从缓存中取出并放入报文段中的数据数量受限于最大报文长度（Maximum Segment Size，MSS）。MSS通常根据最初确定的最大链路层长度（最大传输单元（MTU））来设置。设置该MSS要保证一个TCP报文段加上TCP/IP首部长度将适合单个链路层帧。 TCP为每块数据配上一个TCP首部，从而形成TCP报文段。这些报文段传输给网络层，网络层将其分别封装进网络层IP数据报中。然后这些IP数据报被发送到网络中。当TCP在另一端接收到一个报文段后，该报文段的数据就被放入该TCP连接的缓存中。 TCP报文段结构 当TCP发送大文件时，通常是将该文件划分为长度为MSS的若干块。报文中除了包含源端口、目的端口、校验和等与UDP一致的，还包含部分其他数据： 32比特的序号字段（sequence number）和32比特的确认字段（acknowledgment number）。提供可靠数据传输。 16比特的接收窗口字段，用于流量控制。 4比特的首部长度字段，指示了以32比特的字为单位的TCP首部长度。 可选与变长的可选字段（options），该字段用于发送方与接收方协商最大报文长度（MSS）时，或在高速网络下用作窗口调节因子。 6比特标志字段。ACK比特用于指示确认字段中的值是有效的，即该报文段包括一个对已被成功接收报文段的确认。RST、SYN和FIN用于连接建立和拆除。当PSH比特被设置时，指示接收方应该立即将数据交付给上层。URG比特用来指示报文段中存放着被发送端实体置为紧急的数据。当紧急数据存在并给出指向紧急数据尾的指针的时候，TCP必须通知接收端的上层实体。（实践中PSH、URG和紧急数据指针并没有使用）。 序号和确认号TCP把数据看成一个无结构的、有序的字节流，序号建立在传送的字节流之上，而不是建立在传送的报文段的序列上。一个报文段的序列号是该报文段首字节的字节流编号。 TCP是双全工的，因此A向B传送的同时，也许同时接收B的数据（同一条TCP连接）。主机A填充进报文段的确认号是主机A期望从主机B收到的下一字节的序号，即可以看做当前A已经接收到的字节数减1，相当于在告诉B当前A已经确认接收到的数据。（这里说确认接收的数据和已经收到的数据其实不是很准确，因为不一定是从0开始的，而是按照一定方式就初始化开始的）。 同时对于确认号来说，由于TCP是流水线传输，所以对于已经确认接收到的数据来说，可能中间部分没有收到，其前面的分组和后面都收到了，此时确认号是该流中至第一个丢失字节为止的字节，所以TCP被称为提供累积确认（cunulative acknowledgment）。对于失序到达的后面的数据，TCP也不会丢弃，而是缓冲下来。 这里序号和确认号分别对于与发送方和接收方的序号，从初始化序号即可看出来。一条TCP连接的双方均可以随机选择初始序列号(目的是减少将那些人在网络中存在的来自两台主机之间先前已经终止的连接的报文段、误认为是这两台主机之间新建立连接所产生的有效报文段的可能性（可能碰巧与就连接使用相同的端口号）)。例如A初始序号为a，B初始序号为b，此时相当于B已经接收了a-1个数据，A已经接收了b-1个数据，因此A接下来要接收的数据是b，B接下来要接收的数据为a，因此A的确认号为b，B的确认号为a。 如下例： 上图中A的序号是42，B的序号是79。 注意：对于发送方来说，发送完成后就要等待接收确认，对于接收方来说，接收到之后，即使自己没有要向发送方传递任何数据，也要发送一个确认报文。如上图的第三天报文。 往返时间的估计与超时与rdt3.0一样，TCP也使用超时/重传机制来处理报文段的丢失问题。 估计往返时间报文段样本RTT（表示为sampleRTT）就是从某报文段被发出到对该报文段被确认收到（收到ACK确认）之间的时间。大多数TCP实现仅在某个时刻做一次sampleRTT测量，而不是为每个发送的报文测量一个sampleRTT。即任意时刻，仅为一个已发送但目前尚未被确认的报文段估计sampleRTT，从而产生一个接近每个RTT的新sampleRTT值。另外，TCP绝不为已被重传的报文段计算sampleRTT。 显然，sampleRTT值是一个随时间变化的值。TCP维持一个sampleRTT均值（称为EstimatedRTT）。一但获取新sampleRTT值就更新EstimatedRTT：$$EstimatedRTT = (1-\alpha)*EstimatedRTT + \alpha *SampleRTT$$$\alpha$一般取0.125。 EstimatedRTT是一个sampleRTT的加权平均值，且越接近当前的采样，权重越大。 除了定义估算RTT外，测量RTT的变化也是有价值的。RTT偏差DevRTT，用于估算sampleRTT一般会偏离EstimatedRTT的程度：$$DevRTT = (1-\beta) * DevRTT + \beta *|sampleRTT - EstimatedRTT|$$$\beta$一般取0.25。 设置和管理重传超时间隔超时间隔应该大于等于EstimatedRTT，否则会造成不必要的重传。超时间隔也不能大太多，否则当报文丢失时，TCP不能很快重传该报文，导致数据传输时延大。于是TCP超时间隔设置为：$$TimeoutInterval = EstimatedRTT + 4 * DevRTT$$ 可靠数据传输TCP可靠传输服务确保一个进程从其接收缓存中读出的数据流是无损的、无间隔的、非冗余和按序的数据流。 前面我们在SR中讲到的方法是使每一个报文和一个定时器关联，但定时器花销是是否大的，因此推荐的定时器管理是仅使用单一的定时器。 下面给出TCP发送方高度简化的描述： 1234567891011121314151617181920212223242526/假设发送方不受TCP流量和拥塞控制的限制, 来自上层的数据长度小于MSS,且数据传送只在一个方向进行. */loop(forever)&#123; switch(event) event: data recieved from application above create TCP segment with sequence number NextSeqNum if(timer currently not running) strat timer pass segment to IP NextSeqNum = NextSeqNum+length(data) break event: timer timeout retransmit not-yet-acknowledged segment with samllest sequence number start timer break event : ACK received, with ACK field value of y if(y &gt; SendBase) SendBase = y if(there are currently any not-yet-acknowledged segments) start timer break; &#125; 其中Nextseqnum被用来记录序号，SendBase是最小为被确认的字节的序号。 超时间隔加倍如前所述，TCP重传具有最小序号的还没被确认的报文段。只是每次TCP重传时都会将下一次的超时间隔设置为先前的两倍，而不是从EstimatedRTT和DevRTT推算出来的值。然而每当定时器在另外两个事件（即收到上层应用的数据和收到ACK）中任意一个启动时，TimeoutInterval由最近的EstimatedRTT值与DevRTT得到。 这种修改提供了一个形式受限的拥塞控制。 快速重传超时触发重传存在的问题是超时周期可能相对较长。发送方通常可在超时时间之前通过注意所谓的冗余ACK来较好的检测到丢包情况。冗余ACK就是再次确认某个报文段的ACK，而发送方先前已经收到对该报文段的确认。 下表总结了TCP接收方ACK的生成策略： 事件 TCP接收方动作 具有所期望的按序报文段到达，所有在期望序号以前的数据都已经被确认 延迟的ACK，对另一个按序报文段的达到最多等待500ms，如果下一个报文段在这个时间间隔内没有达到，则发送一个ACK 具有所期望序号的按序报文段到达，另一个按序报文段等待ACK传输 立即发送单个累积ACK，以确认两个按序报文段。 比期望大的失序报文段到达，检测出现间隔 立即发送冗余ACK，指示下一个期待字节的序号（其为间隔的低端序号） 能部分或完全填充数据间隔的报文段到达 倘若该报文段起始于低端，立即发送ACK 因为发送方经常发送大量报文段，如果一个报文段丢失，就可能引起许多冗余ACK。如果TCP发送方接收到对相同数据的3个冗余ACK，它把这当成一种指示，说明在这个已被确认过三次的报文段之后的报文段已经丢失。因此，一旦收到3个冗余ACK，TCP就执行快速重传，即在该报文段超时之前重传。 因此，可用下面的代码来替代之前的发送方部分代码： 12345678910111213141516event : ACK received,wite ACK field value of y if(y &gt;SendBase) &#123; SendBase = y if(there are currently any not yet acknowledged segments) start timer &#125; else&#123; /* y == SendBase, 即收到冗余ACK */ increment number of duplicate ACks received for y if(number of duplicate ACKs received for y==3) &#123; /* TCP fast retransmit */ resend segment with sequence number y &#125; &#125; TCP的差错恢复机制应该属于GBN和SR的混合体。 流量控制一条TCP连接每一测主机都为该连接设置了接收缓存。TCP提供了流量控制服务（flow-control service）以消除发送方使接收方缓存溢出的可能。该服务与拥塞控制不同。 TCP通过让发送方维护一个称为接收窗口（receive window）的变量来提供流量控制。接收窗口用于给发送方一个指示——该接收方还有多少可用的缓存空间。由于TCP是双全工通信，在连接两端的发送方都各种维护一个接收窗口。假设主机A通过一条TCP连接向主机B发送一个大文件。主机B为该连接分配一个缓存区，用RevBuffer来表示其大小。主机上的应用进程不时地从该缓存中读取数据。同时定义如下变量： LastByteRead：主机B上的应用进程从缓存读出的数据流的最后一个字节的编号。 LastByteRevd：从网络到达的并且已放入主机B接收缓存中的数据流的最后一个字节的编号。 由于TCP不允许缓存溢出，因此：$$LastByteRecv - LastByteRead &lt;= RevBuffer$$接收窗口用rwnd表示，则：$$rwnd = RevBuffer - [LastByteRevd - LastByteRead]$$rwnd是动态变化的。 主机B通过把当前rwnd值放到它发送给A的报文段接收窗口字段中，通知主机A它在该连接的缓存中还有多少可用空间。开始时，主机B设定rwnd = RevBuffer。为了实现这一点，主机B必须跟踪几个与连接有关的变量。 主机A轮流跟踪两个变量，LastByteSent和LastByteAcked。这两个变量之间的差LastByteSend - LastByteAsked就是主机A发送到连接中但未被确认的数据量。将该数量限制在rwnd内就可以保证主机A不会使主机B的接收缓存溢出。所以：$$LastByteSent - LastByteAcked &lt;= rwnd$$但该方案存在一个问题。如果B的接收缓存已经满了，使得rwnd = 0。将rend告知A之后，假设主机B上没有任何数据要发送给A。此时，主机B上的应用进程将缓存清空，TCP并不向主机A发送任何带有rwnd的新报文。这样，主机A不可能知道主机B接收空间已经有新空间了，即主机A被阻塞而不能再发送数据。为了解决这个问题，TCP要求，当主机B接收窗口为0时，主机A继续发送只有一个字节数据的报文段。这些报文段将会被接收方确认。最终缓存将开始清空，并且确认报文里将包含一个非0的rwnd值。 TCP连接管理现在来看一条TCP连接是如何建立的，假设运行在主机（客户）上的一个进程想要与另一台主机（服务器）上的进程建立一条连接。客户机会用下面方式与服务器建立连接： 第一步：客户机的TCP首先向服务器端的TCP发送一个特殊的TCP报文段。该报文不包含应用层数据。但是报文段首部中的一个标志位（SYN比特）被置1.因此这个特殊报文段被称为SYN报文段。另外，客户机会随机初始化一个初始序号（client_isn），并将该编号置于起始的TCP SYN报文段的序号段中。该报文被封装在一个IP数据报中，并发送给服务器。 第二步：一旦一个包含TCP SYN报文段的IP数据报到达服务器主机，服务器会从该数据报中提取出TCP SYN报文段，为该TCP连接分配TCP缓存和变量，并向该酷虎就TCP发送允许连接的报文段。（在完成三次握手的第三步之前分配资源，使得TCP易于受到被称为SYN洪泛的拒绝服务攻击）。这个运行连接的报文段也不包含应用层数据。但是该报文段首部包含3个重要信息。首先SYN比特被置1，其次该TCP报文段首部的确认号字段被设置为client_isn+1。最后，服务器选择自己的初始序号（server_isn)，并将其放置到TCP报文段首部的序号字段中。该报文被称为SYNACK报文段。 在收到SYNACK报文段后，客户机也要为该连接分配缓存和变量。客户机向服务器发送另一个报文段，最后一个报文段对服务器的允许连接的报文段进行了确认（将值server_isn+1放置到TCP报文段首部的确认字段中来完成此项工作）。因为连接已经建立，该SYN比特被置为0。该三次握手的第三阶段可以在报文段负载中携带客户到服务器的数据。 一旦建立连接后，就可以互相传输报文了，此时SYN都是0。 下面我们再来看TCP如何终止连接。参与连接的任何一个都可以终止该连接。当连接结束后，主机中的资源将被释放。假如某个主机打算关闭连接，如下图。客户应用进程发出一个关闭连接命令。这会使客户TCP向服务器进程发送一个特殊的TCP报文段，该报文段首部FIN标志位被设置为1。当服务器接收到该该报文段后，就向发送方返回一个确认报文段。然后服务器就发送自己的终止报文，其FIN被置为1.最后，该客户机对这个服务器的终止报文进行确认。此时，在两台主机上用于该连接的所以资源都被释放了。 下图展示了客户TCP经典的TCP状态序列： 其中在TIME_WAIT等待状态时，确定ACK丢失，TIME_WAIT状态使TCP客户重传最后的确认报文经过等待后，连接正式关闭，客户机所以资源包括端口号被释放。（等待时间取决于实现） 下图为服务器端TCP经历的典型的TCP状态序列： 拥塞控制原理拥塞原因与代价情况1：两个发送方和一台无穷大缓存的路由器最简单的拥塞情况：两台主机（A和B）都有一条连接，且这两条连接共享源与目的地之间的单跳路由。此时限制只有共享式输出链路的容量。当两个主机传输的总速度超过链路的总容量，就会导致拥塞。 情况2：两个发送方和一台具有有限缓存的路由器此时拥塞则有两部分组成，第一部分和情况1一样，两台主机所传输速度和，还有一个问题则是在有限缓存的路由器上存在丢包。丢包会加大两台主机传输速率，但造成更严重的拥塞和丢包。 情况3:4个发送方和具有有限缓存的多台路由器及多跳路径 此时对于每一条传输路径来说，都经历两段。每段都有两条路径共享，而且共享段是其中一条路径的第一段，另一条路径的第二段。此时，往往作为第一段的那条路径会被优先满足，挤占掉作为第二段路径的那条路径。而被满足的那条路径到它的第二段路径时，又会被另一条路径挤占掉（因为在它的第二段里还存一个作为第一段的路径）。最终将会导致所以路径全部拥塞。 拥塞控制方法拥塞控制主要有两种方法： 端到端拥塞控制：网络中存在拥塞，端系统必须通过对网络进行观察来推断。 网络辅助的拥塞控制：在网络辅助的拥塞控制中，网络层构建（即路由器）向发送方提供关于网络中阻塞状态的显示反馈信息。 TCP拥塞控制TCP所采取的方法是让每一个发送方根据所感知到的网络拥塞程度来限定其向连接发送的流量的速率。 首先来看TCP如何限制向其连接发送流量的。运行在发送方的TCP拥塞控制机制跟踪一个额外的变量，即拥塞控制窗口（cwnd），它对一个TCP发送方能够向网络中发送流量的速率进行了限制，特别是，一个发送方中未被确认的数据量不会超过cwnd和rwnd中的最小值：$$LastByteSent - LastByteAcked &lt;= min{cwnd, rwnd}$$为了只关注与拥塞控制，下面的讨论假设rwnd足够大，我们可以忽略该值。因此，发送方发送速率大概是cwnd/RTT 字节/秒。通过调节cwnd值，我们可以调节其发送速率。 下面考虑TCP发送方如何感知它与目的地之间的路径上出现了拥塞。我们将一个TCP发送方的“丢包事件”定义为：要么出现超时，要么收到来自接收方的3个冗余ACK。 接下来考虑网络没有拥塞的情况，即没有出现丢包时间的情况。此时，TCP的发送方将收到对于以前未确认报文段的确认。TCP将这些确认到达作为一切正常的指示，并用来增加窗口的长度。因为TCP使用确认来触发（或计时）增大它的拥塞窗口长度，TCP被说成是自计时的。 TCP对各个事件的指导性原则是： 一个丢失的报文段意味着拥塞，因此丢失报文段时应该降低TCP发送方的速率。一个超时事件或者四个确认（一个初始ACK和三个冗余ACK）被解释为“丢包事件”的一种隐含的指示。 一个确认报文段指示该网络正在向接收方交付发送方的报文段，因此，当对先前未确认报文段的确认到达时，能够增加发送方的速率。 带宽探测：给定ACK指示源到目的地路径无拥塞，而丢包事件指示路径拥塞，TCP调节其传输速率的策略是增加其速率以响应到达的ACK，除非出现丢包事件，此时才减小传输速度。因为，为探测拥塞开始的速率，TCP发送方增加它的传输速率，从该速率后退，进而再次探测，可靠拥塞开始速率是否发送了变化。 TCP拥塞控制算法包括三部分：慢启动；拥塞避免；快速恢复。 慢启动当一条TCP连接开始时，cwnd通常设置为一个MSS的较小值，TCP希望迅速找到可用带宽的数量。在慢启动状态，cwnd的值以1个MSS开始并且每当传输的报文段首次被确认就增加一个MSS。如下图所示，每过一个RTT，发送速率就翻倍，TCP发送速率起始慢，但在慢启动阶段以指数增长， 慢启动结束的条件有多种。首先，如果存在一个由超时指示的丢包（即拥塞），TCP发送方将cwnd设置为1并重新开始慢启动过程。它还将第二个状态变量的值ssthresh（慢启动阈值）设置为cwnd/2，即当检测到拥塞时，将ssthresh置为拥塞窗口值的一半。慢启动的第二种方式是直接与ssthresh值相关联。因为当检测到拥塞时ssthresh设为cwnd的一半，当cwnd等于ssthresh值时，结束慢启动并将TCP转移到拥塞避免模式。最后一种方式是，如果检测到3个冗余ACK，TCP执行快速重传并进入快速恢复状态。 拥塞避免一旦进入拥塞避免，cwnd值大约是上次遇到拥塞时值的一半。此时采取比较保守的方法，每个RTT只将cwnd值加一（慢启动成倍）。通用方法是对于TCP发送方无论何时到达一个新的确认，就将cwnd增加一个MSS（MSS/cwnd）字节。例如，MSS是1460字节，cwnd是14600字节，则在一个RTT内发送10个报文。每个到达ACK增加1/10MSS的拥塞长度，这样在收到10个报文后，拥塞窗口就增加了一个MSS。 结束拥塞避免的线性增长时机为：当出现超时时，TCP的拥塞避免算法行为与慢启动情况一致，cwnd被设置为1MSS。当出现3个冗余ACK事件时，网络继续从发送方向接收方交付报文段，因此TCP对这种丢包事件的行为，相比于超时指示的丢包应当不那么剧烈，此时TCP将cwnd的值减半，并且将ssthresh的值记录为cwnd的值的一半。接下来进入快速恢复状态。 快速恢复在快速恢复中，对于引起TCP进入快速恢复状态的缺失报文段，对收到的每个冗余的ACK，cwnd的值增加一个MSS。最终，当对丢失报文段的一个ACK到达时，TCP进入拥塞避免状态。如果出现超时事件，快速恢复再执行如图在慢启动和拥塞避免中相同的动作，迁移到慢启动状态。 下图展示了TCP的FSM： TCP拥塞控制常常被错误加性增、乘性减（AIMD）。 TCP吞吐量公式，该公式作为丢包率L、往返时间RTT和最大报文段长度MSS的函数：$$一条连接的平均吞吐量 = \frac{1.22*MSS}{RTT\sqrt{L}}$$]]></content>
      <categories>
        <category>-计算机基础知识</category>
      </categories>
      <tags>
        <tag>-网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[learnlinux]]></title>
    <url>%2Flearnlinux.html</url>
    <content type="text"><![CDATA[linux注意事项 严格区分大小写（命令、文件名等） Linux中所有内容以文件形式保存，包括硬件 硬件文件是/dev/sd[a-p] 光盘文件是/dev/sr0等 Linux不靠扩展名区分文件类型（靠的是文件权限） 压缩包：”*.gz“、”*.bz2“、”*.tar.bz2“等 二进制包：”rpm“等 网页文件：”*.html“ 脚本文件：”*.sh” 配置文件：“*.conf” 但是这些扩展名是给管理员看的，其实并不需要。主要是便于识别，非必须。 Linux所有的存储设备都必须挂载，只有用户才能使用，包括硬盘、U盘和光盘 Windows下的程序不能直接在Linux中安装和运行 服务器注意事项： 远程服务器不允许关机，只能重启 重启时应该关闭服务 不要在服务器访问高峰运行高负载命令 远程配置防火墙不要把自己踢出服务器 制定合理的密码规范并定期更新 合理分配权限 定期备份重要数据和日志 Linux各个目录的作用 /bin/ 存放系统命令的目录，普通用户和超级用户都可以执行. 不过放在/bin下的命令在单用户模式下也可以执行 。 /sbin/ 保存和系统环境设置相关的命令，只有超级用户可以使用这些命令进行系统环境设置，但是有些命令可以允许普通用户查看。 /usr/bin/ 存放系统命令的目录，普通用户和超级用户都可以执行。这些命令和系统无关，在单用户模式下不能执行。 /usr/sbin/ 存放根文件系统不必要的系统管理命令，例如多数服务程序。只有超级用户可以使用。 /boot/ 系统启动目录，保存系统启动相关文件。如内核文件和启动引导程序。 /dev/ 设备文件保存位置。 /etc/ 配置文件保存位置。系统内所有采用默认安装(rpm安装)的服务的配置文件全部都保存在这个目录当中。如用户的账号和密码，服务的启动脚本。常用服务的配置文件等。 /home/ 普通用户的家目录。建立每个用户时，每个用户要有一个默认的登录位置，这个位置就是这个用户的家目录。所有普通用户的家目录就是在/home下建立一个和用户名相同的目录。如user1的家目录就是/home/user1 /lib/ 系统调用的函数库保存位置 /lost+found/ 当系统意外崩溃或意外关机，而产生一些文件碎片放在这里。当系统启动的过程中fsck工具会检查这里，并修复已损坏的文件系统。这个目录只在每个分区中出现，例如/lost+found 就是根分区的备份恢复录，/boot/lost+found 就是/boot分区的备份恢复目录。 /media/ 挂载目录，系统建议是用来挂载媒体设备的，例如软盘和光盘。 /mnt/ 挂载目录，早期linux中只有这一个挂载目录，并没有细分，现在这个目录系统建议挂载额外设备，例如U盘，移动硬盘和其他操作系统的分区 /misc/ 挂载目录， 系统建议用来挂载NFS服务的共享目录。 /opt/ 第三方安装的软件保存位置。 这个目录就是放置和安装其他软件的位置。现在行业习惯是安装在在usr/local/目录中。 /proc/ 虚拟文件系统，该目录中的数据并不保存到硬盘当中，而是保存到内存当中。 主要保存系统的内核，进程。外部设备状态和网络状态灯。如/proc/cpuinfo 是保存cpu信息的，/proc/devices是保存设备驱动的列表的，/proc/filesystems是保存文件系统列表的， /proc/net是保存网络协议信息的。注意不要往里面写东西。 /sys/ 虚拟文件系统，和/proc目录相似，都是保存在内存当中的，主要是保存于内核相关信息的。 /root/ 超级用户的家目录，普通用户家目录在”/home”下，超级用户家目录直接在 “/”下。 /srv/ 服务数据目录.一些系统服务启动之后，可以在这个目录中保存所需要的数据。 /tmp/ 临时目录，系统存在临时文件的目录. 该目录下所有用户都可以访问和写入，建议此目录中不能存放重要数据，最好每次开机都可以把该目录清空 /usr/ 系统软件资源目录，”unix softwre resource”的缩写，存在系统软件资源的目录。系统中安装的软件大多数保存在这里。 /var/ 动态数据保存位置，主要保存缓存，日志已经软件运行所产生的文件。 Linux常用命令文件处理命令命令格式与目录处理命令ls 命令格式：命令 [-选项] [参数]例 : ls -la /etc 说明: 个别命令使用不遵循此格式 当有多个选项时,可以写在一起 简化选项与完整选项-a 等于 –all 目录处理命令 命令名称: ls 命令英文原意: list 命令所在路径: /bin/ls 执行权限: 所有用户 功能描述: 显示目录文件 语法: ls 选项[-ald] [文件或目录] -a 显示所有文件,包括隐藏文件 -l 详细信息显示 -d 查看目录属性 -rw-r–r– - 文件类型(- 文件 d 目录 l 软链接文件)rw- r– r–u g ou所有者 g所属组 o其他人r读 w写 x执行 目录处理命令mkdir 命令名称:mkdir 命令英文原意:make directories 命令所在路径:/bin/mkdir 执行权限:所有用户 语法:mkdir -p [目录名] 功能描述:创建新目录 -p 递归创建 范例: $ mkdir -p /tmp/Japan/boduo$ mkdir /tmp/Japan/longze /tmp/Japan/cangjing cd 命令名称:cd 命令英文原意:change directory 命令所在路径:shell内置命令 执行权限:所有用户 语法:cd [目录] 功能描述:切换目录 范例: $ cd /tmp/Japan/boduo 切换到指定目录 ​ $cd .. 回到上一级目录 ​ $cd ../.. 回到上上一次所在目录 ​ $cd - 返回上两级目录 pwd 命令名称:pwd 命令英文原意:print working directory 命令所在路径:/bin/pwd 执行权限:所有用户 语法:pwd 功能描述:显示当前目录 范例: $ pwd 显示当前目录 rmdir 命令名称:rmdir 命令英文原意:remove empty directories 命令所在路径:/bin/rmdir 执行权限:所有用户 语法:rmdir [目录名] 功能描述: 删除空目录 范例: $ rmdir /tmp/linux/test cp 命令名称: cp 命令英文原意: copy 命令所在路径: /bin/cp 执行权限: 所有用户 语法: cp -rp [原文件或目录] [目标目录] ​ -r 递归复制目录及内部的所有内容 ​ -p 保留文件属性 ​ -f 强制 ​ -i 目标文件以存在，则在覆盖前询问是否覆盖 ​ -u 若源文件比目标文件新，则覆盖，否则跳过 功能描述:复制文件或目录 mv 命令名称:mv 命令英文原意:move 命令所在路径:/bin/mv 执行权限:所有用户 语法:mv [原文件或目录] [目标目录] 功能描述:剪切文件、改名 rm 命令名称:rm 命令英文原意:remove 命令所在路径:/bin/rm 执行权限:所有用户 语法: rm -rf [文件或目录] ​ -r 删除目录 ​ -f 强制执行 功能描述:删除文件 文件处理命令touch 创建空文件 1touch file_name cat 语法: cat [文件名] 功能描述: 显示文件内容 ​ -n 显示行号 tac 语法:tac [文件名] 功能描述:显示文件内容(反向列示) more 语法:more [文件名] ​ (空格) 或f 翻页​ (Enter) 换行​ q或Q 退出 功能描述:分页显示文件内容 less 语法:less [文件名] 功能描述:分页显示文件内容(可向上翻页) head 语法:head [文件名] 功能描述:显示文件前面几行-n 指定行数 tail 语法:tail [文件名] 功能描述:显示文件后面几行 -n 指定行数 -f 动态显示文件末尾内容 12tail -n 100 /etc/cron #显示最后100行数据tail -n -100 /etc/cron #除了前99行不显示外，显示第100行到末尾行 链接命令ln 语法:ln -s [原文件] [目标文件]-s 创建软链接 功能描述:生成链接文件 1234$ ln -s /etc/issue /tmp/issue.soft 创建文件/etc/issue的软链接/tmp/issue.soft$ ln /etc/issue /tmp/issue.hard 创建文件/etc/issue的硬链接/tmp/issue.hard 软链接特征:类似Windows快捷方式1、lrwxrwxrwx l 软链接软链接文件权限都为rwxrwxrwx2、文件大小-只是符号链接3、/tmp/issue.soft -&gt; /etc/issue箭头指向原文件 硬链接特征:1、拷贝cp -p + 同步更新echo &quot;this is a test&quot; &gt;&gt; /etc/motd2、可通过i节点识别3、不能跨分区4、不能针对目录使用 权限管理命令chmod 语法:chmod [{ugoa}{+-=}{rwx}] [文件或目录] [mode=421 ] [文件或目录] -R 递归修改 u 表示该文件的拥有者，g 表示与该文件的拥有者属于同一个群体(group)者，o 表示其他以外的人，a 表示这三者皆是。 表示增加权限、- 表示取消权限、= 表示唯一设定权限。 r 表示可读取，w 表示可写入，x 表示可执行，X 表示只有当该文件是个子目录或者该文件已经被设定过为可执行。 功能描述:改变文件或目录权限 将目前目录下的所有文件与子目录皆设为任何人可读取 : 1chmod -R a+r * 1chmod pqn file 其中p,q,n各为一个数字，分别表示User、Group、及Other的权限。 r=4，w=2，x=1 若要rwx属性则4+2+1=7； 若要rw-属性则4+2=6； 若要r-x属性则4+1=5。 1chmod a=rwx file 和 1chmod 777 file 效果相同 1chmod ug=rwx,o=x file 和 1chmod 771 file 效果相同 其他权限管理命令chown 语法:chown [用户] [文件或目录] 功能描述:改变文件或目录的所有者 范例:$ chown usr_1 file_1 改变文件file_1的所有者为usr_1 chgrp 语法:chgrp [用户组] [文件或目录] 功能描述:改变文件或目录的所属组 范例:$ chgrp lampbrother file_1改变文件file_1的所属组为lampbrother umask 语法:umask [-S] ​ -S 以rwx形式显示新建文件缺省权限 功能描述:显示、设置文件的缺省权限 范例: $ umask -S 文件搜索命令find 功能描述:文件搜索 语法: 1$ find path -option 【 -print 】 【 -exec -ok |xargs |grep 】 【 command &#123;&#125; \; 】 path：要查找的目录路径。 ~ 表示$HOME目录 ​ . 表示当前目录 ​ / 表示根目录 -exec 对搜索到的文件执行特定的操作，固定的格式为：-exec &#39;commond&#39; {} \; 注意：{} 表示查询的结果。 举例1: 搜索 /etc 目录下的文件（非目录），文件以 conf 结尾，且大于 10k，然后将其删除。 1find /etc -type f -name &apos;*.conf&apos; -size +10k -exec rm -f &#123;&#125; \ ok：与exec作用相同， 区别在于，在执行命令之前，都会给出提示，让用户确认是否执行 |xargs 与exec作用相同 ，起承接作用 区别在于 |xargs 主要用于承接删除操作 ，而 -exec 都可用 如复制、移动、重命名等 1234567891011121314151617181920212223242526272829-name filename #查找名为filename的文件-iname filename #不区分大小写-user user_1 #查找文件所属用户为user_1的所有文件-group group_1 #查找文件所属组为group_1的所有文件-type 根据类型查找：如下 f 文件 find . -type f d 目录 find . -type d c 字符设备文件 find . -type c b 块设备文件 find . -type b l 链接文件 find . -type l p 管道文件 find . -type p-size 根据文件大小查询 -n 小于 大小为 n 的文件 +n 大于 大小为 n 的文件-mtime -n n 天以内修改的文件。 +n n 天以外修改的文件。 n 正好 n天 修改的文件-mmin -n n 分钟以内修改过的文件 +n n 分钟之前修改过的文件-perm #按执行权限来查找-mindepth n 从第 n 级目录开始搜索-maxdepth n 表示至多搜索到第 n-1 级子目录。#逻辑运算符 -a 与 （默认情况查询条件之间都是 与 的关系）-o 或-not | ！ 非 其他搜索命令locate 语法:locate 文件名 功能描述: 在文件资料库中查找文件 which 语法:which 命令 功能描述:搜索命令所在目录及别名信息 范例: $ which ls whereis 语法:whereis [命令名称] 功能描述:搜索命令所在目录及帮助文档路径 范例:$ whereis ls grep 语法:grep -iv [指定字串] [文件] 功能描述:在文件中搜寻字串匹配的行并输出 ​ -i 不区分大小写 ​ -v 排除指定字串 范例:# grep mysql /root/install.log 帮助命令man 语法:man [命令或配置文件] 功能描述:获得帮助信息 范例: $ man ls 查看ls命令的帮助信息\$ man services 查看配置文件services的帮助信息 help 语法:help 命令 功能描述:获得Shell内置命令的帮助信息 范例: $ help umask 查看umask命令的帮助信息 用户管理命令useradd 执行权限:root 语法:useradd 用户名 功能描述:添加新用户 范例: $ useradd finyorko passwd 执行权限:所有用户 语法:passwd 用户名 功能描述:设置用户密码 范例: $ passwd finyorko who 执行权限:所有用户 语法:who 功能描述:查看登录用户信息 范例: $ who w 执行权限:所有用户 语法:w 功能描述:查看登录用户详细信息 范例: $ w 压缩解压命令gzip压缩 语法: gzip [文件] 功能描述: 压缩文件 压缩后文件格式: .gz gunzip解压 语法:gunzip [压缩文件] 功能描述:解压缩.gz的压缩文件 范例: $ gunzip boduo.gz tar压缩 语法:tar 选项[-zcf] [压缩后文件名] [目录]-c 打包 -v 显示详细信息 -f 指定文件名 -z 打包同时压缩 功能描述:打包目录 压缩后文件格式: .tar.gz 范例: $ tar -zcf Japan.tar.gz Japan将目录Japan打包并压缩为Japan.tar.gz文件 tar解压 tar命令解压缩语法:-x 解包-v 显示详细信息-f 指定解压文件-z 解压缩-C 指定需要解压到的目录 -r：向压缩归档文件末尾追加文件-u：更新原压缩包中的文件 范例:$ tar -zxvf Japan.tar.gz zip压缩 语法: zip 选项[-r] [压缩后文件名] [文件或目录] -r 压缩目录 功能描述:压缩文件或目录 压缩后文件格式:.zip 范例:$ zip buduo.zip boduo 压缩文件​$ zip -r Japan.zip Japan 压缩目录 unzip解压 语法:unzip [压缩文件] 功能描述:解压.zip的压缩文件 范例:$ unzip test.zip bzip2压缩 语法: bzip2 选项 [-k] [文件]-k 产生压缩文件后保留原文件 功能描述:压缩文件 压缩后文件格式: .bz2 范例: $ bzip2 -k boduo​ $ tar -cjf Japan.tar.bz2 Japan bunzip解压 语法: bunzip2 选项 [-k] [压缩文件]-k 解压缩后保留原文件 功能描述:解压缩 范例: $ bunzip2 -k boduo.bz2\$ tar -xjf Japan.tar.bz2 网络命令write 语法:write &lt;用户名&gt; 功能描述:给用户发信息,以Ctrl+D保存结束 范例: # write finyorko wall 命令英文原意:write all 执行权限:所有用户 语法:wall [message] 功能描述:发广播信息 范例: # wall Finyorko is a honest man! ping 语法:ping 选项 IP地址-c 指定发送次数 功能描述:测试网络连通性 范例: # ping 192.168.1.156 ifconfig 命令英文原意:interface configure 执行权限:root 语法:ifconfig 网卡名称 IP地址 功能描述:查看和设置网卡信息 范例: # ifconfig eth0 192.168.8.250 mail 语法:mail [用户名] 功能描述:查看发送电子邮件 范例:# mail root last 语法:last 功能描述:列出目前与过去登入系统的用户信息 lastlog 语法:lastlog 功能描述:检查某特定用户上次登录的时间 范例 : $ lastlog\$ lastlog -u 502 traceroute 语法:traceroute 功能描述:显示数据包到主机间的路径 范例:# traceroute www.lampbrother.net netstat 语法:netstat [选项] 功能描述:显示网络相关信息 选项:-t : TCP协议-u : UDP协议-l : 监听-r : 路由-n : 显示IP地址和端口号 范例: #netstat -tlun 查看本机监听的端口 #netstat -an 查看本机所有的网络连接 #netstat -rn 查看本机路由表 setup 语法:setup 功能描述:配置网络 范例:# setup mount mount [-t 文件系统] 设备文件名 挂载点 范例:# mount -t iso9660 /dev/sr0 /mnt/cdrom 关机重启命令shutdown shutdown [选项] 时间 选项:-c: 取消前一个关机命令-h: 关机-r: 重启 其他关机命令halt poweroff init 0 其他重启命令reboot init 6 系统运行级别 0 关机 1 单用户 2 不完全多用户,不含NFS服务 3 完全多用户 4 未分配 5 图形界面 6 重启 修改默认系统运行级别 #cat /etc/inittab 查询系统运行级别 #runlevel 退出登录命令# logout 文本编辑器VimVim常用操作插入命令 命令 作用 a 在光标所在字符后插入 A 在光标所在行尾插入 i 在光标所在字符前插入 I 在光标所在行行首插入 o 在光标下插入新行 O 在光标上插入新行 定位命令 命令 作用 : set nu 设置行号 : set nonu 取消行号 gg 到第一行 G 到最后一行 nG 到第n行 n&lt;space&gt; n表示数字, 按下数字而后按空格(不用同时, 先后顺序), 光标会右移n格. n&lt;enter&gt; n为数字, 输入数字再按回车, 光标向下移n行. : n 到第n行 $ 移至行尾 0 移至行首 Ctrl + f 屏幕向下翻动一页, 相当于Page Down按键 Ctrl + b 屏幕向上翻动一页, 相当于Page Up按键 删除复制和粘贴命令 命令 作用 x/X 在当前刚标处进行删除操作. x为向后删除(删除光标所在字符), X为向前删除(删除光标所在前一个字符). n x/X n为数字, 删除规则与上述一致, 不过删除数量为n D 删除光标所在处到行尾内容 :n1,n2d 删除指定范围的行 dd 删除/剪切光标所在整行. ndd 删除/剪切光标所在向下n行(包括光标所在行总共n行). d1G 删除光标所在到第一行所以数据.(包括光标行) dG 删除光标所在到最后一行所以数据.(包括光标行) d$ 删除光标所在到该行最后一个字符(包括光标所在字符) d0 删除光标所在到该行第一个字符.(不包括光标所在) yy 复制光标所在行. nyy 复制光标所在向下n行. (包括该行) y1G 复制光标所在到第一行所以数据.(包括光标行) yG 复制光标所在到最后一行所以数据.(包括光标行) y0 复制光标所在到该行第一个字符.(不包括光标所在) y$ 复制光标所在到该行最后一个字符(包括光标所在字符) p/P p为将复制内容粘贴到光标所在的下一行. P为将复制内容粘贴到光标所在上一行. J 将光标所在行与下一行的数据结合成为一行. u 恢复前一个动作. 撤销. Ctrl + r 重复上一个动作. . 重复上一个动作. :n1, n2 co n3 将n1与n2行之间的内容复制到第n3行(之后). :n1, n2 m n3 将n1与n2行之间的内容剪切到第n3行(之后). 替换和取消命令 命令 作用 r 取代光标所在处字符 R 从光标所在处开始替换字符,按Esc结束 u 取消上一步操作 搜索和搜索替换命令 命令 作用 /word 从光标所在之下搜索word字符串搜索时忽略大小写 :set ic ?word 从光标所在之上搜索word字符串 n 重复前一个搜索动作. 对于/word即为向下查找匹配. ?word为向上查找匹配. N 与n相反 :n1, n2s/word1/word2/g 在n1到n2之间查找word1, 并将其替换为word2. :1,$s/word1/word2/g 在全文查找word1替换成word2 :1,$s/word1/word2/gc 在全文查找word1替换成word2并在替换前向用户确定. :s/world1/word2 将光标所在行的第一个word1替换成word2 :s/word1/word2/g 将光标所在整行的word1换成word2 搜索后找到的字符串会被高亮显示, 恢复的方式为:noh即可. 保存和退出命令 命令 作用 :w 保存修改 :w! 强制保存(是否真正能够保存取决于用户权限) :w new_filename 另存为指定文件 :n1, n2, w filename 将n1到n2之间内容另存为 :r filename 打开文档将打开的文档内容添加到当前光标所在行后. :wq 保存修改并退出 ZZ 快捷键,保存修改并退出 :q 退出 :q! 不保存修改退出 :wq 保存并退出 :wq! 保存并退出(文件所有者及root可使用) :set nu 设置显示行号 :set nonu 设置取消行号 vim暂存机制很多编辑软件都有恢复功能 ，即当系统因为某些原因而导致编辑中的文件突然退出．可以通过暂存的文件进行恢复．vim当然也存在这样一个机制．当我们使用vim打开一个文件时，在文件所在目录会自动创建一个.filename.swap文件．对原文件的操作会被记录在其中．当突然退出时，.filename.swap文件会帮我们存储下对文件的修改．当我们再次打开是可以选择是否通过该文件恢复对原文件的修改． 注意：当vim默认设置文件中存在如下字段时就不会有暂存机制． 1set noswapfile 配置文件一般在~/.vimrc． 暂存机制主要适用于两种情况． 在编辑文件过程中vim意外终止(在打开文件时.filename.swap文件已经被自动创建, 当正常退出时会自动删除). 多人编辑同一个文件.(在你之前有人已经打开了该文件正在编辑.) 当存在暂存文件已经存在而你右对原文件进行操作而异常退出时会生成第二个暂存文件, 以此类推. 当暂存文件存在时打开文件就会提示响应的操作,解释如下: [O]pen Read-Only 只读模式打开. [E]dit anyway 正常方式打开, 不载入暂存文件. [R]ecover 加载暂存文件. 不过不会自动删除, 完成后需要自己删除. [Q]uit 退出 [D]elete it 不载入暂存文件直接将暂存文件删除 A(bout) 类似与退出. 在较新版本的vim中该功能似乎以及取消了(默认set noswapfile), 通过实验发现确实存在一些问题.所以尽量不要使用为好. vim高级操作vim区块选择区块选择用来操作一个区域. 下面是区块选择键含义. v 进行区块选择, 按照进过字符选择. 即按v后,操作光标移动, 将会将移动范围内的内容反白标注选中. V 与上面一个类似, 不过是按照行来选取. Ctrl+v 区块选则, 按照长方形区域选取.即按下Ctrl+v的位置为一个顶点,操纵光标选择第二个顶点. 选择这两个顶点之间的区域. 需要注意的是, 如果复制矩形区域进行粘贴操纵, 赞帖也是按照矩形区域进行的. y 复制选中区域 d 复制选中区域 区块选则在实际编程操作中使用是否有用. 区块选择后也可以进入编辑模式进行编辑, 例如将多行代码注释掉(或相反操作)只需要将对于的区块选择, 按I进入插入模式, 添加注释, 按Esc退出即可. 过程中按下Esc会过一会儿才出现, 别着急(一般第一行直接出现). 多档案编辑我们可以一次打开多个文件进行一起操作. 实现分别打开无法完成的操作,如将一个文件的一部分复制到另一个文件中. 打开多文件方式为vim后面接多个文件名. 例: 1$ vim file1 file2 多文档编辑操作: :n 编辑下一个文件 :N 编辑上一个文件 :files 列出当前vim开启的所以文件. 多窗口编辑上面的操作需要使用指令进行切换而且无法同时查看两个文件, 这对于编程时是十分不方便的, 要能够保存上面多文档的便捷和查看多文件的舒适多窗口才是王道. 多窗口操作: :sp filename 开启一个新的窗口, 如果参数filename则在新窗口打开对于文件,否则打开当前文件. [Ctrl]+w+j/下箭头 按键操作是先[Ctrl]+w, 而后松开按第三个键. 切换到下一个窗口中. [Ctrl]+w+k/上箭头 切换到上一个窗口中. [Ctrl]+w+q 退出当前窗口. 可以按照这个操作,也可以直接在当前窗口:q 操作目录 :Ex 在当前窗口开启目录浏览器. :Sex 新打开一个窗口开启目录浏览器. Linux软件安装编译安装方式(小贴士:使用编译安装前,需要先建立编译环境,使用以下命令建立基本的编译环境:sudo apt-get install build-essential)在 linux 的世界,有很多软件只提供了源代码给你,需要你自己进行编译安装,一般开源的软件都会使用 tar.gz 压缩档来进行发布,当然也有其他的形式。拿到源代码的压缩文档把它解压到/tmp 目录下,进入/tmp/软件目录,然后执行以下三个命令: 1）解压tar.gz包 1tar -zxvf nginx-1.8.1.tar.gz -C /home/Desktop # 将软件包名.tar.gz解压到指定的目录下 2）进入解压后的文件目录下 执行“./configure”命令为编译做好准备； 12cd nginxsudo ./configure --prefix=/opt/nginx # 表示安装到/opt目录下 3）执行“make”命令进行软件编译； 4）执行“make install”完成安装； 5）执行“make clean”删除安装时产生的临时文件。 在 ./configure 时可能会提示说有某某软件找不到,例如提示“ libgnome”这个开发包找不到,那就把 libgnome 这个关键词 copy,然后打开新立得软件管理器,在里面搜索 libgnome 这个关键词,就会找到 libgnome 相关的项目,把前面有个 ubuntu 符号的 libgnome 包(注意:同样需要安装 dev 包,但可以不装 doc 包)全部安装,通过这个方法把./configure 过程中缺失的开发包都全部装上就 OK 了,第一步能顺利通过,第二 ,三步基本问题不大。 源码包的卸载：不需要卸载命令,直接删除安装目录即可。不会遗留任何垃圾文件 以上就是一般初学 ubuntu 的朋友必须掌握的编译安装的基本方法! apt-get 安装方法ubuntu 默认的软件管理系统是apt。apt有很多国内软件源，推荐使用淘宝。 apt-get 的基本软件安装命令是: sudo apt-get install 软件名 deb 包的安装方式deb 是 debian 系 Linux 的包管理方式，ubuntu 是属于 debian 系的 Linux 发行版，所以默认支持这种软件安装方式。当下载到一个 deb 格式的软件后,在终端输入这个命令就能安装： sudo dpkg -i \**软件名\**.deb 二进制编译或者脚本安装方式github上一般都会提供二进制源码或者脚本安装方式。这类软件,你会在软件安装目录下发现类似后缀名的文件，如： .sh .py .run 等等,有的甚至连后缀名都没有,直接只有一个 INSTALL 文件。或者是一个其他什么的可执行文件。对于这种软件,可尝试以下几种方式安装： 在软件目录下输入: ./软件名* ** 或者 : sh 软件名.sh或者: python 软件名.py** rpm 包的安装方式rpm 包是 deb 包外最常见的一种包管理方式,但 ubuntu 同样可以使用 rpm 的软件资源,首先我们需要安装一个 rpm 转 deb 的软件sudo apt-get install alien然后就可以对 rpm 格式的软件转换成 deb 格式了:alien -d *.rpm然后就可以用 deb 的安装方式进行软件安装也可以不需转换而直接对 rpm 包进行安装:alien -i *.rpm更多的 alien 使用方法可以用-h 参数查看相应说明文档 用户和用户组管理 用户管理简介 越是对服务器安全性要求高的服务器,越需要建立合理的用户权限等级制度和服务器操作规范。 在Linux中主要是通过用户配置文件来查看和修改用户信息 用户配置文件用户信息文件/etc/passwd 第1字段:用户名称 第2字段:密码标志 第3字段:UID(用户ID) 0: 超级用户 1-499: 系统用户(伪用户) 500-65535: 普通用户 第4字段:GID(用户初始组ID) 第5字段:用户说明 第6字段:家目录 普通用户:/home/用户名/ 超级用户:/root/ 第7字段:登录之后的Shell 初始组和附加组 初始组:就是指用户一登录就立刻拥有这个用户组的相关权限,每个用户的初始组只能有一个,一般就是和这个用户的用户名相同的组名作为这个用户的初始组。 附加组:指用户可以加入多个其他的用户组,并拥有这些组的权限,附加组可以有多个。 Shell是什么 Shell就是Linux的命令解释器。 在/etc/passwd当中,除了标准Shell是/bin/bash之外,还可以写如/sbin/nologin,/usr/bin/passwd等。 影子文件/etc/shadow 第1字段:用户名 第2字段:加密密码 加密算法升级为SHA512散列加密算法 如果密码位是“!!”或“*”代表没有密码,不能登录 第3字段:密码最后一次修改日期使用1970年1月1日作为标准时间,每过一天时间戳加1 第4字段:两次密码的修改间隔时间(和第3字段相比) 第5字段:密码有效期(和第3字段相比) 第6字段:密码修改到期前的警告天数(和第5字段相比) 第7字段:密码过期后的宽限天数(和第5字段相比) 0:代表密码过期后立即失效 -1:则代表密码永远不会失效。 第8字段:账号失效时间 要用时间戳表示 第9字段:保留 时间戳换算 把时间戳换算为日期date -d “1970-01-01 16066 days” 把日期换算为时间戳echo $(($(date –date=”2014/01/06” +%s)/86400+1)) 组信息文件/etc/group和组密码文件/etc/gshadow组信息文件/etc/group 第一字段:组名 第二字段:组密码标志 第三字段:GID 第四字段:组中附加用户 组密码文件/etc/gshadow 第一字段:组名 第二字段:组密码 第三字段:组管理员用户名 第四字段:组中附加用户 用户管理相关文件用户的家目录 普通用户：/home/用户名/,所有者和所属组都是此用户,权限是700 超级用户:/root/,所有者和所属组都是root用户,权限是550 用户的邮箱 /var/spool/mail/用户名/ 用户模板目录 /etc/skel/ 用户管理命令用户添加命令useradduseradd命令格式[root@localhost ~]#useradd [选项] 用户名选项:-u UID: 手工指定用户的UID号-d 家目录: 手工指定用户的家目录-c 用户说明: 手工指定用户的说明-g 组名: 手工指定用户的初始组-G 组名: 指定用户的附加组-s shell: 手工指定用户的登录shell。默认是/bin/bash 添加默认用户[root@localhost ~]# useradd lamp[root@localhost ~]# grep “lamp” /etc/passwd[root@localhost ~]# grep “lamp” /etc/shadow[root@localhost ~]# grep “lamp” /etc/group[root@localhost ~]# grep “lamp” /etc/gshadow[root@localhost ~]# ll -d /home/lamp/[root@localhost ~]# ll /var/spool/mail/lamp 指定选项添加用户 groupadd lamp1 useradd -u 550 -g lamp1 -G root -d /home/lamp1 -c “test user” -s /bin/bash lamp1 用户默认值文件 /etc/default/useradd GROUP=100 #用户默认组 HOME=/home #用户家目录 NACTIVE=-1 #密码过期宽限天数( 7 ) EXPIRE= #密码失效时间( 8 ) SHELL=/bin/bash # 默认 shell SKEL=/etc/skel #模板目录 CREATE_MAIL_SPOOL=yes #是否建立邮箱 /etc/login.defs PASS_MAX_DAYS 99999 # 密码有效期( 5 ) PASS_MIN_DAYS 0 # 密码修改间隔( 4 ) PASS_MIN_LEN 5 # 密码最小 5 位( PAM ) PASS_WARN_AGE 7 # 密码到期警告( 6 ) UID_MIN 500 # 最小和最大 UID 范围GID_MAX 60000 ENCRYPT_METHOD SHA512 #加密模式 修改用户密码passwdpasswd命令格式[root@localhost ~]#passwd [选项] 用户名选项:-S 查询用户密码的密码状态。仅root用户可用。-l 暂时锁定用户。仅root用户可用-u 解锁用户。仅root用户可用–stdin 可以通过管道符输出的数据作为用户的密码。 查看密码状态[root@localhost ~]# passwd -S lamplamp PS 2013-01-06 0 99999 7 -1 #用户名 密码设定时间( 2013-01-06 ) 密码修改间隔时间( 0 ) #密码有效期( 99999 ) 警告时间( 7 ) 密码不失效( -1 ) 锁定用户和解锁用户[root@localhost ~]# passwd -l lamp[root@localhost ~]# passwd -u lamp 使用字符串作为用户的密码[root@localhost ~]# echo “123” | passwd –stdin lamp 修改用户信息usermod和修改用户密码状态chage修改用户信息usermod[root@localhost ~]#usermod [选项] 用户名选项:-u UID: 修改用户的UID号-c 用户说明: 修改用户的说明信息-G 组名: 修改用户的附加组-L: 临时锁定用户(Lock)-U: 解锁用户锁定(Unlock) [root@localhost ~]# usermod -c “test user” lamp修改用户的说明 [root@localhost ~]# usermod -G root lamp把 lamp 用户加入 root 组 [root@localhost ~]# usermod -L lamp锁定用户 [root@localhost ~]# usermod -U lamp解锁用户 修改用户密码状态chage[root@localhost ~]#chage [选项] 用户名选项:-l: 列出用户的详细密码状态-d 日期: 修改密码最后一次更改日期(shadow3字段)-m 天数: 两次密码修改间隔(4字段)-M 天数: 密码有效期(5字段)-W 天数: 密码过期前警告天数(6字段)-I 天数: 密码过后宽限天数(7字段)-E 日期: 账号失效时间(8字段) [root@localhost ~]# chage -d 0 lamp #这个命令其实是把密码修改日期归 0 了( shadow 第 3 字段) #这样用户一登陆就要修改密码 删除用户userdel和用户切换命令su删除用户userdel[root@localhost ~]# userdel [-r] 用户名选项: -r 删除用户的同时删除用户家目录 手工删除用户[root@localhost ~]# vi /etc/passwd[root@localhost ~]# vi /etc/shadow[root@localhost ~]# vi /etc/group[root@localhost ~]# vi /etc/gshadow[root@localhost ~]# rm -rf /var/spool/mail/lamp[root@localhost ~]# rm -rf /home/lamp/ 查看用户ID[root@localhost ~]# id 用户名 切换用户身份su[root@localhost ~]# su [选项] 用户名选项: ​ -: 选项只使用“-”代表连带用户的环境 变量一起切换​ -c 命令: 仅执行一次命令,而不切换用户身份 [lamp@localhost ~]$ su – root切换成 root [lamp@localhost ~]$ su - root -c “useradd user3”不切换成 root ,但是执行 useradd 命令添加 user1 用户 用户组管理命令groupmod用法：groupmod [选项] 组 选项: -g, –gid GID 将组 ID 改为 GID -h, –help 显示此帮助信息并推出 -n, –new-name NEW_GROUP 改名为 NEW_GROUP -o, –non-unique 允许使用重复的 GID -p, –password PASSWORD 将密码更改为(加密过的) PASSWORD -R, –root CHROOT_DIR chroot 到的目录 删除用户组groupdel [用户组名] gpasswd用法：gpasswd [选项] 组 选项： -a, –add USER 向组 GROUP 中添加用户 USER -d, –delete USER 从组 GROUP 中添加或删除用户 -h, –help 显示此帮助信息并推出 -Q, –root CHROOT_DIR 要 chroot 进的目录 -r, –remove-password 移除组 GROUP 的密码 -R, –restrict 向其成员限制访问组 GROUP -M, –members USER,… 设置组 GROUP 的成员列表 -A, –administrators ADMIN,… 设置组的管理员列表 权限管理ACL权限ACL权限简介与开启简介：根目录中有一个 /project 目录，这是班级的项目目录。班级中的每个学员都可以访问和修改这个目录，老师也需要对这个目录拥有访问和修改权限，其他班级的学员当然不能访问这个目录。需要怎么规划这个目录的权限呢？应该这样：老师使用 root 用户，作为这个目录的属主，权限为 rwx；班级所有的学员都加入 tgroup 组，使 tgroup 组作为 /project 目录的属组，权限是 rwx；其他人的权限设定为 0。这样这个目录的权限就可以符合我们的项目开发要求了。 有一天，班里来了一位试听的学员 st，她必须能够访问 /project 目录，所以必须对这个目录拥有 r 和 x 权限；但是她又没有学习过以前的课程，所以不能赋予她 w 权限，怕她改错了目录中的内容，所以学员 st 的权限就是 r-x。可是如何分配她的身份呢？变为属主？当然不行，要不 root 该放哪里？加入 tgroup 组？也不行，因为 tgroup 组的权限是 rwx，而我们要求学员 st 的权限是 r-x。如果把其他人的权限改为 r-x 呢？这样一来，其他班级的所有学员都可以访问 /project 目录了。 当出现这种情况时，普通权限中的三种身份就不够用了。ACL 权限就是为了解决这个问题的。在使用 ACL 权限给用户 st 陚予权限时，st 既不是 /project 目录的属主，也不是属组，仅仅赋予用户 st 针对此目录的 r-x 权限。这有些类似于 Windows 系统中分配权限的方式，单独指定用户并单独分配权限，这样就解决了用户身份不足的问题。 ACL是Access Control List（访问控制列表）的缩写，不过在Linux系统中，ACL用于设定用户针对文件的权限，而不是在交换路由器中用来控制数据访问的功能（类似于防火墙） 开启： 查看分区是否开启ACL权限[root@hhh]#df -h 看一下根目录所在分区[root@hhh]#dumpe2fs -h [根目录所在分区] ​ -h：仅显示超级块中的信息，而不显示磁盘块组的详细信息 查找：Default mount options 后面是否有ACL（一般分区都开启ACL） 如果没开启，则可以临时开启分区ACL权限[root@hhh]#mount -o remount ,acl 重新挂载根分区，并加入acl权限或者：永久开启ACL权限[root@hhh]#vim /etc/fstab查找到：UUID=c2ca6f57-b15c-43ea-bca0-f239083d8bd2 / ext4 default 1 1在default后加上“，acl”然后重新挂载文件系统#mount -o remount/ 或 重启动系统，使修改生效 查看与设定ACL权限查看ACL命令[root@localhost ~]# getfacle 文件名 #查看 acl 权限 设定ACL权限的命令[root@localhost ~]# setfacl 选项 文件名选项:-m 设定ACL权限 如果是给予用户 ACL 权限，则使用”u:用户名：权限”格式赋予 如果是给予组 ACL 权限，则使用”g:组名：权限” 格式赋予；-x 删除指定的ACL权限-b 删除所有的ACL权限,只对目录生效，指目录中新建立的文件拥有此默认权限；-d 设定默认ACL权限。-k 删除默认ACL权限-R 递归设定ACL权限。 给用户和用户组设定ACL权限我们要求 root 是 /project 目录的属主，权限是 rwx；tgroup 是此目录的属组，tgroup 组中拥有班级学员 zhangsan 和 lisi，权限是 rwx；其他人的权限是 0。这时，试听学员 st 来了，她的权限是 r-x。我们来看具体的分配命令。 123456789101112131415161718192021222324252627282930[root@localhost ~]# useradd zhangsan[root@localhost ~]# useradd lisi[root@localhost ~]# useradd st[root@localhost ~]# groupadd tgroup#添加需要试验的用户和用户组，省略设定密码的过程[root@localhost ~]# mkdir /project #建立需要分配权限的目录[root@localhost ~]# chown root:tgroup /project/#改变/project目录的属主和属组[root@localhost ~]# chmod 770 /project/#指定/project目录的权限[root@localhost ~]# ll -d /project/drwxrwx--- 2 root tgroup 4096 1月19 04:21 /project/#查看一下权限，已经符合要求了#这时st学员来试听了，如何给她分配权限[root@localhost ~]# setfacl -m u:st:rx /project/#给用户st赋予r-x权限，使用"u:用户名：权限" 格式[root@localhost /]# cd /[root@localhost /]# ll -d project/drwxrwx---+ 3 root tgroup 4096 1月19 05:20 project/#使用ls-l査询时会发现，在权限位后面多了一个"+"，表示此目录拥有ACL权限[root@localhost /]# getfacl project#查看/prpject目录的ACL权限#file: project &lt;-文件名#owner: root &lt;-文件的属主#group: tgroup &lt;-文件的属组user::rwx &lt;-用户名栏是空的，说明是属主的权限user:st:r-x &lt;-用户st的权限group::rwx &lt;-组名栏是空的，说明是属组的权限mask::rwx &lt;-mask权限other::--- &lt;-其他人的权限 大家可以看到，st 用户既不是 /prpject 目录的属主、属组，也不是其他人，我们单独给 st 用户分配了 r-x 权限。这样分配权限太方便了，完全不用先辛苦地规划用户身份了。 我想给用户组赋予 ACL 权限可以吗？当然可以，命令如下： 1234567891011121314151617[root@localhost /]# groupadd tgroup2#添加测试组[root@localhost /]# setfacl -m g:tgroup2:rwx project/#为组tgroup2纷配ACL权限，使用"g:组名:权限"格式[root@localhost /]# ll -d project/drwxrwx---+ 2 root tgroup 4096 1月19 04:21 project/#属组并没有更改[root@localhost /]# getfacl project/#file: project/#owner: root#group: tgroupuser::rwxuser:st:r-xgroup::rwxgroup:tgroup2:rwx &lt;-用户组tgroup2拥有了rwx权限mask::rwxother::-- 最大有效权限与删除ACL权限最大有效权限maskmask 是用来指定最大有效权限的。mask 的默认权限是 rwx，如果我给 st 用户赋予了 r-x 的 ACL 权限，是需要和 mask 的 rwx 权限”相与”才能得到 st 的真正权限，也就是 r-x “相与”rwx 出的值是 r-x，所以 st 用户拥有 r-x 权限。 如果把 mask 的权限改为 r–，和 st 用户的权限相与，也就是 r–”相与”r-x 得出的值是 r–，st 用户的权限就会变为只读。大家可以这么理解：用户和用户组所设定的权限必须在 mask 权限设定的范围之内才能生效，mask权限就是最大有效权限。 不过我们一般不更改 mask 权限，只要给予 mask 最大权限 rwx，那么任何权限和 mask 权限相与，得出的值都是权限本身。也就是说，我们通过给用户和用户组直接赋予权限，就可以生效，这样做更直观。 修改最大有效权限的命令如下： 1234567891011[root@localhost /]# setfacl -m m:rx project/#设定mask权限为r-x，使用"m:权限"格式[root@localhost /]# getfacl project/#file：project/#owner：root#group：tgroupuser::rwxgroup::rwx #effective:r-xmask::r-x#mask权限变为r-xother::-- 删除ACL权限123456[root@localhost /]# setfacl -x u:用户名 文件名# 删除指定用户的 ACL 权限[root@localhost /]# setfacl -x g:组名 文件名# 删除指定用户组的 ACL 权限[root@localhost /]# setfacl -b 文件名# 会删除文件的所有的 ACL 权限 默认ACL权限和递归ACL权限默认ACL权限我们已经给 /project 目录设定了 ACL 权限，那么，在这个目录中新建一些子文件和子目录，这些文件是否会继承父目录的 ACL 权限呢？我们试试吧。 123456789[root@localhost /]# cd /project/[root@localhost prq'ect]# touch abc[root@localhost prq'ect]# mkdir d1#在/project目录中新建了abc文件和d1目录[root@localhost project]#ll总用量4-rw-r--r-- 1 root root 01月19 05:20 abcdrwxr-xr-x 2 root root 4096 1月19 05:20 d1#这两个新建立的文件权限位后面并没有"+"，表示它们没有继承ACL权限 子文件 abc 和子目录 d1 因为是后建立的，所以并没有继承父目录的 ACL 权限。当然，我们可以手工给这两个文件分配 ACL 权限，但是如果在目录中再新建文件，都要手工指定，则显得过于麻烦。这时就需要用到默认 ACL 权限。 默认 ACL 权限的作用是：如果给父目录设定了默认 ACL 权限，那么父目录中所有新建的子文件都会继承父目录的 ACL 权限。默认 ACL 权限只对目录生效。 命令如下： 123456789101112131415161718192021222324252627[root@localhost /]# setfacl -m d:u:st:rx /project/#使用"d:u:用户名：权限"格式设定默认ACL权限[root@localhost project]# getfacl project/# file: project/# owner: root# group: tgroupuser:: rwxuser:st:r-xgroup::rwxgroup:tgroup2:rwxmask::rwxother::--default:user::rwx &lt;-多出了default字段default:user:st:r-xdefault:group::rwxdefault:mask::rwxdefault:other::--[root@localhost /]# cd project/[root@localhost project]# touch bcd[root@localhost project]# mkdir d2#新建子文件和子目录[root@localhost project]# ll 总用量8-rw-r--r-- 1 root root 01月19 05:20 abc-rw-rw----+ 1 root root 01月19 05:33 bcddrwxr-xr-x 2 root root 4096 1月19 05:20 d1drwxrwx---+ 2 root root 4096 1月19 05:33 d2#新建的bcd和d2已经继承了父目录的ACL权限 原先的 abc 和 d1 还是没有 ACL 权限，因为默认 ACL 权限是针对新建立的文件生效的。 递归 ACL 权限递归是指父目录在设定 ACL 权限时，所有的子文件和子目录也会拥有相同的 ACL 权限。 123456789[root@localhost project]# setfacl -m u:st:rx -R/project/#-R递归[root@localhost project]# ll总用量8-rw-r-xr--+ 1 root root 01月19 05:20 abc-rw-rwx--+ 1 root root 01月19 05:33 bcddrwxr-xr-x+ 2 root root 4096 1月19 05:20 d1drwxrwx--+ 2 root root 4096 1月19 05:33 d2#abc和d1也拥有了ACL权限 总结一下： 默认 ACL 权限指的是针对父目录中新建立的文件和目录会继承父目录的 ACL 权限，格式是setfacl-m d:u:用户名：权限 文件名； 递归 ACL 权限指的是针对父目录中已经存在的所有子文件和子目录继承父目录的 ACL 权限，格式是setfacl-m u:用户名： 权限 -R 文件名。 文件特殊权限SetUIDSetUID的功能 只有可以执行的二进制程序才能设定SUID权限 命令执行者要对该程序拥有x(执行)权限 命令执行者在执行该程序时获得该程序文件属主的身份(在执行程序的过程中灵魂附体为文件的属主) SetUID权限只在该程序执行过程中有效,也就是说身份改变只在程序执行过程中有效 passwd命令拥有SetUID权限,所以普通可以修改自己的密码 12root@finyorke:/home/finyorko# ll /usr/bin/passwd-rwsr-xr-x 1 root root 54256 3月 27 2019 /usr/bin/passwd* cat命令没有SetUID权限,所以普通用户不能查看/etc/shadow文件内容 12root@finyorke:/home/finyorko# ll /bin/cat-rwxr-xr-x 1 root root 52080 3月 3 2017 /bin/cat* 设定SetUID的方法 4代表SUID chmod 4755 文件名 chmod u+s 文件名 取消SetUID的方法 chmod 755 文件名 chmod u-s 文件名 危险的SetUID 关键目录应严格控制写权限。比如“/”、“/usr”等 用户的密码设置要严格遵守密码三原则 对系统中默认应该具有SetUID权限的文件作一列表,定时检查有没有这之外的文件被设置了SetUID权限 SetGIDSetGID针对文件的作用 只有可执行的二进制程序才能设置SGID权限 命令执行者要对该程序拥有x(执行)权限 命令执行在执行程序的时候,组身份升级为该程序文件的属组 SetGID权限同样只在该程序执行过程中有效,也就是说组身份改变只在程序执行过程中有效 1234root@finyorke:/home/finyorko# ll /usr/bin/locatelrwxrwxrwx 1 root root 24 4月 16 2019 /usr/bin/locate -&gt; /etc/alternatives/locate*root@finyorke:/home/finyorko# ll /var/lib/mlocate/mlocate.db-rw-r----- 1 root mlocate 17479196 12月 3 07:17 /var/lib/mlocate/mlocate.db /usr/bin/locate是可执行二进制程序,可以赋予SGID 执行用户lamp对/usr/bin/locate命令拥有执行权限 执行/usr/bin/locate命令时,组身份会升级为slocate组,而slocate组对/var/lib/mlocate/mlocate.db数据库拥有r权限,所以普通用户可以使用locate命令查询mlocate.db数据库 命令结束,lamp用户的组身份返回为lamp组 SetGID针对目录的作用 普通用户必须对此目录拥有r和x权限,才能进入此目录 普通用户在此目录中的有效组会变成此目录的属组 若普通用户对此目录拥有w权限时,新建的文件的默认属组是这个目录的属组 123456789[root@localhost ~]# cd /tmp/[root@localhost tmp]# mkdir dtest[root@localhost tmp]# chmod g+s dtest[root@localhost tmp]# ll -d dtest/[root@localhost tmp]# chmod 777 dtest/[root@localhost tmp]# su – lamp[lamp@localhost ~]$ cd /tmp/dtest/[lamp@localhost dtest]$ touch abc[lamp@localhost dtest]$ ll 设定SetGID 2代表SGID chmod 2755 文件名 chmod g+s 文件名 取消SetGID chmod 755 文件名 chmod g-s 文件名 Sticky BITSBIT粘着位作用 粘着位目前只对目录有效 普通用户对该目录拥有w和x权限,即普通用户可以在此目录拥有写入权限 如果没有粘着位,因为普通用户拥有w权限,所以可以删除此目录下所有文件,包括其他用户建立的文件。一但赋予了粘着位,除了root可以删除所有文件,普通用户就算拥有w权限,也只能删除自己建立的文件,但是不能删除其他用户建立的文件 12root@finyorke:/home/finyorko# ll -d /tmp/drwxrwxrwt 27 root root 4096 12月 3 20:18 /tmp// 设置与取消粘着位 设置粘着位 chmod 1755 目 录名 chmod o+t 目录名 取消粘着位 chmod 777 目录名 chmod o-t 目录名 文件系统属性chattr权限chattr命令格式[root@localhost ~]# chattr [+-=] [选项] 文件或目录名 +: 增加权限 -: 删除权限 =: 等于某权限 选项 i:如果对文件设置i属性,那么不允许对文件进行删除、改名,也不能添加和修改数据;如果对目录设置i属性,那么只能修改目录下文件的数据,但不允许建立和删除文件。 a:如果对文件设置a属性,那么只能在文件中增加数据,但是不能删除也不能修改数据;如果对目录设置a属性,那么只允许在目录中建立和修改文件,但是不允许删除 查看文件系统属性[root@localhost ~]# lsattr 选项 文件名 选项: -a 显示所有文件和目录 -d 若目标是目录,仅列出目录本身的属性,而不是子文件的 系统命令sudo权限sudo权限 root把本来只能超级用户执行的命令赋予普通用户执行。 sudo的操作对象是系统命令 sudo使用[root@localhost ~]# visudo #实际修改的是 /etc/sudoers 文件 root ALL=(ALL) ALL #用户名 被管理主机的地址 = (可使用的身份) 授权命令(绝对路径) #%wheel ALL=(ALL) ALL #% 组名 被管理主机的地址 = (可使用的身份) 授权命令(绝对路径) 授权sc用户可以重启服务器[root@localhost ~]# visudoscALL= /sbin/shutdown –r now 授权sc用户可以重启服务器[root@localhost ~]# visudosc ALL= /sbin/shutdown –r now 普通用户执行sudo赋予的命令12345[root@localhost ~]# su – sc[sc@localhost ~]$ sudo -l# 查看可用的 sudo 命令[lamp@localhost ~]$ sudo /sbin/shutdown -r now# 普通用户执行 sudo 赋予的命令 文件系统管理回顾分区和文件系统分区类型 主分区:总共最多只能分四个 扩展分区:只能有一个,也算作主分区的一种,也就是说主分区加扩展分区最多有四个。但是扩展分区不能存储数据和格式化,必须再划分成逻辑分区才能使用。 逻辑分区:逻辑分区是在扩展分区中划分的,如果是IDE硬盘,Linux最多支持59个逻辑分区,如果是SCSI硬盘Linux最多支持11个逻辑分区 问题：第2块SCSI硬盘的第3个逻辑分区，Linux如何表示？ 答： ​ 硬盘表示的规律：磁盘设备存放于/dev/文件夹下；对于IDE接口的磁盘，按照顺序分别表示为/dev/hda、/dev/hdb、/dev/hdc、/dev/hdd；对于SCSI接口的磁盘，按照顺序分别表示为/dev/sda、/dev/sdb、/dev/sdc、/dev/sdd、……。 ​ MBR传统分区模式的特点：主分区最多只能有四个（其中一个可作为扩展分区），其分区编号对应1-4；扩展分区最多只能有一个，也可以没有，扩展分区需要占用主分区编号，不能被格式化用来存放文档；逻辑分区只能从扩展分区范围内再次划分，其分区编号始终从5开始。 ​ 综上所述，第2块SCSI硬盘的第3个逻辑分区，其设备文件应该位于/dev/sdb7。 文件系统 ext2:是ext文件系统的升级版本,Red Hat Linux7.2版本以前的系统默认都是ext2文件系统。1993年发布,最大支持16TB的分区和最大2TB的文件(1TB=1024GB=1024*1024KB) ext3: ext3文件系统是ext2文件系统的升级版本,最大的区别就是带日志功能,以在系统突然停止时提高文件系统的可靠性。支持最大16TB的分区和最大2TB的文件 ext4:它是ext3文件系统的升级版。ext4 在性能 、伸缩性和可靠性方面进行了大量改进。EXT4 的变化可以说是翻天覆地的,比如向下兼容 EXT3、最大1EB文件系统和16TB文件、无限数 量子目录、Extents连续数据块概念、多块分配 、延迟分配、持久预分配、快速FSCK、日志校 验、无日志模式、在线碎片整理、inode增强、 默认启用barrier等。是CentOS 6.3的默认文件系 统 (1EB=1024PB=1024*1024TB) 文件系统常用命令df命令、du命令、fsck命令和dump2fs命令文件系统查看命令df[root@localhost ~]# df [选项] [挂载点] 选项:-a 显示所有的文件系统信息,包括特殊文件系统,如 /proc、/sysfs-h 使用习惯单位显示容量,如KB,MB或GB等-T 显示文件系统类型-m 以MB为单位显示容量-k 以KB为单位显示容量。默认就是以KB为单位 统计目录或文件大小[root@localhost ~]# du [选项] [目录或文件名]选项:-a 显示每个子文件的磁盘占用量。默认只统计子目录的磁盘占用量-h 使用习惯单位显示磁盘占用量,如KB,MB或GB等-s 统计总占用量,而不列出子目录和子文件的占用量 du命令和df命令的区别 df命令是从文件系统考虑的,不光要考虑 文件占用的空间,还要统计被命令或程序 占用的空间(最常见的就是文件已经删除 ,但是程序并没有释放空间) du命令是面向文件的,只会计算文件或目录占用的空间 文件系统修复命令fsck[root@localhost ~]# fsck [选项] 分区设备文件名选项:-a: 不用显示用户提示,自动修复文件系统-y: 自动修复。和-a作用一致,不过有些文件系统只支持-y 显示磁盘状态命令dumpe2fs[root@localhost ~]# dumpe2fs 分区设备文件名 挂载命令查询与自动挂载1234[root@localhost ~]# mount [-l]#查询系统中已经挂载的设备, -l 会显示卷标名称[root@localhost ~]# mount –a#依据配置文件 /etc/fstab 的内容,自动挂载 挂载命令格式[root@localhost ~]# mount [-t 文件系统] [-L 卷标名] [-o 特殊选项] 设备文件名 挂载点选项:-t 文件系统:加入文件系统类型来指定挂载的类型,可以ext3、ext4、iso9660等文件系统-L 卷标名:挂载指定卷标的分区,而不是安装设备文件名挂载-o 特殊选项:可以指定挂载的额外选项 参数 说明 atime/noatime 更新访问时间/不更新访问时间。访问分区文件时,是否更新文件 的访问时间,默认为更新 async/sync 异步/同步,默认为异步 auto/noauto 自动/手动,mount –a命令执行时,是否会自动安装/etc/fstab文件 内容挂载,默认为自动 defaults 定义默认值,相当于rw,suid,dev,exec,auto,nouser,async这七个选项 exec/noexec 执行/不执行,设定是否允许在文件系统中执行可执行文件,默认是exec允许 remount 重新挂载已经挂载的文件系统,一般用于指定修改特殊权限 rw/ro 读写/只读,文件系统挂载时,是否具有读写权限,默认是rw suid/nosuid 具有/不具有SUID权限,设定文件系统是否具有SUID和SGID的权 限,默认是具有 user/nouser 允许/不允许普通用户挂载,设定文件系统是否允许普通用户挂载, 默认是不允许,只有root可以挂载分区 usrquota 写入代表文件系统支持用户磁盘配额,默认不支持 grpquota 写入代表文件系统支持组磁盘配额,默认不支持 12345678[root@localhost ~]# mount -o remount,noexec /home# 重新挂载 /boot 分区,并使用 noexec 权限[root@localhost sh]# cd /home[root@localhost boot]# vi hello.sh[root@localhost boot]# chmod 755 hello.sh[root@localhost boot]# ./hello.sh[root@localhost boot]# mount -o remount,exec /home# 记得改回来啊,要不会影响系统启动的 挂载光盘与U盘挂载光盘12345[root@localhost ~]# mkdir /mnt/cdrom/# 建立挂载点[root@localhost ~]# mount -t iso9660 /dev/cdrom /mnt/cdrom/# 挂载光盘[root@localhost ~]# mount /dev/sr0 /mnt/cdrom/ 卸载命令12[root@localhost ~]# umount 设备文件名或挂载点[root@localhost ~]# umount /mnt/cdrom 挂载U盘123[root@localhost ~]# fdisk –l# 查看 U 盘设备文件名[root@localhost ~]# mount -t vfat /dev/sdb1 /mnt/usb/ 注意:Linux默认是不支持NTFS文件系统的 支持NTFS文件系统下载NTFS-3G插件http://www.tuxera.com/community/ntfs-3g-download/ 安装NTFS-3G12345678910[root@localhost ~]# tar -zxvf ntfs-3g_ntfsprogs-2013.1.13.tgz# 解压[root@localhost ~]# cd ntfs-3g_ntfsprogs-2013.1.13# 进入解压目录[root@localhost ntfs-3g_ntfsprogs-2013.1.13]# ./configure# 编译器准备。没有指定安装目录,安装到默认位置中[root@localhost ntfs-3g_ntfsprogs-2013.1.13]# make# 编译[root@localhost ntfs-3g_ntfsprogs-2013.1.13]# make install# 编译安装 使用[root@localhost ~]# mount -t ntfs-3g 分区设备文件名 挂载点 fdisk分区fdisk命令分区过程 添加新硬盘 查看新硬盘[root@localhost ~]# fdisk -l 使用fdisk命令分区[root@localhost ~]# fdisk /dev/sdb fdisk交互指令说明 命令 说明 a 设置可引导标记 b 编辑bsd磁盘标签 c 设置DOS操作系统兼容标记 d 删除一个分区 l 显示已知的文件系统类型。82为Linux swap分区,83为Linux分区 m 显示帮助菜单 n 新建分区 o 建立空白DOS分区表 p 显示分区列表 q 不保存退出 s 新建空白SUN磁盘标签 t 改变一个分区的系统ID u 改变显示记录单位 n 验证分区表验证分区表 w 保存退出 x 附加功能(仅专家) 重新读取分区表信息[root@localhost ~]# partprobe 格式化分区[root@localhost ~]# mkfs -t ext4 /dev/sdb1 建立挂载点并挂载[root@localhost ~]# mkdir /disk1[root@localhost ~]# mount /dev/sdb1 /disk1/ 分区自动挂载与fstab文件修复 /etc/fstab文件第一字段:分区设备文件名或UUID(硬盘通用唯一识别码)第二字段:挂载点第三字段:文件系统名称第四字段:挂载参数第五字段:指定分区是否被dump备份,0代表不备份,1代表每天备份,2代表不定期备份第六字段:指定分区是否被fsck检测,0代表不检测,其他数字代表检测的优先级,那么当然1的优先级比2高 分区自动挂载[root@localhost ~]# vi /etc/fstab…省略部分输出…/dev/sdb5 /disk5 ext4 defaults 1 2 /etc/fstab文件修复[root@localhost ~]# mount -o remount,rw / 分配swap分区新建swap分区1[root@localhost ~]# fdisk /dev/sdb 别忘记把分区ID改为82 格式化1[root@localhost ~]# mkswap /dev/sdb1 加入swap分区1234[root@localhost ~]# swapon /dev/sdb1# 加入 swap 分区[root@localhost ~]# swapoff /dev/sdb1# 取消 swap 分区 swap分区开机自动挂载12[root@localhost ~]# vi /etc/fstab/dev/sdb1 swap swap defaults 0 0 free命令12[root@localhost ~]# free# 查看内存与 swap 分区使用状况 cached(缓存):是指把读取出来的数据保存在内存当 中,当再次读取时,不用读取硬盘而直接从内存当中读 取,加速了数据的读取过程 buffer(缓冲):是指在写入数据时,先把分散的写入操 作保存到内存当中,当达到一定程度再集中写入硬盘, 减少了磁盘碎片和硬盘的反复寻道,加速了数据的写入 过程 Shell基础Shell概述Shell是什么 Shell是一个命令行解释器,它为用户提供 了一个向Linux内核发送请求以便运行程 序的界面系统级程序,用户可以用Shell来 启动、挂起、停止甚至是编写一些程序。 Shell还是一个功能相当强大的编程语言, 易编写,易调试,灵活性较强。Shell是解 释执行的脚本语言,在Shell中可以直接调 用Linux系统命令。 Shell的分类 Bourne Shell:从1979起Unix就开始使用 Bourne Shell,Bourne Shell的主文件名为 sh。 C Shell: C Shell主要在BSD版的Unix系 统中使用,其语法和C语言相类似而得名 Shell的两种主要语法类型有Bourne和C, 这两种语法彼此不兼容。Bourne家族主要 包括sh、ksh、Bash、psh、zsh;C家族主 要包括:csh、tcsh Bash: Bash与sh兼容,现在使用的Linux 就是使用Bash作为用户的基本Shell Linux支持的Shell/etc/shells Shell脚本的执行方式echo输出命令12345678910111213141516[root@localhost ~]# echo [选项] [输出内容]选项:-e: 支持反斜线控制的字符转换控制字符及其作用\\ 输出\本身\a 输出警告音\b 退格键,也就是向左删除键\c 取消输出行末的换行符。和“-n”选项一致\e ESCAPE键\f 换页符\n 换行符\r 回车键\t 制表符,也就是Tab键\v 垂直制表符\0nnn 按照八进制ASCII码表输出字符。其中0为数字零,nnn是三位八进制数\xhh 按照十六进制ASCII码表输出字符。其中hh是两位十六进制数 123456789101112[root@localhost ~]# echo -e &quot;ab\bc&quot;# 删除左侧字符[root@localhost ~]# echo -e &quot;a\tb\tc\nd\te\tf&quot;# 制表符与换行符[root@localhost ~]# echo -e \ &quot;\x61\t\x62\t\x63\n\x64\t\x65\t\x66&quot;# 按照十六进制 ASCII 码也同样可以输出[root@localhost ~]# echo -e &quot;\e[1;31m abcd \e[0m&quot;# 输出颜色#\e[ 开始颜色输出#\e[0m 结束颜色输出#30m= 黑色, 31m= 红色, 32m= 绿色, 33m= 黄色#34m= 蓝色, 35m= 洋红, 36m= 青色, 37m= 白色 第一个脚本12345[root@localhost sh]# vi hello.sh#!/bin/Bash -----注意这一行不是注释#The first program# Author: finyorkoecho -e "The first shell.sh" 脚本执行 赋予执行权限,直接运行 chmod 755 hello.sh ./hello.sh 绝对路径执行/root/sh/hello.sh 相对路径执行./hello.sh 通过Bash调用执行脚本 bash hello.sh #此种方式，甚至执行权限不给都可以用 1234# unix2dos #unix格式转化为Windows格式# dos2unix #Windows格式转化为unix格式 Bash的基本功能历史命令与命令补全历史命令12345[root@localhost ~]# history [选项] [历史命令保存文件]选项:-c: 清空历史命令-w: 把缓存中的历史命令写入历史命令保存文件~/.bash_history 历史命令默认会保存1000条,可以在环境变量配置文件/etc/profile中进行修改 历史命令的调用 使用上、下箭头调用以前的历史命令 使用“!n”重复执行第n条历史命令 使用“!!”重复执行上一条命令 使用“!字串”重复执行最后一条以该字串开头的命令 命令与文件补全在Bash中,命令与文件补全是非常方便与常用的功能,我们只要在输入命令或文件时,按“Tab”键就会自动进行补全 命令别名与常用快捷键命令别名1234[root@localhost ~]# alias 别名='原命令'# 设定命令别名[root@localhost ~]# alias# 查询命令别名 命令执行时顺序 第一顺位执行用绝对路径或相对路径执行的命令。 第二顺位执行别名。 第三顺位执行Bash的内部命令。 第四顺位执行按照$PATH环境变量定义的目录查找顺序找到的第一个命令。 让别名永久生效 1[root@localhost ~]# vi /root/.bashrc 删除别名 1[root@localhost ~]# unalias 别名 Bash常用快捷键 快捷键 作用 ctrl+A 把光标移动到命令行开头。如果我们输入的命令过长,想要把光标移动到命令行开头时使用。 ctrl+E 把光标移动到命令行结尾。 ctrl+C 强制终止当前的命令。 ctrl+L 清屏,相当于clear命令。 ctrl+U 删除或剪切光标之前的命令。我输入了一行很长的命令,不用使用退格键一个一个字符的删除,使用这个快捷键会更加方便 ctrl+K 删除或剪切光标之后的内容。 ctrl+Y 粘贴ctrl+U或ctrl+K剪切的内容。 ctrl+R 在历史命令中搜索,按下ctrl+R之后,就会出现搜索界面,只要输入搜索内容,就会从历史命令中搜索。 ctrl+D 退出当前终端。 ctrl+Z 暂停,并放入后台。这个快捷键牵扯工作管理的内容,我们在系统管理章节详细介绍。 ctrl+S 暂停屏幕输出。 ctrl+Q 恢复屏幕输出 输入输出重定向标准输入输出 设备 设备文件夹 文件描述符 类型 键盘 /dev/stdin 0 标准输入 显示器 /dev/sdtout 1 标准输出 显示器 /dev/sdterr 2 标准错误输出 输出重定向 类型 符号 作用 标准输出重定向 命令 &gt; 文件 以覆盖的方式,把命令的正确输出输出到指定的文件或设备当中。 命令 &gt;&gt; 文件 以追加的方式,把命令的 正确输出输出到指定的文 件或设备当中。 标准错误输出重定向 错误命令 2&gt;文件 以覆盖的方式,把命令的 错误输出输出到指定的文 件或设备当中 错误命令 2&gt;&gt;文件 以追加的方式,把命令的 错误输出输出到指定的文 件或设备当中。 正确输出和错误输出同时保存 命令 &gt; 文件 2&gt;&amp;1 以覆盖的方式,把正确输 出和错误输出都保存到同 一个文件当中。 命令 &gt;&gt; 文件 2&gt;&amp;1 以追加的方式,把正确输出和错误输出都保存到同一个文件当中。 命令 &amp;&gt;文件 以覆盖的方式,把正确输出和错误输出都保存到同一个文件当中。 命令 &amp;&gt;&gt;文件 以追加的方式,把正确输出和错误输出都保存到同一个文件当中。 命令&gt;&gt;文件1 2&gt;&gt;文件2 把正确的输出追加到文件1中,把错误的输出追加到文件2中。 输入重定向[root@localhost ~]# wc [选项] [文件名]选项:-c 统计字节数-w 统计单词数-l 统计行数 命令&lt;文件 把文件作为命令的输入 命令&lt;&lt; 标识符…标识符 把标识符之间内容作为命令的输入 多命令顺序执行与管道符多命令顺序执行 多命令执行符 格式 作用 ; 命令1 ;命令2 多个命令顺序执行,命令之间没有任何逻辑联系 &amp;&amp; 命令1 &amp;&amp; 命令２ 逻辑与当命令1正确执行,则命令2才会执行当命令1执行不正确,则命令2不会执行 || 命令１||命令２ 逻辑或当命令1 执行不正确,则命令2才会执当命令1正确执行,则命令2不会执行 例子： 1[root@localhost ~]# ls ; date ; cd /user ; pwd [root@localhost ~]# dd if=输入文件 of=输出文件 bs=字节数 count=个数选项:if=输入文件 指定源文件或源设备of=输出文件 指定目标文件或目标设备bs=字节数 指定一次输入/输出多少字节,即把这些字节看做一个数据块count=个数 指定输入/输出多少个数据块 例子: 1234[root@localhost ~]# date ; dd if=/dev/zero of=/root/testfile bs=1k count=100000 ;date[root@localhost ~]# ls anaconda-ks.cfg &amp;&amp; echo yes[root@localhost ~]# ls /root/test || echo "no[root@localhost ~]# 命令 &amp;&amp; echo yes || echo no 管道符命令格式: 12[root@localhost ~]# 命令1 | 命令2# 命令 1 的正确输出作为命令 2 的操作对象 例子： 12[root@localhost ~]# ll -a /etc/ | more[root@localhost ~]# netstat -an | grep "ESTABLISHED" [root@localhost ~]# grep [选项] “搜索内容” 文件名选项:-i: 忽略大小写-n: 输出行号-v: 反向查找–color=auto 搜索出的关键字用颜色显示 通配符与其他特殊符号通配符 通配符 作用 ？ 匹配一个任意字符 * 匹配0个或任意多个任意字符,也就是可以匹配任何内容 [] 匹配中括号中任意一个字符。例如:[abc]代表一定匹配一个字符,或者是a,或者是b,或者是c。 [-] 匹配中括号中任意一个字符,-代表一个范围。例如:[a-z]代表匹配一个小写字母。 [^] 逻辑非,表示匹配不是中括号内的一个字符。例如:[^0-9]代表匹配一个不是数字的字符。 123456789[root@localhost ~]# cd /tmp/[root@localhost tmp]# rm -rf *[root@localhost tmp]# touch abc[root@localhost tmp]# touch abcd[root@localhost tmp]# touch 012[root@localhost tmp]# touch 0abc[root@localhost tmp]# ls ?abc[root@localhost tmp]# ls [0-9]*[root@localhost tmp]# ls [^0-9]* Bash中其他特殊符号 符号 作用 ‘ ‘ 单引号。在单引号中所有的特殊符号,如“$”和“`”(反引号)都没有特殊含义 “” 双引号。在双引号中特殊符号都没有特殊含义,但是“$”、“`”和“\”是例外,拥有“调用变量的值”、“引用命令”和“转义符”的特殊含义。 `` 反引号。反引号括起来的内容是系统命令,在Bash中会先执行它。和$()作用一样,不过推荐使用$(),因为反引号非常容易看错。 $() 和反引号作用一样,用来引用系统命令 # 在Shell脚本中,#开头的行代表注释。 $ 用于调用变量的值,如需要调用变量name的值时,需要用$name的方式得到变量的值 \ 转义符,跟在\之后的特殊符号将失去特殊含义,变为普通字符。如$将输出“$”符号,而不当做是变量引用。 例子： 12345678910反引号与$()[root@localhost ~]# echo `ls`[root@localhost ~]# echo $(date)单引号与双引号[root@localhost ~]# name=sc[root@localhost ~]# echo '$name'[root@localhost ~]# echo "$name"[root@localhost ~]# echo ‘$(date)'[root@localhost ~]# echo “$(date)" Bash的变量用户自定义变量 什么是变量 变量是计算机内存的单元,其中存放的值可以改变。当Shell脚本需要保存一些信息时,如一个文件名或是一个数字,就把它存放在一个变量中。每个变量有一个名字,所以很容易引用它。使用变量可以保存有用信息,使系统获知用户相关设置,变量也可以用于保存暂时信息。 变量设置规则 变量名称可以由字母、数字和下划线组成,但是不能以数字开头。如果变量名是“2name”则是错误的。 在Bash中,变量的默认类型都是字符串型,如果要进行数值运算,则必修指定变量类型为数值型。 变量用等号连接值,等号左右两侧不能有空格。 变量的值如果有空格,需要使用单引号或双引号包括。 在变量的值中,可以使用“\”转义符。 如果需要增加变量的值,那么可以进行变量值的叠加。不过变量需要用双引号包含“$变量名”或用${变量名}包含。 如果是把命令的结果作为变量值赋予变量,则需要使用反引号或$()包含命令。 环境变量名建议大写,便于区分。 变量分类 用户自定义变量 环境变量:这种变量中主要保存的是和系统操作环境相关的数据。 位置参数变量:这种变量主要是用来向脚本当中传递参数或数据的,变量名不能自定义,变量作用是固定的。 预定义变量:是Bash中已经定义好的变量,变量名不能自定义,变量作用也是固定的。 本地变量 变量定义 1[root@localhost ~]# name="finyorke" 变量叠加 123[root@localhost ~]# aa=123[root@localhost ~]# aa="$aa"456[root@localhost ~]# aa=$&#123;aa&#125;789 变量调用 1[root@localhost ~]# echo $name 变量查看 1[root@localhost ~]# set 变量删除 1[root@localhost ~]# unset name 环境变量 环境变量是什么用户自定义变量只在当前的Shell中生效,而环境变量会在当前Shell和这个Shell的所有子Shell当中生效。如果把环境变量写入相应的配置文件,那么这个环境变量就会在所有的Shell中生效 设置环境变量 export 变量名=变量值 #申明变量 env #查询变量 unset 变量名 #删除变量 系统常见环境变量 PATH:系统查找命令的路径 1[root@localhost ~]# echo $PATH PATH=”$PATH”:/root/sh#PATH 变量叠加 PS1:定义系统提示符的变量\d: 显示日期,格式为“星期 月 日”\h: 显示简写主机名。如默认主机名“localhost”\t: 显示24小时制时间,格式为“HH:MM:SS”\T: 显示12小时制时间,格式为“HH:MM:SS”\A: 显示24小时制时间,格式为“HH:MM”\u: 显示当前用户名\w: 显示当前所在目录的完整名称\W: 显示当前所在目录的最后一个目录\#: 执行的第几个命令\$: 提示符。如果是root用户会显示提示符为“#”,如果是普通用户会显示提 示符为“​$” 举例： 123[root@localhost ~]# PS1='[\u@\t \w]\$ '[root@04:50:08 /usr/local/src]#PS1='[\u@\@ \h \# \W]\$‘[root@04:53 上午 localhost 31 src]#PS1='[\u@\h \W]\$ ' 位置参数变量 位置参数变量 作用 $ｎ n为数字,$0代表命令本身,​$1-$9代表第一到第九个参数,十以上的参数需要用大括号包含,如${10} $* 这个变量代表命令行中所有的参数,$*把所有的参数看成一个整体 $0 这个变量也代表命令行中所有的参数,不过$@把每个参数区分对待 $# 这个变量代表命令行中所有参数的个数 例子： 例子1: 1234567#!/bin/bash num1=$1 num2=$2 sum=$(( $num1 + $num2)) #变量 sum 的和是 num1 加 num2 echo $sum #打印变量 sum 的值 例子２： 123456789#!/bin/bashecho "A total of $# parameters"#使用 $# 代表所有参数的个数echo "The parameters is: $*"#使用 $* 代表所有的参数echo "The parameters is: $@"#使用 $@ 也代表所有参数 例子3:$*与$@的区别 12345678910111213#!/bin/bashfor i in "$*"#$* 中的所有参数看成是一个整体,所以这个 for 循环只会循环一次doecho "The parameters is: $i"donex=1for y in "$@"#$@ 中的每个参数都看成是独立的,所以“ $@ ”中有几个参数,就会循环几次doecho "The parameter$x is: $y"x=$(( $x +1 ))done 预定义变量 预定义变量 作用 $? 最后一次执行的命令的返回状态。如果这个变量的值为0,证明上一个命令正确执行;如果这个变量的值为非0(具体是哪个数,由命令自己来决定),则证明上一个命令执行不正确了。 $$ 当前进程的进程号(PID) $! 后台运行的最后一个进程的进程号(PID) 12345678910#!/bin/bash# Author: shenchao (E-mail: shenchao@lampbrother.net)echo &quot;The current process is $$&quot;# 输出当前进程的 PID 。# 这个 PID 就是 variable.sh 这个脚本执行时,生成的进程的 PIDfind /root -name hello.sh &amp;# 使用 find 命令在 root 目录下查找 hello.sh 文件# 符号 &amp; 的意思是把命令放入后台执行,工作管理我们在系统管理章节有详细介绍echo &quot;The last one Daemon process is $!&quot; 接收键盘输入 [root@localhost ~]# read [选项] [变量名]选项:-p “提示信息”: 在等待read输入时,输出提示信息-t 秒数: read命令会一直等待用户输入,使用此选项可以指定等待时间-n 字符数: read命令只接受指定的字符数,就会执行-s: 隐藏输入的数据,适用于机密信息的输入 12345678910111213#!/bin/bash# Author: shenchao (E-mail: shenchao@lampbrother.net)read -t 30 -p "Please input your name: " name# 提示“请输入姓名”并等待 30 秒,把用户的输入保存入变量 name 中echo "Name is $name "read -s -t 30 -p "Please enter your age: " age# 年龄是隐私,所以我们用“ -s ”选项隐藏输入echo -e "\n"echo "Age is $age "read -n 1 -t 30 -p "Please select your gender[M/F]: " gender# 使用“ -n 1 ”选项只接收一个输入字符就会执行(都不用输入回车)echo -e "\n"echo "Sex is $gender" Bash的运算符数值运算与运算符 declare声明变量类型[root@localhost ~]# declare [+/-][选项] 变量名选项:-: 给变量设定类型属性+: 取消变量的类型属性-i: 将变量声明为整数型(integer)-x: 将变量声明为环境变量-p: 显示指定变量的被声明的类型 数值运算 方法一： 1234[root@localhost ~]# aa=11[root@localhost ~]# bb=22# 给变量 aa 和 bb 赋值[root@localhost ~]# declare -i cc=$aa+$bb 方法二:expr或let数值运算工具 123456[root@localhost ~]# aa=11[root@localhost ~]# bb=22# 给变量 aa 和变量 bb 赋值[root@localhost ~]# dd=$(expr $aa + $bb)#dd 的值是 aa 和 bb 的和。注意“ + ”号左右两侧必须有空格 方法3:“$((运算式))”或“$[运算式]” 1234[root@localhost ~]# aa=11[root@localhost ~]# bb=22[root@localhost ~]# ff=$(( $aa+$bb ))[root@localhost ~]# gg=$[ $aa+$bb ] 运算符 优先级 运算符 说明 13 -, + 单目负、单目正 12 !, ~ 逻辑非、按位取反或补码 11 * , / , % 乘、除、取模 10 +, - 加、减 9 &lt;&lt; , &gt;&gt; 按位左移、按位右移 8 &lt; =, &gt; =, &lt; , &gt; 小于或等于、大于或等于、小于、大于 7 == , != 等于、不等于 6 &amp; 按位与 5 ^ 按位异或 4 | 按位或 3 &amp;&amp; 逻辑与 2 || 逻辑或 1 =,+=,-=,*=,/=,%=,&amp;=, ^=,=, &lt;&lt;=, &gt;&gt;= 赋值、运算且赋值 1234567[root@localhost ~]# aa=$(( (11+3)*3/2 ))# 虽然乘和除的优先级高于加,但是通过小括号可以调整运算优先级[root@localhost ~]# bb=$(( 14%3 ))#14 不能被 3 整除,余数是 2[root@localhost ~]# cc=$(( 1 &amp;&amp; 0 ))# 逻辑与运算只有想与的两边都是 1 ,与的结果才是 1 ,否则与的结果是 0 变量测试与内容替换 变量置换方式 变量y没有设置 变量y为空值 变量y设置值 x=${y-新值} x=新值 x为空 x=$y x=${y:-新值} x=新值 x=新值 x=$y x=${y+新值} x为空 x=新值 x=新值 x=${y:+新值} x为空 x为空 x=新值 x=${y=新值} x=新值y=新值 x为空y值不变 x=$yy值不变 x=${y:=新值} x=新值y=新值 x=新值y=新值 x=$yy值不变 x=${y?新值} 新值输出到标准错误输出(就是屏幕) x为空 x=$y x=${y:?新值} 新值输出到标准错误输出 新值输出到标准错误输出 x=$y 例子：测试x=${y-新值} 1234567[root@localhost ~]# unset y# 删除变量 y[root@localhost ~]# x=$&#123;y-new&#125;# 进行测试[root@localhost ~]# echo $xnew# 因为变量 y 不存在,所以 x=new 12345[root@localhost ~]# y=""# 给变量 y 赋值为空[root@localhost ~]# x=$&#123;y-new&#125;# 进行测试[root@localhost ~]# echo $x 123456[root@localhost ~]# y=old# 给变量 y 赋值[root@localhost ~]# x=$&#123;y-new&#125;# 进行测试[root@localhost ~]# echo $xold 环境变量配置文件环境变量配置文件简介 source命令 123[root@localhost ~]# source 配置文件或[root@localhost ~]# . 配置文件 环境变量配置文件简介 环境变量配置文件中主要是定义对系统的操作环境生效的系统默认环境变量,比如PATH、HISTSIZE、PS1、HOSTNAME等默认环境变量。 /etc/profile /etc/profile.d/*.sh ~/.bash_profile ~/.bashrc /etc/bashrc 环境变量配置文件作用 /etc/profile /etc/profile.d/*.sh ~/.bash_profile ~/.bashrc /etc/bashrc /etc/profile的作用: USER变量: LOGNAME变量: MAIL变量: PATH变量: HOSTNAME变量: HISTSIZE变量: umask: 调用/etc/profile.d/*.sh文件 ~/.bash_profile的作用 调用了~/.bashrc文件。 在PATH变量后面加入了“:$HOME/bin”这个目录 ~/.bashrc的作用 定义默认别名 调用/etc/bashrc /etc/bashrc的作用 PS1变量 umask PATH变量 调用/etc/profile.d/*.sh文件 其他配置文件和登录信息 注销时生效的环境变量配置文件~/.bash_logout 其他配置文件~/bash_history Shell登录信息 本地终端欢迎信息: /etc/issue 转义符 作用 \d 显示当前系统日期 \s 显示操作系统名称 \l 显示登录的终端号,这个比较常用。 \m 显示硬件体系结构,如i386、i686等 \n 显示主机名 \o 显示域名 \r 显示内核版本 \t 显示当前系统时间 \u 显示当前登录用户的序列号 远程终端欢迎信息: /etc/issue.net 转义符在/etc/issue.net文件中不能使用 是否显示此欢迎信息,由ssh的配置文件/etc/ssh/sshd_config决定,加入“Banner/etc/issue.net”行才能显示(记得重启SSH服务) 登陆后欢迎信息:/etc/motd不管是本地登录,还是远程登录,都可以显示此欢迎信息 Shell编程基础正则表达式正则表达式与通配符 正则表达式用来在文件中匹配符合条件的字符串,正则是包含匹配。grep、awk、sed等命令可以支持正则表达式。 通配符用来匹配符合条件的文件名,通配符是完全匹配。ls、find、cp这些命令不支持正则表达式,所以只能使用shell自己的通配符来进行匹配了。 基础正则表达式 元字符 作用 * 前一个字符匹配0次或任意多次。 . 匹配除了换行符外任意一个字符。 ^ 匹配行首。例如:^hello会匹配以hello开头的行。 $ 匹配行尾。例如:hello&amp;会匹配以hello结尾的行。 [] 匹配中括号中指定的任意一个字符,只匹配一个字符。例如:[aoeiu] 匹配任意一个元音字母,[0-9] 匹配任意一位数字, [a-z][0-9]匹配小写字和一位数字构成的两位字符。 [^] 匹配除中括号的字符以外的任意一个字符。例如:[^0-9] 匹配任意一位非数字字符,[^a-z] 表示任意一位非小写字母。 \ 转义符。用于取消讲特殊符号的含义取消。 \{n\} 表示其前面的字符恰好出现n次。例如:[0-9]\{4\} 匹配4位数字,[1][3-8][0-9]{9} 匹配手机号码。 \{n,\} 表示其前面的字符出现不小于n次。例如: [0-9]\{2,\} 表示两位及以上的数字。 \{n,m\} 表示其前面的字符至少出现n次,最多出现m次。例如: [a-z]\{6,8\} 匹配6到8位的小写字母。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162“*”前一个字符匹配0次,或任意多次:grep &quot;a*&quot; test_rule.txt# 匹配所有内容,包括空白行grep &quot;aa*&quot; test_rule.txt# 匹配至少包含有一个 a 的行grep &quot;aaa*&quot; test_rule.txt匹配最少包含两个连续a的字符串grep &quot;aaaaa*&quot; test_rule.txt#则会匹配最少包含四个个连续a的字符串“.” 匹配除了换行符外任意一个字符:grep &quot;s..d&quot; test_rule.txt# “ s..d ”会匹配在 s 和 d 这两个字母之间一定有两个字符的单词grep &quot;s.*d&quot; test_rule.txt# 匹配在 s 和 d 字母之间有任意字符grep &quot;.*&quot; test_rule.txt# 匹配所有内容“^”匹配行首,“$”匹配行尾:grep &quot;^M&quot; test_rule.txt# 匹配以大写“ M ”开头的行grep &quot;n$&quot; test_rule.txt# 匹配以小写“ n ”结尾的行grep &quot;^M.*n$&quot; test_rule.txt# 匹配以大写“ M ”开头,以小写“ n ”结尾的行grep -n &quot;^$&quot; test_rule.txt# 会匹配空白行“[]” 匹配中括号中指定的任意一个:字符,只匹配一个字符grep &quot;s[ao]id&quot; test_rule.txt# 匹配 s 和 i 字母中,要不是 a 、要不是 ogrep &quot;[0-9]&quot; test_rule.txt# 匹配任意一个数字grep &quot;^[a-z]&quot; test_rule.txt# 匹配用小写字母开头的行“[^]” 匹配除中括号的字符以外的:任意一个字符grep &quot;^[^a-z]&quot; test_rule.txt# 匹配不用小写字母开头的行grep &quot;^[^a-zA-Z]&quot; test_rule.txt# 匹配不用字母开头的行“\” 转义符:grep &quot;\.$&quot; test_rule.txt# 匹配使用“ . ”结尾的行“\&#123;n\&#125;”表示其前面的字符恰好出现n次:grep &quot;a\&#123;3\&#125;&quot; test_rule.txt# 匹配 a 字母连续出现三次的字符串grep &quot;[0-9]\&#123;3\&#125;&quot; test_rule.txt# 匹配包含连续的三个数字的字符串“\&#123;n,\&#125;”表示其前面的字符出现不小于n次grep &quot;^[0-9]\&#123;3,\&#125;[a-z]&quot; test_rule.txt# 匹配最少用连续三个数字开头的行“\&#123;n,m\&#125;”匹配其前面的字符至少出现n次,最多出现m次grep &quot;sa\&#123;1,3\&#125;i&quot; test_rule.txt# 匹配在字母 s 和字母 i 之间有最少一个 a ,最多三个 a 字符截取命令cut字段提取命令[root@localhost ~]# cut [选项] 文件名选项:-f 列号: 提取第几列-d 分隔符: 按照指定分隔符分割列 eg: 123[root@localhost ~]# cut -f 2 student.txt[root@localhost ~]# cut -f 2,3 student.txt[root@localhost ~]# cut -d ":" -f 1,3 etc/passwd cut命令的局限 1[root@localhost ~]# df -h | cut -d " " -f 1,3 printf命令printf ’输出类型输出格式’ 输出内容输出类型:%ns: 输出字符串。n是数字指代输出几个字符%ni: 输出整数。n是数字指代输出几个数字%m.nf: 位数和小数位数。如%8.2f代表共输出8位数,其中2位是小数,6位是整数。 输出格式:\a: 输出警告声音\b: 输出退格键,也就是Backspace键\f: 清除屏幕\n: 换行\r: 回车,也就是Enter键\t: 水平输出退格键,也就是Tab键\v: 垂直输出退格键,也就是Tab键 12345678910111213[root@localhost ~]# printf %s 1 2 3 4 5 6[root@localhost ~]# printf %s %s %s 1 2 3 4 5 6[root@localhost ~]# printf '%s %s %s' 1 2 3 4 5 6[root@localhost ~]# printf '%s %s %s\n' 1 2 3 4 5 6[root@localhost ~]# vi student.txtID Name PHP Linux MySQL Average1 Liming 82 95 86 87.662 Sc 74 96 87 85.663 Gao 99 83 93 91.66[root@localhost ~]# printf '%s' $(cat student.txt)#不调整输出格式[root@localhost ~]# printf '%s\t %s\t %s\t %s\t %s\t %s\t \n' $(cat student.txt)#调整格式输出 在awk命令的输出中支持print和printf命令 print:print会在每个输出之后自动加入一个换行符(Linux默认没有print命令) printf:printf是标准格式输出命令,并不会自动加入换行符,如果需要换行,需要手工加入换行符 awk命令123456789[root@localhost ~]# awk ‘条件1&#123;动作1&#125; 条件2&#123;动作2&#125;...’ 文件名----条件(Pattern):一般使用关系表达式作为条件x &gt; 10 判断变量 x是否大于10x&gt;=10 大于等于x&lt;=10 小于等于----动作(Action):格式化输出流程控制语句 1234567[root@localhost ~]# vi student.txtID Name PHP Linux MySQL Average1 Liming 82 95 86 87.662 Sc 74 96 87 85.663 Gao 99 83 93 91.66[root@localhost ~]# awk '&#123;printf $2 "\t" $6 "\n"&#125;' student.txt[root@localhost ~]# df -h | awk '&#123;print $1 "\t" $3&#125;' BEGIN 1# awk 'BEGIN&#123;printf "This is a transcript \n" &#125;&#123;printf $2 "\t" $6 "\n"&#125;' student.txt END 1# awk 'END&#123;printf "The End \n" &#125; &#123;printf $2 "\t" $6 "\n"&#125;' student.txt FS内置变量 1# cat /etc/passwd | grep "/bin/bash" | \awk 'BEGIN &#123;FS=":"&#125; &#123;printf $1 "\t" $3 "\n"&#125;' 关系运算符 1# cat student.txt | grep -v Name | \awk '$6 &gt;= 87 &#123;printf $2 "\n" &#125;' sed命令 sed 是一种几乎包括在所有 UNIX 平台( 包括 Linux)的轻量级流编辑器。sed主要 是用来将数据进行选取、替换、删除、新 增的命令。 12345678910111213141516[root@localhost ~]# sed [选项] ‘[动作]’ 文件名选项:-n: 一般sed命令会把所有数据都输出到屏幕 ,如果加入此选择,则只会把经过 sed命令处理的行输出到屏幕-e: 允许对输入数据应用多条sed命令编辑-i: 用sed的修改结果直接修改读取数据的文件,而不是由屏幕输出动作:a\: 追加,在当前行后添加一行或多行。添加多行时,除最后 一行 外,每行末尾需要用“\”代表数据未完结。c\: 行替换,用c后面的字符串替换原数据行,替换多行时,除最 后一行外,每行末尾需用“\”代表数据未完结。i\: 插入,在当期行前插入一行或多行。插入多行时,除最后 一行 ,每行末尾需要用“\”代表数据未完结。d: 删除,删除指定的行。p: 打印,输出指定的行。s: 字串替换,用一个字符串替换另外一个字符串。格式为“行范 围s/旧字串/新字串/g”(和vim中的替换格式类似) 。 学生成绩表 12345[root@localhost ~]# vi student.txtID Name PHP Linux MySQL Average1 Liming 82 95 86 87.662 Sc 74 96 87 85.663 Gao 99 83 93 91.66 行数据操作 1234567891011[root@localhost ~]# sed '2p' student.txt#查看文件的第二行[root@localhost ~]# sed -n '2p' student.txt[root@localhost ~]# sed '2,4d' student.txt# 删除第二行到第四行的数据,但不修改文件本身[root@localhost ~]# sed '2a hello' student.txt# 在第二行后追加 hello[root@localhost ~]# sed '2i hello \world' student.txt# 在第二行前插入两行数据# sed '2c No such person‘ student.txt# 数据替换 字符串替换 1234567# sed ‘s/旧字串/新字串/g’ 文件名# sed '3s/74/99/g' student.txt# 在第三行中,把 74 换成 99#sed -i '3s/74/99/g' student.txt#sed操作的数据直接写入文件# sed -e 's/Liming//g ; s/Gao//g' student.txt# 同时把“ Liming ”和“ Gao ”替换为空 字符处理命令排序命令sort[root@localhost ~]# sort [选项] 文件名选项:-f: 忽略大小写-n: 以数值型进行排序,默认使用字符串型排序-r: 反向排序-t: 指定分隔符,默认是分隔符是制表符-k n[,m]: 按照指定的字段范围排序。从第n字段开始,m字段结束(默认到行尾) 12345678[root@localhost ~]# sort /etc/passwd# 排序用户信息文件[root@localhost ~]# sort -r /etc/passwd# 反向排序[root@localhost ~]# sort -t ":" -k 3,3 /etc/passwd# 指定分隔符是“:”,用第三字段开头,第三字段结尾排序,就是只用第三字段排序[root@localhost ~]# sort -n -t ":" -k 3,3 /etc/passwd 统计命令wc[root@localhost ~]# wc [选项] 文件名选项:-l: 只统计行数-w: 只统计单词数-m: 只统计字符数 条件判断 按照文件类型进行判断 测试选项 作用 -b 文件 判断该文件是否存在,并且是否为块设备文件(是块设备文件 为真) -c 文件 判断该文件是否存在,并且是否为字符设备文件(是字符设备 文件为真) -d 文件 判断该文件是否存在,并且是否为目录文件(是目录为真) -e 文件 判断该文件是否存在(存在为真) -f 文件 判断该文件是否存在,并且是否为普通文件(是普通文件为真) -L 文件 判断该文件是否存在,并且是否为符号链接文件(是符号链接 文件为真) -p 文件 判断该文件是否存在,并且是否为管道文件(是管道文件为真) -s 文件 判断该文件是否存在,并且是否为非空(非空为真) -S 文件 判断该文件是否存在,并且是否为套接字文件(是套接字文件 为真) 两种判断格式 12345[root@localhost ~]# test -e /root/install.log[root@localhost ~]# [ -e /root/install.log ][ -d /root ] &amp;&amp; echo "yes" || echo "no"# 第一个判断命令如果正确执行,则打印“ yes ”,否则打印“ no ” 按照文件权限进行判断 测试选项 作用 -r 判断该文件是否存在,并且是否该文件拥有读权限(有读 权限为真) -w 判断该文件是否存在,并且是否该文件拥有写权限(有写 权限为真) -x 判断该文件是否存在,并且是否该文件拥有执行权限(有执行权限为真) -u 判断该文件是否存在,并且是否该文件拥有SUID权限(有SUID权限为真) -g 判断该文件是否存在,并且是否该文件拥有SGID权限(有SGID权限为真) -k 判断该文件是否存在,并且是否该文件拥有SBit权限(有SBit权限为真) 12[ -w student.txt ] &amp;&amp; echo &quot;yes&quot; || echo &quot;no&quot;# 判断文件是拥有写权限的 两个文件之间进行比较 测试选项 作用 文件1 -nt 文件2 判断文件1的修改时间是否比文件2的新(如果新则为真) 文件1 -ot 文件2 判断文件1的修改时间是否比文件2的旧(如果旧则为真) 文件1 -ef 文件2 判断文件1是否和文件2的Inode号一致,可以理解为两个文件是否为同一个文件。这个判断用于判断硬链接是很好的方法 12345ln /root/student.txt /tmp/stu.txt# 创建个硬链接吧[ /root/student.txt -ef /tmp/stu.txt ] &amp;&amp; echo &quot;yes&quot; || echo &quot;no&quot;yes# 用 test 测试下,果然很有用 两个整数之间比较 测试选项 作用 整数1 -eq 整数２ 判断整数1是否和整数2相等(相等为真) 整数1 -ne 整数２ 判断整数1是否和整数2不相等(不相等位置) 整数1 -gt 整数2 判断整数1是否大于整数2(大于为真) 整数1 -lt 整数2 判断整数1是否小于整数2(小于位置) 整数1 -ge 整数2 判断整数1是否大于等于整数2(大于等于为真) 整数1 -le 整数2 判断整数1是否小于等于整数2(小于等于为真) 123456[ 23 -ge 22 ] &amp;&amp; echo &quot;yes&quot; || echo &quot;no&quot;yes# 判断 23 是否大于等于 22 ,当然是了[ 23 -le 22 ] &amp;&amp; echo &quot;yes&quot; || echo &quot;no&quot;no# 判断 23 是否小于等于 22 ,当然不是了 字符串的判断 测试选项 作用 -z 字符串 判断字符串是否为空(为空返回真) -n 字符串 判断字符串是否为非空(非空返回真) 字串1 ==字串2 判断字符串1是否和字符串2相等(相等返回真) 字串1 != 字串2 判断字符串1是否和字符串2不相等(不相等返回真) 12345678910111213name=sc# 给 name 变量赋值[ -z &quot;$name&quot; ] &amp;&amp; echo &quot;yes&quot; || echo &quot;no&quot;no# 判断 name 变量是否为空,因为不为空,所以返回 noaa=11bb=22# 给变量 aa 和变量 bb 赋值[ &quot;$aa&quot; == &quot;bb&quot; ] &amp;&amp; echo &quot;yes&quot; || echo &quot;no&quot;no# 判断两个变量的值是否相等,明显不相等,所以返回 no 多重条件判断 测试选项 作用 判断1 -a 判断2 逻辑与,判断1和判断2都成立,最终的结果才为真 判断1 -o 判断2 逻辑或,判断1和判断2有一个成立,最终的结果就为真 !判断 逻辑非,使原始的判断式取反 123456789aa=11[ -n &quot;$aa&quot; -a &quot;$aa&quot; -gt 23 ] &amp;&amp; echo &quot;yes&quot; || echo &quot;no&quot;no# 判断变量 aa 是否有值,同时判断变量 aa 的是否大于 23# 因为变量 aa 的值不大于 23 ,所以虽然第一个判断值为真,返回的结果也是假aa=24[ -n &quot;$aa&quot; -a &quot;$aa&quot; -gt 23 ] &amp;&amp; echo &quot;yes&quot; || echo &quot;no&quot;yes 流程控制if语句 单分支if条件语句 12345678if [ 条件判断式 ];then 程序fi或者if [ 条件判断式 ] then 程序fi 单分支条件语句需要注意几个点 if语句使用fi结尾,和一般语言使用大括号结尾不同 [ 条件判断式 ]就是使用test命令判断,所以中括号和条件判断式之间必须有空格 then后面跟符合条件之后执行的程序,可以放在[]之后,用“;”分割。也可以换行写入,就不需要“;”了 例子:判断分区使用率 123456789#!/bin/bash#统计根分区使用率# Author: finyorkorate=$(df -h | grep "/dev/sda3" | awk '&#123;print $5&#125;' | cut -d "%" -f1)#把根分区使用率作为变量值赋予变量 rateif [ $rate -ge 80 ] then echo "Warning! /dev/sda3 is full!!"fi 双分支if条件语句 123456if [ 条件判断式 ] then 条件成立时,执行的程序 else 条件不成立时,执行的另一个程序fi 例子1:备份mysql数据库 123456789101112131415161718192021222324#!/bin/bash#备份 mysql 数据库。# Author: finyorkontpdate asia.pool.ntp.org &amp;&gt;/dev/null#同步系统时间date=$(date +%y%m%d)#把当前系统时间按照“年月日”格式赋予变量 datesize=$(du -sh /var/lib/mysql)#统计 mysql 数据库的大小,并把大小赋予 size 变量if [ -d /tmp/dbbak ] then echo "Date : $date!" &gt; /tmp/dbbak/dbinfo.txt echo "Data size : $size" &gt;&gt; /tmp/dbbak/dbinfo.txt cd /tmp/dbbak tar -zcf mysql-lib-$date.tar.gz /var/lib/mysql &amp;&gt;/dev/null rm -rf /tmp/dbbak/dbinfo.txt else mkdir /tmp/dbbak echo "Date : $date!" &gt; /tmp/dbbak/dbinfo.txt echo "Data size : $size" &gt;&gt; /tmp/dbbak/dbinfo.txt cd /tmp/dbbak dbinfo.txt tar -zcf mysql-lib-$date.tar.gz /var/lib/mysql dbinfo.txt &amp;&gt;/dev/null rm -rf /tmp/dbbak/dbinfo.txtfi 例子2:判断apache是否启动 1234567891011#!/bin/bash# Author: finyorkoport=$(nmap -sT 192.168.1.156 | grep tcp | grep http | awk &apos;&#123;print $2&#125;&apos;)#使用nmap命令扫描服务器,并截取apache服务的状态,赋予变量portif [ &quot;$port&quot; == &quot;open&quot; ] then echo “$(date) httpd is ok!” &gt;&gt; /tmp/autostart-acc.log else /etc/rc.d/init.d/httpd start &amp;&gt;/dev/null echo &quot;$(date) restart httpd !!&quot; &gt;&gt; /tmp/autostart-err.logfi 多分支if条件语句 12345678910if [ 条件判断式1 ] then 当条件判断式1成立时,执行程序1elif [ 条件判断式2 ] then 当条件判断式2成立时,执行程序2„省略更多条件 ...else 当所有条件都不成立时,最后执行此程序fi 1234567891011121314151617181920212223242526#!/bin/bash#判断用户输入的是什么文件# Author: finyorkoread -p "Please input a filename: " file#接收键盘的输入,并赋予变量 fileif [ -z "$file" ]#判断 file 变量是否为空 then echo "Error,please input a filename" exit 1elif [ ! -e "$file" ]#判断 file 的值是否存在 then echo "Your input is not a file!" exit 2elif [ -f "$file" ]#判断 file 的值是否为普通文件 then echo "$file is a regulare file!"elif [ -d "$file" ]#判断 file 的值是否为目录文件 then echo "$file is a directory!"else echo "$file is an other file!"fi case语句多分支case条件语句 case语句和if…elif…else语句一样都是多分支条件语句,不过和if多分支条件语句不同的是,case语句只能判断一种条件关系,而if语句可以判断多种条件关系。 123456789101112case $变量名 in "值1") 如果变量的值等于值1,则执行程序1 ;; "值2") 如果变量的值等于值2,则执行程序2 ;; ...省略其他分支... *) 如果变量的值都不是以上的值,则执行此程序 ;;esac 123456789101112131415#!/bin/bash#判断用户输入# Author: finyorkoread -p "Please choose yes/no: " -t 30 chocase $cho in "yes") echo "Your choose is yes!" ;; "no") echo "Your choose is no!" ;; *) echo "Your choose is error!" ;;esac for循环 语法一 1234for 变量 in 值1 值2 值3... do 程序 done 1234567#!/bin/bash#打印时间# Author: finyorkpfor time in morning noon afternoon evening do echo "This time is $time!" done 12345678910#!/bin/bash#批量解压缩脚本# Author: finyorkocd /lampls *.tar.gz &gt; ls.logfor i in $(cat ls.log) do tar -zxf $i &amp;&gt;/dev/null donerm -rf /lamp/ls.log 语法二 1234for (( 初始值;循环控制条件;变量变化 )) do 程序 done 12345678910#!/bin/bash# 从 1 加到 100# Author: finyorkos=0for (( i=1;i&lt;=100;i=i+1 )) do s=$(( $s+$i )) doneecho "The sum of 1+2+...+100 is : $s" 123456789101112131415161718#!/bin/bash#批量添加指定数量的用户# Author: finyorkoread -p "Please input user name: " -t 30 nameread -p "Please input the number of users: " -t 30 numread -p "Please input the password of users: " -t 30 passif [ ! -z "$name" -a ! -z "$num" -a ! -z "$pass" ] then y=$(echo $num | sed 's/[0-9]//g') if [ -z "$y" ] then for (( i=1;i&lt;=$num;i=i+1 )) do /usr/sbin/useradd $name$i &amp;&gt;/dev/null echo $pass | /usr/bin/passwd --stdin$name$i &amp;&gt;/dev/null done fifi while循环与until循环 while循环while循环是不定循环,也称作条件循环 。只要条件判断式成立,循环就会一直继 续,直到条件判断式不成立,循环才会停 止。这就和for的固定循环不太一样了。 1234while [ 条件判断式 ] do 程序 done 12345678910111213#!/bin/bash#从1加到100# Author: finyorkoi=1s=0while [ $i -le 100 ]#如果变量 i 的值小于等于 100 ,则执行循环 do s=$(( $s+$i )) i=$(( $i+1 )) doneecho "The sum is: $s" until循环until循环,和while循环相反,until循环时 只要条件判断式不成立则进行循环,并执 行循环程序。一旦循环条件成立,则终止 循环。 1234until [ 条件判断式 ] do 程序 done 12345678910111213#!/bin/bash#从1加到100# Author: finyorkoi=1s=0until [ $i -gt 100 ]#循环直到变量 i 的值大于 100 ,就停止循环 do s=$(( $s+$i )) i=$(( $i+1 )) doneecho "The sum is: $s" Linux服务管理服务简介与分类123456graph LRA[Linux服务] A --&gt;D[RPM包安装的服务] A --&gt;E[源码包安装的服务] D --&gt;F[独立的服务] D --&gt;G[基于xinetd服务] 启动与自启动 服务启动:就是在当前系统中让服务运行,并提供功能。 服务自启动:自启动是指让服务在系统开机或重启动之后,随着系统的启动而自动启动服务。 查询已安装的服务 RPM包安装的服务 chkconfig –list ​ #查看服务自启动状态,可以看到所有 RPM 包安装的服务 源码包安装的服务查看服务安装位置,一般是/usr/local/下 RPM安装服务和源码包安装服务的区别 RPM安装服务和源码包安装服务的区别就是安装位置的不同 RPM包安装服务的管理独立服务的管理 RPM包安装服务的位置 RPM安装服务和源码包安装服务的区别就是安装位置的不同 源码包安装在指定位置,一般是/usr/local/ RPM包安装在默认位置中 /etc/init.d/:启动脚本位置 /etc/sysconfig/:初始化环境配置文件位置 /etc/:配置文件位置 /etc/xinetd.conf:xinetd配置文件 /etc/xinetd.d/:基于xinetd服务的启动脚本 /var/lib/:服务产生的数据放在这里 /var/log/:日志 独立服务的启动 /etc/init.d/独立服务名 start|stop|status|restart| service 独立服务名 start|stop|restart||status 独立服务的自启动 chkconfig [–level 运行级别] [独立服务名] [on|off] 修改/etc/rc.d/rc.local文件 使用ntsysv命令管理自启动 基于xinetd服务的管理 安装xinetd与telnet 12[root@localhost ~]# yum -y install xinetd[root@localhost ~]# yum -y install telnet-server xinetd服务的启动 1234567891011[root@localhost ~]# vi /etc/xinetd.d/telnetservice telnet #服务的名称为 telnet&#123;flags = REUSE #标志为 REUSE ,设定 TCP/IP socket 可重用socket_type = stream #使用 TCP 协议数据包wait = no #允许多个连接同时连接user= root #启动服务的用户为 rootserver= /usr/sbin/in.telnetd #服务的启动程序log_on_failure += USERID #登陆失败后,记录用户的 IDdisable= no #服务不启动&#125; 重启xinetd服务 ~]# service xinetd restart```123456789101112131415161718192021222324252627282930313233343. xinetd服务的自启动 - `[root@localhost ~]# chkconfig telnet on` - `ntsysv`### 源码包安装服务的管理1. 源码包安装服务的启动 - 使用绝对路径,调用启动脚本来启动。不同的源码包的启动脚本不同。可以查看源码包的安装说明,查看启动脚本的方法。 - /usr/local/apache2/bin/apachectl start|stop2. 源码包服务的自启动 `[root@localhost ~]# vi /etc/rc.d/rc.local` 加入 `/usr/local/apache2/bin/apachectl start`3. 让源码包服务被服务管理命令识别 - 让源码包的apache服务能被service命令管理启动 `ln -s /usr/local/apache2/bin/apachectl /etc/init.d/apache` - 让源码包的apache服务能被chkconfig与ntsysv命令管理自启动 ```bash vi /etc/init.d/apache # chkconfig: 35 86 76 # 指定 httpd 脚本可以被 chkconfig 命令管理 。 格式是: chkconfig : 运行级别 启动顺序 关闭顺序 # description: source package apache # 说明,内容随意 [root@localhost ~]# chkconfig --add apache #把源码包apache加入chkconfig命令 服务管理总结 Linux系统管理进程管理进程查看 进程简介进程是正在执行的一个程序或命令,每一个进程都是一个运行的实体,都有自己的地址空间,并占用一定的系统资源。 进程管理的作用 判断服务器健康状态 查看系统中所有进程 杀死进程 查看系统中所有进程 12345678910111213141516[root@localhost ~]# ps aux# 查看系统中所有进程,使用 BSD 操作系统格式[root@localhost ~]# ps -le# 查看系统中所有进程,使用 Linux 标准命令格式。USER:该进程是由哪个用户产生的;PID:进程的ID号;%CPU:该进程占用CPU资源的百分比,占用越高,进程越耗费资源;%MEM:该进程占用物理内存的百分比,占用越高,进程越耗费资源;VSZ:该进程占用虚拟内存的大小,单位KB;RSS:该进程占用实际物理内存的大小,单位KB;TTY:该进程是在哪个终端中运行的。其中tty1-tty7代表本地控制台终端,tty1-tty6是本地的字符界面终端,tty7是图形终端。pts/0-255代表虚拟终端。STAT:进程状态。常见的状态有:R:运行、S:睡眠、T:停止状态、s:包含子进 程、+:位于后台START:该进程的启动时间TIME:该进程占用CPU的运算时间,注意不是系统时间OMMAND:产生此进程的命令名 查看系统健康状态 123456789[root@localhost ~]# top [选项]选项:-d 秒数: 指定top命令每隔几秒更新。默认是3秒在top命令的交互模式当中可以执行的命令:?或h: 显示交互模式的帮助P: 以CPU使用率排序,默认就是此项M: 以内存的使用率排序N: 以PID排序q: 退出top 第一行信息为任务队列信息 内容 说明 12:26:46 系统当前时间 up 1 day, 13:32 系统的运行时间,本机已经运行1天13小时32分钟 2 users 当前登录了两个用户 load average:0.00,0.00, 0.00 系统在之前1分钟,5分钟,15分钟 的平均负载。一般认为小于1时,负载较小。如果大于1,系统已经超出负荷。 第二行为进程信息 内容 说明 Tasks: 95 total 系统中的进程总数 1 running 正在运行的进程数 94 sleeping 睡眠的进程 0 stopped 正在停止的进程 0 zombie 僵尸进程。如果不是0,需要手工检查僵尸进程 第三行为CPU信息 内容 说明 Cpu(s): 0.1%us 用户模式占用的CPU百分比 0.1%sy 系统模式占用的CPU百分比 0.0%ni 改变过优先级的用户进程占用的CPU百分比 99.7%id 空闲CPU的CPU百分比 0.1%wa 空闲CPU的CPU百分比比 0.0%hi 硬中断请求服务占用的CPU百分比 0.1%si 软中断请求服务占用的CPU百分比 0.0%st st(Steal time)虚拟时间百分比。就是当有虚拟机时 ,虚拟CPU等待实际CPU的时间百分比。 第四行为物理内存信息 内容 说明 Mem:625344k total 物理内存的总量,单位KB 571504k used 已经使用的物理内存数量 53840k free 空闲的物理内存数量,我们使用的是虚拟机,总共只分配了628MB内存,所以只有53MB的空闲内存了 65800k buffers 作为缓冲的内存数量 第五行为交换分区(swap)信息 内容 说明 Swap:524280k total 交换分区(虚拟内存)的总大小 0k used 已经使用的交互分区的大小 524280k free 空闲交换分区的大小 409280k cached 作为缓存的交互分区的大小 查看进程树 1234[root@localhost ~]# pstree [选项]选项:-p: 显示进程的PID-u: 显示进程的所属用户 终止进程 kill命令 12[root@localhost ~]# kill –l# 查看可用的进程信号 信号代号 信号代号 说明 1 SIGHUP 该信号让进程立即关闭,然后重新读取配置文件之后重启。 2 SIGINT 程序终止信号,用于终止前台进程。相当于输出ctrl+c快捷键。 8 SIGFPE 在发生致命的算术运算错误时发出. 不仅包括浮点运算错误,还包括溢出及除数为0等其它所有的算术的错误。 9 SIGKILL 用来立即结束程序的运行. 本信号不能被阻塞、处理和忽略。一般用于强制终止进程 14 SIGALRM 时钟定时信号, 计算的是实际的时间或时钟时间. alarm函数使用该信号。 15 SIGTERM 正常结束进程的信号,kill命令的默认信号。有时如果进程已经发生问题,这个信号是无法正常终止进程的,我们才会尝试SIGKILL信号,也就是信号9。 18 SIGCONT 该信号可以让暂停的进程恢复执行,本信号不能被阻断 19 SIGSTOP 该信号可以暂停前台进程,相当于输入ctrl+z快捷键。本信号不能被阻断。 1234[root@localhost ~]# kill -1 22354# 重启进程[root@localhost ~]# kill -9 22368# 强制杀死进程 killall命令 12345[root@localhost ~]# killall [选项][信号] 进程名# 按照进程名杀死进程选项:-i: 交互式,询问是否要杀死某个进程-I: 忽略进程名的大小写 pkill命令 1234[root@localhost ~]# pkill [选项] [信号] 进程名# 按照进程名终止进程选项:-t 终端号:按照终端号踢出用户 按照终端号踢出用户 1234[root@localhost ~]# w# 使用 w 命令查询本机已经登录的用户[root@localhost ~]# pkill -t -9 pts/1# 强制杀死从 pts/1 虚拟终端登录的进程 工作管理 把进程放入后台 tar -zcf etc.tar.gz /etc &amp; [root@localhost ~]# top#在 top 命令执行的过程中,按下 ctrl+z 快捷键 查看后台的工作 1234[root@localhost ~]# jobs [-l]选项:-l: 显示工作的PID注:“ + ”号代表最近一个放入后台的工作,也是工作恢复时,默认恢复的工作。“ - ”号代表倒数第二个放入后台的工作 将后台暂停的工作恢复到前台执行 123[root@localhost ~]# fg %工作号参数:%工作号: %号可以省略,但是注意工作号和PID的区别 把后台暂停的工作恢复到后台执行 1[root@localhost ~]# bg %工作号 注:后台恢复执行的命令,是不能和前台有交互的,否则不能恢复到后台执行 系统资源查看vmstat命令监控系统资源123[root@localhost ~]# vmstat [刷新延时 刷新次数]例如:[root@localhost proc]# vmstat 1 3 dmesg开机时内核检测信息12[root@localhost ~]# dmesg[root@localhost ~]# dmesg | grep CPU free命令查看内存使用状态123456[root@localhost ~]# free [-b|-k|-m|-g]选项:-b: 以字节为单位显示-k: 以KB为单位显示,默认就是以KB为单位显示-m: 以MB为单位显示-g: 以GB为单位显示 缓存和缓冲的区别 简单来说缓存(cache)是用来加速数据 从硬盘中“读取”的,而缓冲(buffer) 是用来加速数据“写入”硬盘的。 查看CPU信息1[root@localhost ~]# cat /proc/cpuinfo uptime命令12[root@localhost ~]# uptime# 显示系统的启动时间和平均负载,也就是 top 命令的第一行。 w 命令也可以看到这个数据。 查看系统与内核相关信息12345[root@localhost ~]# uname [选项]选项:-a: 查看系统所有相关信息;-r: 查看内核版本;-s: 查看内核名称。 判断当前系统的位数 1[root@localhost ~]# file /bin/ls 查询当前Linux系统的发行版本 1[root@localhost ~]# lsb_release -a 列出进程打开或使用的文件信息123456[root@localhost ~]# lsof [选项]#列出进程调用或打开的文件的信息选项:-c 字符串:只列出以字符串开头的进程打开的文件-u 用户名:只列出某个用户的进程打开的文件-p pid:列出某个PID进程打开的文件 系统定时任务crond服务管理与访问控制12[root@localhost ~]# service crond restart[root@localhost ~]# chkconfig crond on 用户的crontab设置123456789[root@localhost ~]# crontab [选项]选项:-e: 编辑crontab定时任务-l: 查询crontab任务-r: 删除当前用户所有的crontab任务[root@localhost ~]# crontab -e# 进入 crontab 编辑界面。会打开 vim 编辑你的工作。* * * * * 执行的任务 项目 含义 范围 第一个“*” 一小时当中的第几分钟 0-59 第二个“*” 一天当中的第几小时 0-23 第三个“*” 一个月当中的第几天 1-31 第四个“*” 一年当中的第几月 1-12 第五个“*” 一周当中的星期几 0-7(0和7都代表星期日) 特殊符号 含义 * 代表任何时间。比如第一个“*”就代表一小时中每分钟都执行一次的意思。 , 代表不连续的时间。比如“0 8,12,16 * * * 命令”,就代表在每天的8点0分,12点0分,16点0分都执行一次命令 - 代表连续的时间范围。比如“0 5 * * 1-6命令”,代表在周一到周六的凌晨5点0分执行命令 */n 代表每隔多久执行一次。比如“*/10 * * * * 命令”,代表每隔10分钟就执行一遍命令 时间 含义 45 22 * * * 命令 在22点45分执行命令 0 17 * * 1 命令 每周1 的17点0分执行命令 0 5 1,15 * * 命令 每月1号和15号的凌晨5点0分执行命令 40 4 * * 1-5 命令 每周一到周五的凌晨4点40分执行命令 */10 4 * * * 命令 每天的凌晨4点,每隔10分钟执行一次命令 0 0 1,15 * 1 命令 每月1号和15号,每周1的0点0分都会执行命令。注意:星期几和几号最好不要同时出现,因为他们定义的都是天。非常容易让管理员混乱。 举例 123*/5 * * * * /bin/echo ”11” &gt;&gt; /tmp/test5 5 * * 2 /sbin/shutdown -r now0 5 1,10,15 * * /root/sh/autobak.sh 日志管理日志管理简介日志服务 在CentOS 6.x中日志服务已经由rsyslogd取代了原先的syslogd服务。rsyslogd日志服务更加先进,功能更多。但是不论该服务的使用,还是日志文件的格式其实都是和syslogd服务相兼容的,所以学习起来基本和syslogd服务一致。 rsyslogd的新特点: 基于TCP网络协议传输日志信息; 更安全的网络传输方式; 有日志消息的及时分析框架; 后台数据库; 配置文件中可以写简单的逻辑判断; 与syslog配置文件相兼容。 确定服务启动 1234[root@localhost ~]# ps aux | grep rsyslogd# 查看服务是否启动chkconfig --list | grep rsyslog# 查看服务是否自启动 常见日志的作用 日志文件 说明 /var/log/cron 记录了系统定时任务相关的日志 /var/log/cups/ 记录打印信息的日志 /var/log/dmesg 记录了系统在开机时内核自检的信息。也可以使用dmesg命令直接查看内核自检信息。 /var/log/btmp 记录错误登录的日志。这个文件是二进制文件,不能直接vi查看,而要使用lastb命令查看,命令如下:[root@localhost log]# lastbroot tty1 Tue Jun 4 22:38 - 22:38 (00:00)#有人在 6 月 4 日 22:38 使用 root 用户,在本地终端 1 登录错误 /var/log/lastlog 记录系统中所有用户最后一次的登录时间的日志。这个文件也是二进制文件,不能直接vi,而要使用lastlogog命令查看。 /var/log/mailog 记录邮件信息。 /var/log/message 记录系统重要信息的日志。这个日志文件中会记录Linux系统的绝大 多数重要信息,如果系统出现问题时,首先要检查的就应该是这个 日志文件。 /var/log/secure 记录验证和授权方面的信息,只要涉及账户和密码的程序都会记录。 比如说系统的登录,ssh的登录,su切换用户,sudo授权,甚至添加 用户和修改用户密码都会记录在这个日志文件中。 /var/log/wtmp 永久记录所有用户的登录、注销信息,同时记录系统的启动、重启、 关机事件。同样这个文件也是一个二进制文件,不能直接vi,而需 要使用last命令来查看。 /var/run/utmp 记录当前已经登录的用户的信息。这个文件会随着用户的登录和注 销而不断变化,只记录当前登录用户的信息。同样这个文件不能直 接vi,而要使用w,who,users等命令来查询。 除了系统默认的日志之外,采用RPM方 式安装的系统服务也会默认把日志记录在 /var/log/目录中(源码包安装的服务日志 是在源码包指定目录中)。不过这些日志 不是由rsyslogd服务来记录和管理的,而 是各个服务使用自己的日志管理文档来记 录自身日志。 日志文件 说明 /var/log/httpd/ RPM包安装的apache服务的默认日志目录 /var/log/mail/ RPM包安装的邮件服务的额外日志目录 /var/log/samba/ RPM包安装的samba服务的日志目录 /var/log/sssd/ 守护进程安全服务目录 rsyslogd日志服务日志文件格式 基本日志格式包含以下四列: 事件产生的时间; 发生事件的服务器的主机名; 产生事件的服务名或程序名; 事件的具体信息。 /etc/rsyslog.conf配置文件123authpriv.* /var/log/secure# 服务名称 [ 连接符号 ] 日志等级 日志记录位置#认证相关服务 . 所有日志等级 记录在/var/log/secure 日志中 服务名称 服务名称 说明 auth 安全和认证相关消息(不推荐使用authpriv替代) authpriv 安全和认证相关消息(私有的) cron 系统定时任务cront和at产生的日志 daemon 和各个守护进程相关的日志 ftp ftp守护进程产生的日志 kern 内核产生的日志(不是用户进程产生的) local0-local7 为本地使用预留的服务 lpr 打印产生的日志 mail 邮件收发信息 news 与新闻服务器相关的日志 syslog 有syslogd服务产生的日志信息(虽然服务名称已经改为rsyslogd,但是很多配置都还是沿用了syslogd的,这里并没有修改服务名)。 user 用户等级类别的日志信息 uucp uucp子系统的日志信息,uucp是早期linux系统进行数据传递的协议,后来也常用在新闻组服务中。 连接符号 连接符号可以识别为: “*”代表所有日志等级,比如:“authpriv.”代表authpriv认证信息服务产生的日志,所有的日志等级都记录 “.”代表只要比后面的等级高的(包含该等级)日志都记录下来。比如:“cron.info”代表cron服务产生的日志,只要日志等级大于等于info级别,就记录 “.=”代表只记录所需等级的日志,其他等级的都不记录。比如:“*.=emerg”代表人和日志服务产生的日志,只要等级是emerg等级就记录。这种用法及少见,了解就好 “.!”代表不等于,也就是除了该等级的日志外,其他等级的日志都记录。 日志等级 等级名称 说明 debug 一般的调试信息说明 info 基本的通知信息 notice 普通信息,但是有一定的重要性 warning 警告信息,但是还不回影响到服务或系统的运行 err 错误信息,一般达到err等级的信息以及可以影响到服务或系 crit 临界状况信息,比err等级还要严重 alert 警告状态信息,比crit还要严重。必须立即采取行动 emerg 疼痛等级信息,系统已经无法使用了 日志记录位置 日志文件的绝对路径,如“/var/log/secure” 系统设备文件,如“/dev/lp0” 转发给远程主机,如“@192.168.0.210:514” 用户名,如“root” 忽略或丢弃日志,如“~” 日志轮替日志文件的命名规则 如果配置文件中拥有“dateext”参数,那 么日志会用日期来作为日志文件的后缀, 例如“secure-20130605”。这样的话日志 文件名不会重叠,所以也就不需要日志文 件的改名,只需要保存指定的日志个数, 删除多余的日志文件即可。 如果配置文件中没有“dateext”参数,那么日 志文件就需要进行改名了。当第一次进行日志 轮替时,当前的“secure”日志会自动改名为 “secure.1”,然后新建“secure”日志,用来 保存新的日志。当第二次进行日志轮替时, “secure.1”会自动改名为“secure.2”,当前的 “secure”日志会自动改名为“secure.1”,然 后也会新建“secure”日志,用来保存新的日志 ,以此类推。 logrotate配置文件 参数 参数说明 daily 日志的轮替周期是每天 weekly 日志的轮替周期是每周 monthly 日志的轮替周期是每月 rotate 数字 保留的日志文件的个数。0指没有备份 compress 日志轮替时,旧的日志进行压缩 create mode owner group 建立新日志,同时指定新日志的权限与所有者和所属组。如create 0600 root utmp mail address 当日志轮替时,输出内容通过邮件发送到指定的邮件地址。如mail finyorko@163.com missingok 如果日志不存在,则忽略该日志的警告信息 notifempty 如果日志为空文件,则不进行日志轮替 minsize 大小 日志轮替的最小值。也就是日志一定要达到这个最小值才会轮替,否则就算时间达到也不轮替 size 大小 日志只有大于指定大小才进行日志轮替,而不是按照时间轮替。如size 100k dateext 使用日期作为日志轮替文件的后缀。如secure-20130605 把apache日志加入轮替123456[root@localhost ~]# vi /etc/logrotate.conf/usr/local/apache2/logs/access_log &#123;dailycreaterotate 30&#125; logrotate命令123456[root@localhost ~]# logrotate [选项] 配置文件名选项:如果此命令没有选项,则会按照配置文件中的条件进行日志轮替-v: 显示日志轮替过程。加了-v选项,会显示日志的轮替的过程-f: 强制进行日志轮替。不管日志轮替的条件是否已经符合,强制配置文件中所有的日志进行轮替 启动管理CentOS 6.x启动管理系统运行级别 运行级别 运行级别 含义 0 关机 1 单用户模式,可以想象为windows的安全模式,主要用于系统修复 2 不完全的命令行模式,不含NFS服务 3 完全的命令行模式,就是标准字符界面 4 系统保留 5 图形模式 6 重启动 运行级别命令 1234[root@localhost ~]# runlevel# 查看运行级别命令[root@localhost ~]# init 运行级别# 改变运行级别命令 系统默认运行级别 123[root@localhost ~]# vim /etc/inittabid:3:initdefault:# 系统开机后直接进入哪个运行级别 系统启动过程initramfs内存文件系统 CentOS 6.x中使用initramfs内存文件系统 取代了CentOS 5.x中的initrd RAM Disk。 他们的作用类似,可以通过启动引导程序 加载到内存中,然后加载启动过程中所需 要的内核模块,比如USB、SATA、SCSI 硬盘的驱动和LVM、RAID文件系统的驱 动 12345678910111213mkdir /tmp/initramfs# 建立测试目录cp /boot/initramfs-2.6.32-279.el6.i686.img /tmp/initramfs/# 复制 initramfs 文件cd /tmp/initramfs/file initramfs-2.6.32-279.el6.i686.imgmv initramfs-2.6.32-279.el6.i686.img initramfs-2.6.32-279.el6.i686.img.gz# 修改文件的后缀名为 .gzgunzip initramfs-2.6.32-279.el6.i686.img.gz# 解压缩file initramfs-2.6.32-279.el6.i686.imgcpio -ivcdu &lt; initramfs-2.6.32-279.el6.i686.img# 解压缩 调用/etc/init/rcS.conf配置文件 主要功能是两个: 先调用/etc/rc.d/rc.sysinit,然后由/etc/rc.d/rc.sysinit配置文件进行Linux系统初始化。 然后再调用/etc/inittab,然后由/etc/inittab配置文件确定系统的默认运行级别 由/etc/rc.d/rc.sysinit初始化 1、获得网络环境2、挂载设备3、开机启动画面Plymouth(取替了过往的 RHGB)4、判断是否启用SELinux5、显示于开机过程中的欢迎画面6、初始化硬件7、用户自定义模块的加载8、配置内核的参数9、设置主机名10、同步存储器11、设备映射器及相关的初始化12、初始化软件磁盘阵列(RAID)13、初始化 LVM 的文件系统功能14、检验磁盘文件系统(fsck)15、设置磁盘配额(quota)16、重新以可读写模式挂载系统磁盘17、更新quota(非必要)18、启动系统虚拟随机数生成器19、配置机器(非必要)20、清除开机过程当中的临时文件21、创建ICE目录22、启动交换分区(swap)23、将开机信息写入/var/log/dmesg文件中 调用/etc/rc.d/rc文件 运行级别参数传入/etc/rc.d/rc这个脚本之后,由这个脚本文件按照不同的运行级别启动/etc/rc[0-6].d/目录中的相应的程序 /etc/rc3.d/k??开头的文件(??是数字),会按照数字顺序依次关闭 /etc/rc3.d/S??开头的文件(??是数字),会按照数字顺序依次启动 启动引导程序grubGrub配置文件 grub中分区表示 硬盘 分区 Linux中设备文件名 Grub 中 设 备 文 件名 第一块SCSI硬盘 第一个主分区 /dev/sda1 hd(0,0) 第二个主分区 /dev/sda2 hd(0,1) 扩展分区 /dev/sda3 hd(0,2) 第一个逻辑分区 /dev/sda5 hd(0,4) 第二块SCSI硬盘 第一个主分区 /dev/sdb1 hd(1,0) 第二个主分区 /dev/sdb2 hd(1,1) 扩展分区 /dev/sdb3 hd(1,2) 第一个逻辑分区 /dev/sdb5 hd(1,4) grub配置文件 12345678910111213141516171819202122vi /boot/grub/grub.confdefault=0 默认启动第一个系统timeout=5 等待时间,默认是5秒splashimage=(hd0,0)/grub/splash.xpm.gz 这里是指定grub启动时的背景图像文件的保存位置的hiddenmenu 隐藏菜单title CentOS (2.6.32-279.el6.i686) title就是标题的意思root (hd0,0) 是指启动程序的保存分区kernel /vmlinuz-2.6.32-279.el6.i686 roroot=UUID=b9a7a1a8-767f-4a87-8a2b-a535edb362c9rd_NO_LUKS KEYBOARDTYPE=pc KEYTABLE=usrd_NO_MD crashkernel=auto LANG=zh_CN.UTF-8rd_NO_LVM rd_NO_DM rhgb quiet 定义内核加载时的选项 initrd /initramfs-2.6.32-279.el6.i686.img 指定了initramfs内存文件系统镜像文件的所在位置 Grub加密与字符界面分辨率调整 grub加密 1234567891011[root@localhost ~]# grub-md5-crypt#生成加密密码串[root@localhost ~]# vi /boot/grub/grub.confdefault=0timeout=5password --md5$1$Y84LB1$8tMY2PibScmuOCc8z8U35/#password 选项放在整体设置处。splashimage=(hd0,0)/grub/splash.xpm.gzhiddenmenu...省略部分内容... 纯字符界面分辨率调整 12grep &quot;CONFIG_FRAMEBUFFER_CONSOLE&quot; /boot/config-2.6.32-279.el6.i686#查询内核是否支持分辨率修改 色深 640×480 800×600 1024×768 1280×1024 8位 769 771 773 775 15位 784 787 790 793 16位 785 788 791 794 32位 786 789 792 795 1234567vi /boot/grub/grub.confkernel /vmlinuz-2.6.32-279.el6.i686 roroot=UUID=b9a7a1a8-767f-4a87-8a2b-a535edb362c9 rd_NO_LUKSKEYBOARDTYPE=pc KEYTABLE=usrd_NO_MD crashkernel=auto LANG=zh_CN.UTF-8 rd_NO_LVM rd_NO_DM rhgb quiet vga=791 系统修复模式单用户模式单用户模式常见的错误修复 遗忘root密码 修改系统默认运行级别 光盘修复模式重要系统文件丢失,导致系统无法启动 123456789101112131415bash-4.1# chroot /mnt/sysimage# 改变主目录sh-4.1# cd /rootsh-4.1# rpm -qf /etc/inittab# 查询下 /etc/inittab 文件属于哪个包。sh-4.1# mkdir /mnt/cdrom# 建立挂载点sh-4.1# mount /dev/sr0 /mnt/cdrom# 挂载光盘sh-4.1# rpm2cpio \/mnt/cdrom/Packages/initscripts-8.45.3-1.i386.rpm \| cpio -idv ./etc/inittab# 提取 inittab 文件到当前目录sh-4.1# cp etc/inittab /etc/inittab# 复制 inittab 文件到指定位置 Linux的安全性 备份与恢复备份概述Linux系统需要备份的数据 /root/目录: /home/目录: /var/spool/mail/目录: /etc/目录: 其他目录: 安装服务的数据 apache需要备份的数据 配置文件 网页主目录 日志文件 mysql需要备份的数据 源码包安装的mysql:/usr/local/mysql/data/ RPM包安装的mysql:/var/lib/mysql/ 备份策略 完全备份:完全备份就是指把所有需要备份的数据全部备份,当然完全备份可以备份整块硬盘,整个分区或某个具体的目录 增量备份 差异备份 dump和restore命令dump命令12345678[root@localhost ~]# dump [选项] 备份之后的文件名 原文件或目录选项:-level: 就是我们说的0-9十个备份级别-f 文件名: 指定备份之后的文件名-u: 备份成功之后,把备份时间记录在/etc/dumpdates文件-v: 显示备份过程中更多的输出信息-j: 调用bzlib库压缩备份文件,其实就是把备份文件压缩为.bz2格式,默认压缩等级是2-W: 显示允许被dump的分区的备份等级及备份时间 备份分区 12345678910dump -0uj -f /root/boot.bak.bz2 /boot/# 备份命令。先执行一次完全备份,并压缩和更新备份时间cat /etc/dumpdates# 查看备份时间文件cp install.log /boot/# 复制日志文件到 /boot 分区dump -1uj -f /root/boot.bak1.bz2 /boot/# 增量备份 /boot 分区,并压缩dump –W# 查询分区的备份时间及备份级别的 备份文件或目录 12dump -0j -f /root/etc.dump.bz2 /etc/# 完全备份 /etc/ 目录,只能使用 0 级别进行完全备份,而不再支持增量备份 restore命令12345678[root@localhost ~]# restore [模式选项] [选项]模式选项:restore命令常用的模式有以下四种,这四个模式不能混用。 -C:比较备份数据和实际数据的变化 -i: 进入交互模式,手工选择需要恢复的文件。 -t: 查看模式,用于查看备份文件中拥有哪些数据。 -r: 还原模式,用于数据还原 。选项: -f: 指定备份文件的文件名 比较备份数据和实际数据的变化 1234mv /boot/vmlinuz-2.6.32-279.el6.i686 /boot/vmlinuz-2.6.32-279.el6.i686.bak# 把 /boot 目录中内核镜像文件改个名字restore -C -f /root/boot.bak.bz2#restore 发现内核镜像文件丢失 查看模式 restore -t -f boot.bak.bz2 还原模式 123456789101112# 还原 boot.bak.bz2 分区备份# 先还原完全备份的数据mkdir boot.testcd boot.test/restore -r -f /root/boot.bak.bz2# 解压缩restore -r -f /root/boot.bak1.bz2# 恢复增量备份数据# 还原 /etc/ 目录的备份 etc.dump.bz2restore -r -f etc.dump.bz2# 还原 etc.dump.bz2 备份 哈哈我是注释，不会在浏览器中显示。我也是注释。]]></content>
      <categories>
        <category>-Linux</category>
      </categories>
      <tags>
        <tag>-Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git学习]]></title>
    <url>%2Flearngit.html</url>
    <content type="text"><![CDATA[Git学习Git安装在liunx上安装Git1$ sudo apt-get install git 创建版本库 创建空目录 mkdir dir_name 通过git init命令把这个目录变成Git可以管理的仓库 时光穿梭机版本回退12$ git log$ git log --pretty=oneline git log命令显示从最近到最远的提交日志 如果嫌输出信息太多，看得眼花缭乱的，可以试试加上--pretty=oneline 首先，Git必须知道当前版本是哪个版本，在Git中，用HEAD表示当前版本，上一个版本就是HEAD^，上上一个版本就是HEAD^^，当然往上100个版本写100个^比较容易数不过来，所以写成HEAD~100 12$ git reset --hard HEAD^$ git reset --hard commit_id //知道commit_id的情况 现在，你回退到了某个版本，关掉了电脑，第二天早上就后悔了，想恢复到新版本怎么办？找不到新版本的commit id怎么办？ 在Git中，总是有后悔药可以吃的。当你用$ git reset --hard HEAD^回退到某个版本后，又想回到后面修改的版本，Git提供了一个命令git reflog用来记录你的每一次命令： 1$ git reflog 工作区和暂存区 工作区就是在电脑里能看到的目录 版本库 工作区有一个隐藏目录.git，这个不算工作区，而是Git的版本库。 Git的版本库里存了很多东西，其中最重要的就是称为stage（或者叫index）的暂存区，还有Git为我们自动创建的第一个分支master，以及指向master的一个指针叫HEAD。 把文件往Git版本库里添加的时候，是分两步执行的： 第一步是用git add把文件添加进去，实际上就是把文件修改添加到暂存区； 第二步是用git commit提交更改，实际上就是把暂存区的所有内容提交到当前分支。 管理修改提交后，用git diff HEAD -- file_name命令可以查看工作区和版本库里面最新版本的区别。 每次修改，如果不用git add到暂存区，那就不会加入到commit中 撤销修改撤销工作区的修改： 1$ git checkout -- file_name //在add之前 撤销暂存区修改： 12$ git reset HEAD file_name //已经add ，执行会放回工作区$ git checkout -- file_name 小节场景1：当你改乱了工作区某个文件的内容，想直接丢弃工作区的修改时，用命令git checkout -- file_name。 场景2：当你不但改乱了工作区某个文件的内容，还添加到了暂存区时，想丢弃修改，分两步，第一步用命令git reset HEAD file_name，就回到了场景1，第二步按场景1操作。 场景3：已经提交了不合适的修改到版本库时，想要撤销本次提交，就用版本回退的知识，不过前提是没有推送到远程库。 删除文件123$ rm file_name$ git rm file_name$ git commit -m &quot;info&quot; 还有一种情况是工作区中的文件被误删(rm file_name), 此时我们可以使用版本库中的文件对其进行恢复操作. 即使用git checkout -- file_name 即使用版本库中的文件(暂存区或版本库)对工作区文件恢复. 如果是使用git rm file_name 对文件删除, 则是先删除工作区文件, 在进行了一次add, 即将暂存区的文件也删除了, 此时如果想要恢复则应该先恢复暂存区的文件git reset HEAD file_name, 再恢复工作区文件 git checkout -- file_name 这里删除文件而后上传到远程仓库, 远程仓库中文件也会被删除. 远程仓库创建ssh1$ ssh-keygen -t rsa -C &quot;youremail@example.com&quot; 如果一切顺利的话，可以在用户主目录里找到.ssh目录，里面有id_rsa和id_rsa.pub两个文件，这两个就是SSH Key的秘钥对，id_rsa是私钥，不能泄露出去，id_rsa.pub是公钥，可以放心地告诉任何人。 登陆GitHub，打开“Account settings”，“SSH Keys”页面：然后，点“Add SSH Key”，填上任意Title，在Key文本框里粘贴id_rsa.pub文件的内容 添加远程库1$ git remote add origin git@github.com:finyorko/learngit.git 将代码传到GitHub1$ git push -u origin master 第一次需要-u, Git不但会把本地的master分支内容推送的远程新的master分支，还会把本地的master分支和远程的master分支关联起来，在以后的推送或者拉取时就可以简化命令。 从现在起，只要本地作了提交，就可以通过命令： 1$ git push origin master 分支管理创建与合并分支1$ git checkout -b &lt;name&gt; 等价于 12$ git branch &lt;name&gt;// 创建分支$ git checkout &lt;name&gt; // 切换分支 可以使用git branch显示工作目录下存在的分支以及当前所处分支 切换分支也可以用 git switch &lt;name&gt; 我们在dev中工作完成就可以将分支合并到master 1$ git merge &lt;name&gt; 删除分支 123$ git branch -d &lt;name&gt;$ git branch -D &lt;name&gt; 强行删除 查看分支的合并情况 12$ git log --graph --pretty=oneline --abbrev-commit包括分支合并图、一行显示、提交校验码缩略显示 分支管理策略当我们在合并后, 常常会将分支删除, 此时我们就不知道了分支合并前的信息, 为了保留合并前信息, 我们在合并时要关闭Fast forward 使用如下命令合并即可: 1$ git merge --no-ff -m &quot;merge with no-ff&quot; dev 后面的-m是该命令调用了commit命令, 生成了一个存储合并前的文件. 解决冲突之前的合并均是在一个分支上没有变换, 另一个分支上发生了变换, 此时的合并规则较为简单, 当两个文件均发生了改变时, 会引起合并冲突. 此时在主分支合并时, git会告诉我们存在冲突, 而对应的工作区文件也会被git更改, 显示出冲突的位置, Git用&lt;&lt;&lt;&lt;&lt;&lt;&lt;(当前工作区冲突内容)，=======(分割)，&gt;&gt;&gt;&gt;&gt;&gt;&gt;(要合并的部分冲突内容)标记出不同分支的内容. 如下: 123456789Git is a distributed version control system.Git is free software distributed under the GPL.Git has a mutable index called stage.Git tracks changes of files.&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEADCreating a new branch is quick &amp; simple.=======Creating a new branch is quick AND simple.&gt;&gt;&gt;&gt;&gt;&gt;&gt; feature1 此时我们需要对该文件进行手动修复，删除分支， 然后再提交一遍即可. 提交就相当于告诉git修复完成， 对当前分支进行更新，修复主分支不会影响另一个分支，切换会另一个分支，其内容依旧是其更改之后的样子。 Bug分支当你接到一个修复一个代号101的bug的任务时，很自然地，你想创建一个分支issue-101来修复它，但是，等等，当前正在dev上进行的工作还没有提交， 并不是你不想提交，而是工作只进行到一半，还没法提交 存储工作区1$ git stash 首先确定要在哪个分支上修复bug，假定需要在master分支上修复，就从master创建临时分支： 12$ git checkout master$ git checkout -b issue-101 现在修复bug，修复完提交： 1234$ git add readme.txt $ git commit -m &quot;fix bug 101&quot;[issue-101 4c805e2] fix bug 101 1 file changed, 1 insertion(+), 1 deletion(-) 修复完成后，切换到master分支，并完成合并，最后删除issue-101分支： 12$ git checkout master$ git merge --no-ff -m &quot;merged bug fix 101&quot; issue-101 太棒了，bug修复完了！现在，是时候接着回到dev分支干活了！ 1$ git checkout dev 恢复工作区刚才的工作现场存到哪去了？用git stash list命令看看 1$ git stash list 恢复方法有两个: 用git stash apply恢复，但是恢复后，stash内容并不删除，你需要用git stash drop来删除 用git stash pop，恢复的同时把stash内容也删了 12$ git stash apply stash@&#123;0&#125;$ git stash drop stash@&#123;n&#125; 在master分支上修复了bug后，我们要想一想，dev分支是早期从master分支分出来的，所以，这个bug其实在当前dev分支上也存在。 那怎么在dev分支上修复同样的bug？ 同样的bug，要在dev上修复，我们只需要把4c805e2 fix bug 101这个提交所做的修改“复制”到dev分支。注意：我们只想复制4c805e2 fix bug 101这个提交所做的修改，并不是把整个master分支merge过来。 为了方便操作，Git专门提供了一个cherry-pick命令，让我们能复制一个特定的提交到当前分支： 123456$ git branch* dev master$ git cherry-pick 4c805e2[master 1d4b803] fix bug 101 1 file changed, 1 insertion(+), 1 deletion(-) Git自动给dev分支做了一次提交，注意这次提交的commit是1d4b803，它并不同于master的4c805e2，因为这两个commit只是改动相同，但确实是两个不同的commit。用git cherry-pick，我们就不需要在dev分支上手动再把修bug的过程重复一遍。 多人协作查看远程仓库要查看远程库的信息，用git remote： 12$ git remoteorigin 或者，用git remote -v显示更详细的信息： 123$ git remote -vorigin git@github.com:michaelliao/learngit.git (fetch)origin git@github.com:michaelliao/learngit.git (push) 上面显示了可以抓取和推送的origin的地址。如果没有推送权限，就看不到push的地址。 推送分支推送分支，就是把该分支上的所有本地提交推送到远程库。推送时，要指定本地分支，这样，Git就会把该分支推送到远程库对应的远程分支上： 1$ git push origin master 如果要推送其他分支，比如dev，就改成： 1$ git push origin dev 但是，并不是一定要把本地分支往远程推送，那么，哪些分支需要推送，哪些不需要呢？ master分支是主分支，因此要时刻与远程同步； dev分支是开发分支，团队所有成员都需要在上面工作，所以也需要与远程同步； bug分支只用于在本地修复bug，就没必要推到远程了，除非老板要看看你每周到底修复了几个bug； 总之，就是在Git中，分支完全可以在本地自己藏着玩，是否推送，视你的心情而定！ 抓取分支多人协作时，大家都会往master和dev分支上推送各自的修改。 现在，模拟一个你的小伙伴，可以在另一台电脑（注意要把SSH Key添加到GitHub）或者同一台电脑的另一个目录下克隆： 1$ git clone ... 当你的小伙伴从远程库clone时，默认情况下，你的小伙伴只能看到本地的master分支。不信可以用git branch命令看看： 12$ git branch* master 现在，你的小伙伴要在dev分支上开发，就必须创建远程origin的dev分支到本地，于是他用这个命令创建本地dev分支： 1$ git checkout -b dev origin/dev dev为克隆下来分支名称, origin/dev表示从远程克隆哪个分支. 现在，他就可以在dev上继续修改，然后，时不时地把dev分支push到远程： 123git add file_namegit commit -m &quot;add file_name&quot;$ git push origin dev 你的小伙伴已经向origin/dev分支推送了他的提交，而碰巧你也对同样的文件作了修改，并试图推送 ，会推送失败，因为你的小伙伴的最新提交和你试图推送的提交有冲突，解决办法也很简单，Git已经提示我们，先用git pull把最新的提交从origin/dev抓下来，然后，在本地合并，解决冲突，再推送： 12345678910$ git pullThere is no tracking information for the current branch.Please specify which branch you want to merge with.See git-pull(1) for details. git pull &lt;remote&gt; &lt;branch&gt;If you wish to set tracking information for this branch you can do so with: git branch --set-upstream-to=origin/&lt;branch&gt; dev git pull也失败了，原因是没有指定本地dev分支与远程origin/dev分支的链接，根据提示，设置dev和origin/dev的链接： 12$ git branch --set-upstream-to=origin/dev devBranch &apos;dev&apos; set up to track remote branch &apos;dev&apos; from &apos;origin&apos;. 而后在使用 git pull. 此时可能会发生合并冲突,在本地进行更改,而后提交即可. 1$ git push origin dev 流程总结因此，多人协作的工作模式通常是这样： 首先，可以试图用git push origin &lt;branch-name&gt; 推送自己的修改； 如果推送失败，则因为远程分支比你的本地更新，需要先用git pull试图合并； 如果合并有冲突，则解决冲突，并在本地提交； 没有冲突或者解决掉冲突后，再用git push origin &lt;branch-name&gt;推送就能成功！ 如果git pull提示no tracking information，则说明本地分支和远程分支的链接关系没有创建，用命令git branch --set-upstream-to origin/&lt;branch-name&gt;。 这就是多人协作的工作模式，一旦熟悉了，就非常简单。 小结 查看远程库信息，使用git remote -v； 本地新建的分支如果不推送到远程，对其他人就是不可见的； 从本地推送分支，使用git push origin branch-name，如果推送失败，先用git pull抓取远程的新提交； 在本地创建和远程分支对应的分支，使用git checkout -b branch-name origin/branch-name，本地和远程分支的名称最好一致； 建立本地分支和远程分支的关联，使用git branch --set-upstream branch-name origin/branch-name； 从远程抓取分支，使用git pull，如果有冲突，要先处理冲突。 Rebase1$ git rebase rebase操作的特点：把分叉的提交历史“整理”成一条直线，看上去更直观。缺点是本地的分叉提交已经被修改过了。 rebase操作可以把本地未push的分叉提交历史整理成直线； rebase的目的是使得我们在查看历史提交的变化时更容易，因为分叉的提交需要三方对比。 标签管理发布一个版本时，我们通常先在版本库中打一个标签（tag），这样，就唯一确定了打标签时刻的版本。将来无论什么时候，取某个标签的版本，就是把那个打标签的时刻的历史版本取出来。所以，标签也是版本库的一个快照。 Git的标签虽然是版本库的快照，但其实它就是指向某个commit的指针（跟分支很像对不对？但是分支可以移动，标签不能移动），所以，创建和删除标签都是瞬间完成的。 Git有commit，为什么还要引入tag？ “请把上周一的那个版本打包发布，commit号是6a5819e…” “一串乱七八糟的数字不好找！” 如果换一个办法： “请把上周一的那个版本打包发布，版本号是v1.2” “好的，按照tag v1.2查找commit就行！” 所以，tag就是一个让人容易记住的有意义的名字，它跟某个commit绑在一起。 创建标签打标签首先切换到需要打标签的分支上： 12345$ git branch* dev master$ git checkout masterSwitched to branch &apos;master&apos; 然后，敲命令git tag就可以打一个新标签： 1$ git tag v1.0 默认标签是打在最新提交的commit上的。有时候，如果忘了打标签，比如，现在已经是周五了，但应该在周一打的标签没有打，怎么办？ 方法是找到历史提交的commit id，然后打上就可以了： 1$ git tag tag_name commt-id 在创建时添加说明文字: 1$ git tag -a tag_name -m &quot;info&quot; commit_id 其中用-a指定标签名，-m指定说明文字。 查看所有标签（ 标签不是按时间顺序列出，而是按字母排序的 ）: 1$ git tag 查看标签信息: 1$ git show tag_name 会展示对应提交的相关信息. 操作标签删除: 1$ git tag -d tag_name 推送标签到远程库: 1$ git push origin tag_name 一次性推送全部尚未推送到远程的本地标签： 1$ git push origin --tags 删除远程标签: 1234先在本地删除.$ git tag -d tag_name再删除远程仓库$ git push origin :refs/tags/tag_name 自定义Git忽略特殊文件不需要从头写.gitignore文件，GitHub已经为我们准备了各种配置文件，只需要组合一下就可以使用了。所有配置文件可以直接在线浏览 [忽略文件][https://github.com/github/gitignore ] 有些时候，你想添加一个文件到Git，但发现添加不了，原因是这个文件被.gitignore忽略了，如果你确实想添加该文件，可以用-f强制添加到Git： 1$ git add -f file_name 或者你发现，可能是.gitignore写得有问题，需要找出来到底哪个规则写错了，可以用git check-ignore命令检查： 1$ git check-ignore -v file_name 配置别名在输入命令时, 总会由于名字太长而不方便, 这时我们可以为命令配置一个简单的别名,此时我们只用输入简单的指令就能够实现一长串指令的操作岂不美滋滋. 语法如下: 1$ git config --global alias.your_command origin_command --global参数是全局参数，也就是这些命令在这台电脑的所有Git仓库下都有用， 如果不加，那只针对当前的仓库起作用 。 配置文件放哪了？每个仓库的Git配置文件都放在.git/config文件中 而当前用户的Git配置文件放在用户主目录下的一个隐藏文件.gitconfig中]]></content>
      <categories>
        <category>-Git</category>
      </categories>
      <tags>
        <tag>-Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Go语言学习笔记]]></title>
    <url>%2Fgo_learning.html</url>
    <content type="text"><![CDATA[Go语言学习笔记第一个Go程序hello.go ，（Go 语言源文件的扩展是 .go），代码如下： 1234567package mainimport "fmt"func main() &#123; fmt.Println("Hello, World!")&#125; 要执行 Go 语言代码可以使用 go run命令。 执行以上代码输出: 12$ go run hello.go Hello, World! 此外我们还可以使用 go build命令来生成二进制文件： 12345$ go build hello.go $ lshello hello.go$ ./hello Hello, World! Go语言结构GO Hello World 实例 Go 语言的基础组成有以下几个部分： 包声明 引用包 函数 变量 语句&amp;表达式 注释 通过实例来解释： 123456package mainimport "fmt"func main() &#123; /* 这是我的第一个简单的程序 */ fmt.Println("Hello, World!")&#125; 第一行代码 package main定义了包名。你必须在源文件中非注释的第一行指明这个文件属于哪个包，如：package main。package main表示一个可独立执行的程序，每个 Go 应用程序都包含一个名为 main 的包。 下一行 import &quot;fmt&quot;告诉 Go 编译器这个程序需要使用 fmt 包（的函数，或其他元素），fmt 包实现了格式化 IO（输入/输出）的函数。 下一行 func main() 是程序开始执行的函数。main 函数是每一个可执行程序所必须包含的，一般来说都是在启动后第一个执行的函数（如果有 init() 函数则会先执行该函数）。 下一行/*...*/是注释，在程序执行时将被忽略。单行注释是最常见的注释形式，你可以在任何地方使用以 // 开头的单行注释。多行注释也叫块注释，均已以 /* 开头，并以 */ 结尾，且不可以嵌套使用，多行注释一般用于包的文档描述或注释成块的代码片段。 下一行fmt.Println(...)可以将字符串输出到控制台，并在最后自动增加换行字符 \n。使用 fmt.Print(&quot;hello, world\n&quot;)可以得到相同的结果。Print 和 Println 这两个函数也支持使用变量，如：fmt.Println(arr)。如果没有特别指定，它们会以默认的打印格式将变量 arr 输出到控制台。 当标识符（包括常量、变量、类型、函数名、结构字段等等）以一个大写字母开头，如：Group1，那么使用这种形式的标识符的对象就可以被外部包的代码所使用（客户端程序需要先导入这个包），这被称为导出（像面向对象语言中的 public）；标识符如果以小写字母开头，如group，则对包外是不可见的，但是他们在整个包的内部是可见并且可用的（像面向对象语言中的 protected ）。 执行Go程序 输入命令 go run hello.go 并按回车执行代码 12$ go run hello.goHello, World! 我们还可以使用 go build 命令来生成二进制文件： 12345$ go build hello.go $ lshello hello.go$ ./hello Hello, World! 注意需要注意的是{不能单独放在一行，所以以下代码在运行时会产生错误： 12345678package mainimport "fmt"func main() &#123; // 错误，&#123; 不能在单独的行上 fmt.Println("Hello, World!")&#125; 笔记 当前的调试部分可以使用 go run filename.go 来执行。 可以生成一个 build.sh 脚本，用于在指定位置产生已编译好的 可执文件: 12345678910111213141516#!/usr/bin/env bashCURRENT_DIR=`pwd`OLD_GO_PATH="$GOPATH" #例如: /usr/local/goOLD_GO_BIN="$GOBIN" #例如: /usr/local/go/binexport GOPATH="$CURRENT_DIR" export GOBIN="$CURRENT_DIR/bin"#指定并整理当前的源码路径gofmt -w srcgo install test_helloexport GOPATH="$OLD_GO_PATH"export GOBIN="$OLD_GO_BIN" 关于包，根据本地测试得出以下几点： 文件名与包名没有直接关系，不一定要将文件名与包名定成同一个。 文件夹名与包名没有直接关系，并非需要一致。 同一个文件夹下的文件只能有一个包名，否则编译报错。 文件结构: 123456Test--helloworld.gomyMath--myMath1.go--myMath2.go 测试代码: 12345678910111213// helloworld.gopackage mainimport ("fmt""./myMath")func main()&#123; fmt.Println("Hello World!") fmt.Println(mathClass.Add(1,1)) fmt.Println(mathClass.Sub(1,1))&#125; 12345// myMath1.gopackage mathClassfunc Add(x,y int) int &#123; return x + y&#125; 12345// myMath2.gopackage mathClassfunc Sub(x,y int) int &#123; return x - y&#125; Go语言基础语法Go标记Go 程序可以由多个标记组成，可以是关键字，标识符，常量，字符串，符号。如以下 GO 语句由 6 个标记组成： 1fmt.Println("Hello, World!") 6 个标记是(每行一个)： 123456fmt.Println(&quot;Hello, World!&quot; ) 行分隔符在 Go 程序中，一行代表一个语句结束。每个语句不需要像 C 家族中的其它语言一样以分号 ; 结尾，因为这些工作都将由 Go 编译器自动完成。 如果你打算将多个语句写在同一行，它们则必须使用 ; 人为区分，但在实际开发中我们并不鼓励这种做法。 以下为两个语句： 12fmt.Println("Hello, World!")fmt.Println("行分隔符，一行一个语句") 注释注释不会被编译，每一个包应该有相关注释。 单行注释是最常见的注释形式，你可以在任何地方使用以 // 开头的单行注释。 多行注释也叫块注释，均已以 /* 开头，并以 */ 结尾。 标识符标识符用来命名变量、类型等程序实体。一个标识符实际上就是一个或是多个字母(AZ和az)数字(0~9)、下划线_组成的序列，但是第一个字符必须是字母或下划线而不能是数字。 以下是有效的标识符： 12mahesh kumar abc move_name a_123myname50 _temp j a23b9 retVal 以下是无效的标识符： 1ab（以数字开头） case（Go 语言的关键字） a+b（运算符是不允许的） 字符串连接 Go 语言的字符串可以通过+实现： 12345package mainimport "fmt"func main() &#123; fmt.Println("Google" + "Runoob")&#125; 12output:GoogleRunoob 关键字下面列举了 Go 代码中会使用到的 25 个关键字或保留字： break default func interface select case defer go map struct chan else goto package switch const fallthrough if range type continue for import return var 除了以上介绍的这些关键字，Go 语言还有 36 个预定义标识符： append bool byte cap close complex complex64 complex128 uint16 copy false float32 float64 imag int int8 int16 uint32 int32 int64 iota len make new nil panic uint64 print println real recover string true uint uint8 uintptr Go 语言的空格Go 语言中变量的声明必须使用空格隔开，如： 1var age int; Go语言数据类型在 Go 编程语言中，数据类型用于声明函数和变量。 数据类型的出现是为了把数据分成所需内存大小不同的数据，编程的时候需要用大数据的时候才需要申请大内存，就可以充分利用内存。 Go 语言按类别有以下几种数据类型： 序号 类型和描述 1 布尔型 布尔型的值只可以是常量 true 或者 false。一个简单的例子：var b bool = true。 2 数字类型 整型 int 和浮点型 float32、float64，Go 语言支持整型和浮点型数字，并且支持复数，其中位的运算采用补码。 3 字符串类型: 字符串就是一串固定长度的字符连接起来的字符序列。Go 的字符串是由单个字节连接起来的。Go 语言的字符串的字节使用 UTF-8 编码标识 Unicode 文本。 4 派生类型: 包括：(a) 指针类型（Pointer） (b) 数组类型 (c) 结构化类型(struct) (d) Channel 类型 (e) 函数类型 (f) 切片类型 (g) 接口类型（interface） (h) Map 类型 数字类型Go 也有基于架构的类型，例如：int、uint 和 uintptr。 int型 序号 类型和描述 1 uint8 无符号 8 位整型 (0 到 255) 2 uint16 无符号 16 位整型 (0 到 65535) 3 uint32 无符号 32 位整型 (0 到 4294967295) 4 uint64 无符号 64 位整型 (0 到 18446744073709551615) 5 int8 有符号 8 位整型 (-128 到 127) 6 int16 有符号 16 位整型 (-32768 到 32767) 7 int32 有符号 32 位整型 (-2147483648 到 2147483647) 8 int64 有符号 64 位整型 (-9223372036854775808 到 9223372036854775807) 浮点型： 序号 类型和描述 1 float32 IEEE-754 32位浮点型数 2 float64 IEEE-754 64位浮点型数 3 complex64 32 位实数和虚数 4 complex128 64 位实数和虚数 其他数字类型 序号 类型和描述 1 byte 类似 uint8 2 rune 类似 int32 3 uint 32 或 64 位 4 int 与 uint 一样大小 5 uintptr 无符号整型，用于存放一个指针 笔记 go 1.9版本对于数字类型，无需定义int及float32、float64，系统会自动识别。 12345678package mainimport "fmt"func main() &#123; var a = 1.5 var b =2 fmt.Println(a,b)&#125; 字符串去除空格和换行符 12345678910111213141516package main import ( "fmt" "strings" ) func main() &#123; str := "这里是 www\n.baidu\n.com" fmt.Println("-------- 原字符串 ----------") fmt.Println(str) // 去除空格 str = strings.Replace(str, " ", "", -1) // 去除换行符 str = strings.Replace(str, "\n", "", -1) fmt.Println("-------- 去除空格与换行后 ----------") fmt.Println(str) &#125; 输出结果为： 123456-------- 原字符串 ----------这里是 www.baidu.com-------- 去除空格与换行后 ----------这里是www.baidu.com Go 语言变量Go 语言变量名由字母、数字、下划线组成，其中首个字符不能为数字。 声明变量的一般形式是使用 var 关键字： 1var identifier type 可以一次声明多个变量： 1var identifier1, identifier2 type 12345678910//实例package mainimport "fmt"func main() &#123; var a string = "Baidu" fmt.Println(a) var b, c int = 1, 2 fmt.Println(b, c)&#125; 123//outputBaidu1 2 变量声明第一种，指定变量类型，如果没有初始化，则变量默认为零值。 12var v_name v_typev_name = value 1234567891011package mainimport "fmt"func main() &#123; // 没有初始化就为零值* var b int fmt.Println(b)//output: 0 // bool 零值为 false* var c bool fmt.Println(c)//output: false&#125; 数值类型（包括complex64/128）为 0 布尔类型为 false 字符串为 “”（空字符串） 以下几种类型为 nil： 123456var a *intvar a []intvar a map[string] intvar a chan intvar a func(string) intvar a error // error 是接口 12345678910111213package mainimport "fmt"func main() &#123; var i int var f float64 var b bool var s string fmt.Printf("%v %v %v %q**\n**", i, f, b, s)&#125; /*output:0 0 false ""*/ 第二种，根据值自行判定变量类型。 1var v_name = value 1234567package mainimport "fmt"func main() &#123; var d = true fmt.Println(d)&#125; //output: true 第三种，省略 var, 注意 *:=* 左侧如果没有声明新的变量，就产生编译错误，格式：v_name := value 12345var intVal int intVal :=1 // 这时候会产生编译错误intVal,intVal1 := 1,2 // 此时不会产生编译错误，因为有声明新的变量，因为 := 是一个声明 可以将 var f string = &quot;Baidu&quot;简写为 f := &quot;Baidu&quot; 多变量声明1234567891011121314//类型相同多个变量, 非全局变量var vname1, vname2, vname3 typevname1, vname2, vname3 = v1, v2, v3var vname1, vname2, vname3 = v1, v2, v3 // 和 python 很像,不需要显示声明类型，自动推断vname1, vname2, vname3 := v1, v2, v3 // 出现在 := 左侧的变量不应该是已经被声明过的，否则会导致编译错误// 这种因式分解关键字的写法一般用于声明全局变量var ( vname1 v_type1 vname2 v_type2) 实例 12345678910111213141516171819202122package mainvar x, y intvar ( // 这种因式分解关键字的写法一般用于声明全局变量 a int b bool)var c, d int = 1, 2var e, f = 123, "hello"//这种不带声明格式的只能在函数体中出现//g, h := 123, "hello"func main()&#123; g, h := 123, "hello" println(x, y, a, b, c, d, e, f, g, h)&#125;/*output:0 0 0 false 1 2 123 hello 123 hello*/]]></content>
      <categories>
        <category>-Go语言</category>
      </categories>
      <tags>
        <tag>-Go语言</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++剑指offer]]></title>
    <url>%2Foffer_dir.html</url>
    <content type="text"><![CDATA[二维数组中的查找题目描述在一个二维数组中（每个一维数组的长度相同），每一行都按照从左到右递增的顺序排序，每一列都按照从上到下递增的顺序排序。请完成一个函数，输入这样的一个二维数组和一个整数，判断数组中是否含有该整数。 解题思路从左下角元素往上查找，右边元素是比这个元素大，上边是的元素比这个元素小。于是，target比这个元素小就往上找，比这个元素大就往右找。如果出了边界，则说明二维数组中不存在target元素。 代码实现123456789101112131415161718class Solution &#123;public: bool Find(int target, vector&lt;vector&lt;int&gt; &gt; array) &#123; // array是二维数组，这里没做判空操作 int rows = array.size(); int cols = array[0].size(); int i=rows-1,j=0;//左下角元素坐标 while(i&gt;=0 &amp;&amp; j&lt;cols)&#123;//使其不超出数组范围 if(target&lt;array[i][j]) i--;//查找的元素较少，往上找 else if(target&gt;array[i][j]) j++;//查找元素较大，往右找 else return true;//找到 &#125; return false; &#125;&#125;; 替换空格题目描述请实现一个函数，将一个字符串中的每个空格替换成“%20”。例如，当字符串为We Are Happy.则经过替换之后的字符串为We%20Are%20Happy。 解题思路从前往后记录空格数目，从后往前替换空格 代码实现1234567891011121314151617181920class Solution &#123;public: void replaceSpace(char *str,int length) &#123; int num = 0 ; for(int i =0;i&lt;length;i++)&#123; if(str[i]==' ')&#123;num++;&#125; &#125; for(int i = length -1 ; i &gt;= 0; i--)&#123; if(str[i] != ' ')&#123; str[i+num*2] = str[i]; &#125; else&#123; str[i+num*2] = '0'; str[i+num*2-1] = '2'; str[i+num*2-2] = '%'; num--; &#125; &#125; &#125;&#125;; 从尾到头打印链表题目描述输入一个链表，按链表从尾到头的顺序返回一个ArrayList。 题目分析比较简单，直接看代码 代码实现 方法一： 链表从尾到头输出，利用递归实现，不使用库函数直接printf输出的时候用递归比较好 123456789101112131415161718192021222324252627/*** struct ListNode &#123;* int val;* struct ListNode *next;* ListNode(int x) :* val(x), next(NULL) &#123;* &#125;* &#125;;*/class Solution &#123;public: vector&lt;int&gt; printListFromTailToHead(struct ListNode* head) &#123; vector&lt;int&gt; value; if(head != NULL) &#123; value.insert(value.begin(),head-&gt;val); if(head-&gt;next != NULL) &#123; vector&lt;int&gt; tempVec = printListFromTailToHead(head-&gt;next); if(tempVec.size()&gt;0) value.insert(value.begin(),tempVec.begin(),tempVec.end()); &#125; &#125; return value; &#125;&#125;; 用库函数，每次扫描一个节点，将该结点数据存入vector中，如果该节点有下一节点，将下一节点数据直接插入vector最前面，直至遍历完，或者直接加在最后，最后调用reverse 。[头插vector 效率太低，可以先vector.push_back返回之前翻转vector，std::reverse(begin,end) ] 123456789101112131415161718192021222324252627/*** struct ListNode &#123;* int val;* struct ListNode *next;* ListNode(int x) :* val(x), next(NULL) &#123;* &#125;* &#125;;*/class Solution &#123;public: vector&lt;int&gt; printListFromTailToHead(struct ListNode* head) &#123; vector&lt;int&gt; value; if(head != NULL) &#123; value.insert(value.begin(),head-&gt;val); while(head-&gt;next != NULL) &#123; value.insert(value.begin(),head-&gt;next-&gt;val); head = head-&gt;next; &#125; &#125; return value; &#125;&#125;; 重建二叉树题目分析前序加中序序列，分解过程图示如下（王道数据结构P120） 由先序序列第一个pre[0]在中序序列中找到根节点位置gen 以gen为中心遍历 0~gen左子树 子中序序列：0~gen-1，放入vin_left[] 子先序序列：1~gen放入pre_left[]，+1可以看图，因为头部有根节点 gen+1~vinlen为右子树 子中序序列：gen+1 ~ vinlen-1放入vin_right[] 子先序序列：gen+1 ~ vinlen-1放入pre_right[] 由先序序列pre[0]创建根节点 连接左子树，按照左子树子序列递归（pre_left[]和vin_left[]） 连接右子树，按照右子树子序列递归（pre_right[]和vin_right[]） 返回根节点 代码实现1234567Definition for binary treestruct TreeNode &#123;int val;TreeNode *left;TreeNode *right;TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125;&#125;; 方法一 123456789101112131415161718192021222324252627282930313233343536373839*/class Solution &#123;public: struct TreeNode* reConstructBinaryTree(vector&lt;int&gt; pre, vector&lt;int&gt; in) &#123; int inlen = in.size(); if (inlen == 0) return NULL; vector&lt;int&gt; left_pre, right_pre, left_in, right_in; //创建根节点，根节点肯定是前序遍历的第一个数 TreeNode* head = new TreeNode(pre[0]); //找到中序遍历根节点所在位置,存放于变量gen中 int gen = 0; for (int i = 0; i&lt;inlen; i++) &#123; if (in[i] == pre[0]) &#123; gen = i; break; &#125; &#125; //对于中序遍历，根节点左边的节点位于二叉树的左边，根节点右边的节点位于二叉树的右边 //利用上述这点，对二叉树节点进行归并 for (int i = 0; i&lt;gen; i++) &#123; left_in.push_back(in[i]); left_pre.push_back(pre[i + 1]);//前序第一个为根节点 &#125; for (int i = gen + 1; i&lt;inlen; i++) &#123; right_in.push_back(in[i]); right_pre.push_back(pre[i]); &#125; //和shell排序的思想类似，取出前序和中序遍历根节点左边和右边的子树 //递归，再对其进行上述所有步骤，即再区分子树的左、右子子数，直到叶节点 head-&gt;left = reConstructBinaryTree(left_pre, left_in); head-&gt;right = reConstructBinaryTree(right_pre, right_in); return head; &#125;&#125;; 方法二（厉害） $i_{0}$=startIn . . . . . i startPre . . . . . x $x=startPre+i-startIn$ 123456789101112131415161718 public TreeNode reConstructBinaryTree( int [] pre, int [] in) &#123; TreeNode root=reConstructBinaryTree(pre, 0 ,pre.length- 1 ,in, 0 ,in.length- 1 ); return root; &#125; //前序遍历&#123;1,2,4,7,3,5,6,8&#125;和中序遍历序列&#123;4,7,2,1,5,3,8,6&#125; private TreeNode reConstructBinaryTree( int [] pre, int startPre, int endPre, int [] in, int startIn, int endIn) &#123; if (startPre&gt;endPre||startIn&gt;endIn) return null ; TreeNode root= new TreeNode(pre[startPre]); for ( int i=startIn;i&lt;=endIn;i++) if (in[i]==pre[startPre])&#123; root.left=reConstructBinaryTree(pre,startPre+ 1 ,startPre+i-startIn,in,startIn,i- 1 ); root.right=reConstructBinaryTree(pre,i-startIn+startPre+ 1 ,endPre,in,i+ 1 ,endIn); break ; &#125; return root; &#125;&#125; 用两个栈实现队列题目分析：入队：将元素进栈A 出队：判断栈B是否为空，如果为空，则将栈A中所有元素pop，并push进栈B，栈B出栈；如果不为空，栈B直接出栈。 代码实现12345678910111213141516171819202122232425262728class Solution&#123;public: void push(int node) &#123; stack1.push(node); &#125; int pop() &#123; int a; if (stack2.empty()) &#123; while (!stack1.empty()) &#123; a = stack1.top(); stack2.push(a); stack1.pop(); &#125; &#125; a = stack2.top(); stack2.pop(); return a; &#125;private: stack&lt;int&gt; stack1; stack&lt;int&gt; stack2;&#125;; 拓展如果用两个队列实现一个栈的功能? 解题思路： 入栈：将元素进队列A 出栈：判断队列A中元素的个数是否为1，如果等于1，则出队列，否则将队列A中的元素 以此出队列并放入队列B，直到队列A中的元素留下一个，然后队列A出队列，再把 队列B中的元素出队列以此放入队列A中。 旋转数组的最小数字题目描述把一个数组最开始的若干个元素搬到数组的末尾，我们称之为数组的旋转。输入一个非递减排序的数组的一个旋转，输出旋转数组的最小元素。例如数组{3,4,5,1,2}为{1,2,3,4,5}的一个旋转，该数组的最小值为1。NOTE：给出的所有元素都大于0，若数组大小为0，请返回0。 题目分析采用二分法解答这个问题： mid = low + (high - low)/2 需要考虑三种情况： (1)array[mid] &gt; array[high]: 出现这种情况的array类似[3,4,5,6,0,1,2]，此时最小数字一定在mid的右边。 low = mid + 1 (2)array[mid] == array[high]: 出现这种情况的array类似 [1,0,1,1,1] 或者[1,1,1,0,1]，此时最小数字不好判断在mid左边还是右边,这时只好一个一个试 ， high = high - 1 (3)array[mid] &lt; array[high]: 出现这种情况的array类似[2,2,3,4,5,6,6],此时最小数字一定就是array[mid]或者在mid的左边。因为右边必然都是递增的。 high = mid 注意这里有个坑：如果待查询的范围最后只剩两个数，那么mid 一定会指向下标靠前的数字 比如 array = [4,6] array[low] = 4 ;array[mid] = 4 ; array[high] = 6 ; 如果high = mid - 1，就会产生错误， 因此high = mid 但情形(1)中low = mid + 1就不会错误 代码实现1234567891011121314151617class Solution &#123;public: int minNumberInRotateArray(vector&lt;int&gt; array) &#123;int low = 0 ; int high = array.size() - 1; while(low &lt; high)&#123; int mid = low + (high - low) / 2; if(array[mid] &gt; array[high])&#123; low = mid + 1; &#125;else if(array[mid] == array[high])&#123; high = high - 1; &#125;else&#123; high = mid; &#125; &#125; return array[low]; &#125;&#125;; 斐波那契数列题目描述大家都知道斐波那契数列$ \begin{equation} f(x)= \begin{cases} 1&amp; \text{x=1;} \ 1&amp; \text{x=2;} \ 1&amp; \text{$f(n-1)+f(n)$} \end{cases} \end{equation} $，现在要求输入一个整数n，请你输出斐波那契数列的第n项（从0开始，第0项为0）。 n&lt;=39 题目分析分别用f和g表示$f(n)$和$f(n+1)$,用循环来实现，最好不要用递归，递归重复计算的部分太多了，花费太大 。 代码实现1234567891011class Solution &#123;public: int Fibonacci(int n) &#123; int f = 0, g = 1; while(n--) &#123; g += f; f = g - f; &#125; return f; &#125;&#125;; 跳台阶题目描述一只青蛙一次可以跳上1级台阶，也可以跳上2级。求该青蛙跳上一个n级的台阶总共有多少种跳法（先后次序不同算不同的结果）。 题目分析对于本题,前提只有 一次 1阶或者2阶的跳法。 a.如果两种跳法，1阶或者2阶，那么假定第一次跳的是一阶，那么剩下的是n-1个台阶，跳法是f(n-1); b.假定第一次跳的是2阶，那么剩下的是n-2个台阶，跳法是f(n-2) c.由a\b假设可以得出总跳法为: f(n) = f(n-1) + f(n-2) d.然后通过实际的情况可以得出：只有一阶的时候 f(1) = 1 ,只有两阶的时候可以有 f(2) = 2 e.可以发现最终得出的是一个斐波那契数列： $ \begin{equation} f(x)= \begin{cases} 1&amp; \text{x=1;} \ 1&amp; \text{x=2;} \ 1&amp; \text{$f(n-1)+f(n)$} \end{cases} \end{equation} $ 代码实现123456789101112131415161718192021class Solution &#123;public: int jumpFloor(int number) &#123; if (number &lt;= 0) &#123; return 0; &#125; if (number == 1) &#123; return 1; &#125; if (number == 2) &#123; return 2; &#125; int first = 1, second = 2, third = 0; for (int i = 3; i &lt;= number; i++) &#123; third = first + second; first = second; second = third; &#125; return third; &#125;&#125;; 变态跳台阶题目描述一只青蛙一次可以跳上1级台阶，也可以跳上2级……它也可以跳上n级。求该青蛙跳上一个n级的台阶总共有多少种跳法。 题目分析-1 关于本题，前提是n个台阶会有一次n阶的跳法。分析如下: f(1) = 1 f(2) = f(2-1) + f(2-2) //f(2-2) 表示2阶一次跳2阶的次数。 f(3) = f(3-1) + f(3-2) + f(3-3) … f(n) = f(n-1) + f(n-2) + f(n-3) + … + f(n-(n-1)) + f(n-n) 说明： 1）这里的f(n) 代表的是n个台阶有一次1,2,…n阶的 跳法数。 2）n = 1时，只有1种跳法，f(1) = 1 3) n = 2时，会有两个跳得方式，一次1阶或者2阶，这回归到了问题（1） ， ​ f(2) = f(2-1) + f(2-2) 4) n = 3时，会有三种跳得方式，1阶、2阶、3阶， 那么就是第一次跳出1阶后面 剩下：f(3-1);第一次跳出2阶，剩下f(3-2)；第一次3阶，那么剩下f(3-3) 因此结论是f(3) = f(3-1)+f(3-2)+f(3-3) 5) n = n时，会有n中跳的方式，1阶、2阶…n阶，得出结论： ​ f(n) = f(n-1)+f(n-2)+…+f(n-(n-1)) + f(n-n) =&gt; f(0) + f(1) + f(2) + f(3) + … + f(n-1) 6) 由以上已经是一种结论，但是为了简单，我们可以继续简化： f(n-1) = f(0) + f(1)+f(2)+f(3) + … + f((n-1)-1) = f(0) + f(1) + f(2) + f(3) + … + f(n-2) f(n) = f(0) + f(1) + f(2) + f(3) + … + f(n-2) + f(n-1) = f(n-1) + f(n-1) 可以得出： f(n) = 2*f(n-1) 7) 得出最终结论,在n阶台阶，一次有1、2、…n阶的跳的方式时，总得跳法为： ​ $ \begin{equation} f(x)= \begin{cases} 1&amp; \text{n=0;} \ 1&amp; \text{n=1;} \ 2*f(n-1)&amp; \text{$n&gt;=2$} \end{cases} \end{equation} $ 代码实现- 11234567891011121314151617181920public class Solution &#123; public int JumpFloorII(int target) &#123; if (target &lt;= 0) &#123; return -1; &#125; else if (target == 1) &#123; return 1; &#125; else &#123; return 2 * JumpFloorII(target - 1); &#125; &#125;&#125;//也可以用移位运算符/*class Solution &#123;public: int jumpFloorII(int number) &#123; int a=1; return a&lt;&lt;(number-1); &#125;&#125;;*/ 题目分析-2（概率内容或者基础排列组合？？有点分不清了）假设有n（n&gt;=2）个台阶，因为青蛙可以一步跳任意阶，所以第n层台阶一定会被青蛙踩到，剩下的就看第1~n-1层台阶会不会被踩到，每层台阶可以任意选择会不会被踩到，所以有$2^{n-1}$种情况 代码实现1234567891011class Solution &#123;public: int jumpFloorII(int number) &#123; int j=1; while(--number) &#123; j*=2; &#125; return j; &#125;&#125;; 矩形覆盖题目描述我们可以用2*1 的小矩形横着或者竖着去覆盖更大的矩形。请问用n个2*1的小矩形无重叠地覆盖一个2*n的大矩形，总共有多少种方法？ 题目分析依旧是斐波那契数列 n&lt;=0时，直接return 1； n=1时，只有一种摆放方法，return 1； n=2时，有两种摆放方法，return 2； n&gt;=2时，分为两步考虑， 第一次摆放2*1的小矩阵，则 摆放方法总共为f(target - 1) $\checkmark$ $\checkmark$ 第一次摆放一块1*2的小矩阵，则摆放方法总共为f(target-2) 因为，摆放了一块1*2的小矩阵（用√√表示），对应下方的1*2（用××表示）摆放方法就确定了，所以为f(targte-2) $\checkmark$ $\checkmark$ $\times$ $\times$ 代码实现123456789101112class Solution &#123;public: int rectCover(int number) &#123; if ( number &lt; 1 ) return 0; int g = 1, f = 2; while ( --number ) &#123; f = f + g; g = f - g; &#125; return g; &#125;&#125;; 二进制中1的个数题目描述输入一个整数，输出该数二进制表示中1的个数。其中负数用补码表示。 题目分析-1用1（1自身左移运算，其实后来就不是1了）和n的每位进行位与，来判断1的个数 代码实现-112345678910111213class Solution &#123;public: int NumberOf1(int n) &#123; int count = 0; int flag = 1; while (flag != 0) &#123; if ((n &amp; flag) != 0) count++; flag = flag &lt;&lt; 1; &#125; &#125;&#125;; 题目分析-2使用(n - 1) &amp; n， 把最右边的一个1变成0 代码实现-2123456789101112class Solution &#123;public: int NumberOf1(int n) &#123; int count = 0; while (n != 0) &#123; ++count; n = (n - 1) &amp; n; &#125; return count; &#125;&#125;; 数值的整数次方题目描述给定一个double类型的浮点数base和int类型的整数exponent。求base的exponent次方。 保证base和exponent不同时为0 题目分析简单快速幂 举例分析：13=1101 $base^{1101}$=$base^{0001}$*$base^{0100}$*$base^{1000}$ 通过&amp;1和&gt;&gt;1来逐位读取1101，为1时将该位代表的乘数累乘到最终结果 代码实现12345678910111213class Solution &#123;public: double Power(double base, int exponent) &#123; long long p = abs((long long)exponent); double r = 1.0; while(p)&#123; if(p &amp; 1) r *= base; base *= base; p &gt;&gt;= 1; &#125; return exponent &lt; 0 ? 1/ r : r; &#125;&#125;;]]></content>
      <categories>
        <category>-算法</category>
      </categories>
      <tags>
        <tag>-算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[排序算法]]></title>
    <url>%2Fsort.html</url>
    <content type="text"><![CDATA[冒泡排序冒泡排序（英语：Bubble Sort）是一种简单的排序算法。它重复地走访过要排序的数列，一次比较两个元素，如果他们的顺序（如从大到小、首字母从A到Z）错误就把他们交换过来。 12345678910void bubble_sort(int arr[], int len) &#123; int i, j, temp; for (i = 0; i &lt; len - 1; i++) for (j = 0; j &lt; len - 1 - i; j++) if (arr[j] &gt; arr[j + 1]) &#123; temp = arr[j]; arr[j] = arr[j + 1]; arr[j + 1] = temp; &#125;&#125; 选择排序选择排序（Selection sort）是一种简单直观的排序算法。它的工作原理如下。首先在未排序序列中找到最小（大）元素，存放到排序序列的起始位置，然后，再从剩余未排序元素中继续寻找最小（大）元素，然后放到已排序序列的末尾。以此类推，直到所有元素均排序完毕。 12345678910111213141516171819void swap(int *a,int *b) //交換兩個變數&#123; int temp = *a; *a = *b; *b = temp;&#125;void selection_sort(int arr[], int len) &#123; int i,j; for (i = 0 ; i &lt; len - 1 ; i++) &#123; int min = i; for (j = i + 1; j &lt; len; j++) //走訪未排序的元素 if (arr[j] &lt; arr[min]) //找到目前最小值 min = j; //紀錄最小值 swap(&amp;arr[min], &amp;arr[i]); //做交換 &#125;&#125; 插入排序插入排序（英语：Insertion Sort）是一种简单直观的排序算法。它的工作原理是通过构建有序序列，对于未排序数据，在已排序序列中从后向前扫描，找到相应位置并插入。插入排序在实现上，通常采用in-place排序（即只需用到 {\displaystyle O(1)} {\displaystyle O(1)}的额外空间的排序），因而在从后向前扫描过程中，需要反复把已排序元素逐步向后挪位，为最新元素提供插入空间。 123456789void insertion_sort(int arr[], int len)&#123; int i,j,temp; for (i=1;i&lt;len;i++)&#123; temp = arr[i]; for (j=i;j&gt;0 &amp;&amp; arr[j-1]&gt;temp;j--) arr[j] = arr[j-1]; arr[j] = temp; &#125;&#125; 归并排序归并排序使用到了分治的思想, 将一个数组分为两部分, 并分别将两部分排序完成, 而后只用对两个排序好的子序列进行合并即可. 对两个子序列的合并操作也使用相同的策略, 递归的进行. 在进行合并的时候, 需要将原来的数组排序结果保存到另一个数组中, 空间复杂度为$O(n)$. 归并排序时间复杂度为$O(nlog(n))$. 典型应用为求逆序对数. 迭代法1234567891011121314151617181920212223242526272829303132int min(int x, int y) &#123; return x &lt; y ? x : y;&#125;void merge_sort(int arr[], int len) &#123; int* a = arr; int* b = (int*) malloc(len * sizeof(int)); int seg, start; for (seg = 1; seg &lt; len; seg += seg) &#123; for (start = 0; start &lt; len; start += seg + seg) &#123; int low = start, mid = min(start + seg, len), high = min(start + seg + seg, len); int k = low; int start1 = low, end1 = mid; int start2 = mid, end2 = high; while (start1 &lt; end1 &amp;&amp; start2 &lt; end2) b[k++] = a[start1] &lt; a[start2] ? a[start1++] : a[start2++]; while (start1 &lt; end1) b[k++] = a[start1++]; while (start2 &lt; end2) b[k++] = a[start2++]; &#125; int* temp = a; a = b; b = temp; &#125; if (a != arr) &#123; int i; for (i = 0; i &lt; len; i++) b[i] = a[i]; b = a; &#125; free(b);&#125; 递归法12345678910111213141516171819202122void merge_sort_recursive(int arr[], int reg[], int start, int end) &#123; if (start &gt;= end) return; int len = end - start, mid = (len &gt;&gt; 1) + start; int start1 = start, end1 = mid; int start2 = mid + 1, end2 = end; merge_sort_recursive(arr, reg, start1, end1); merge_sort_recursive(arr, reg, start2, end2); int k = start; while (start1 &lt;= end1 &amp;&amp; start2 &lt;= end2) reg[k++] = arr[start1] &lt; arr[start2] ? arr[start1++] : arr[start2++]; while (start1 &lt;= end1) reg[k++] = arr[start1++]; while (start2 &lt;= end2) reg[k++] = arr[start2++]; for (k = start; k &lt;= end; k++) arr[k] = reg[k];&#125;void merge_sort(int arr[], const int len) &#123; int reg[len]; merge_sort_recursive(arr, reg, 0, len - 1);&#125; 快速排序迭代法12345678910111213141516171819202122232425262728293031323334353637383940414243typedef struct _Range &#123; int start, end;&#125; Range;Range new_Range(int s, int e) &#123; Range r; r.start = s; r.end = e; return r;&#125;void swap(int *x, int *y) &#123; int t = *x; *x = *y; *y = t;&#125;void quick_sort(int arr[], const int len) &#123; if (len &lt;= 0) return; // 避免len等于负值引发段错误（Segment Fault） // r[]列表,p数量,r[p++]为push,r[--p]为pop且取得元素 Range r[len]; int p = 0; r[p++] = new_Range(0, len - 1); while (p) &#123; Range range = r[--p]; if (range.start &gt;= range.end) continue; int mid = arr[(range.start + range.end) / 2]; //选择中间点为基准点 int left = range.start, right = range.end; do &#123; while (arr[left] &lt; mid) ++left; // 检测基准点左侧是否符合要求 while (arr[right] &gt; mid) --right; //检测基准点右侧是否符合要求 if (left &lt;= right) &#123; swap(&amp;arr[left],&amp;arr[right]); left++;right--; //移动指针以继续 &#125; &#125; while (left &lt;= right); if (range.start &lt; right) r[p++] = new_Range(range.start, right); if (range.end &gt; left) r[p++] = new_Range(left, range.end); &#125;&#125; 递归法左右指针法123456789101112131415161718192021222324252627282930313233343536373839#include&lt;iostream&gt;using namespace std;void swap(int *x, int *y) &#123; int t = *x; *x = *y; *y = t;&#125;void quick_sort_recursive(int arr[], int left, int right) &#123; if (left &gt;= right) return; int mid = arr[right]; int begin = left, end = right - 1;//左右指针法 while (begin &lt; end) &#123; while (arr[begin] &lt; mid &amp;&amp; begin &lt; end) begin++; while (arr[end] &gt;= mid &amp;&amp; begin &lt; end) end--; swap(&amp;arr[begin], &amp;arr[end]); &#125; if (arr[begin] &gt;= arr[right]) swap(&amp;arr[begin], &amp;arr[right]); else begin++; if (begin) quick_sort_recursive(arr, left, begin - 1); quick_sort_recursive(arr, begin + 1, right);&#125;void quick_sort(int arr[], int len) &#123; quick_sort_recursive(arr, 0, len - 1);&#125;int main()&#123; int a[10] = &#123; 8,7,5,10,3,1,2,4,9,6 &#125;; quick_sort(a, 10); for(int i=0;i&lt;10;i++) cout &lt;&lt; a[i]; return 0;&#125; 挖洞法123456789101112131415161718192021222324void quick_sort(T a[], int start, int end)&#123; if(end-start &lt; 1) return; if(end-start == 1) &#123; if(a[start]&gt;a[end]) swap(a[start], a[end]); return; &#125; int key = a[start], i=start, j=end; while (i&lt;j) &#123; while(i&lt;j &amp;&amp; key &lt; a[j]) j--; a[i] = a[j]; while(i&lt;j &amp;&amp; key &gt; a[i]) i++; a[j] = a[i]; &#125; a[i] = key; quick_sort(a, start, i-1); quick_sort(a, i+1, end);&#125; 例：找出第k大或者第k小的数123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133//目前还有错误，还待解决中。。。//大到小排序1 2 3 4 5 6 7 8 9 10 第五大会出现错误，思路好的时候整理#include&lt;iostream&gt;using namespace std;//从小到大排序int partion1(int A[], int low, int high)&#123; int pivot = A[low];//用第一个数作为主元 while (low &lt; high) &#123; while (low &lt; high &amp;&amp; A[high] &gt;= pivot) --high; A[low] = A[high]; while (low &lt; high&amp;&amp;A[low] &lt;= pivot) ++low; A[high] = A[low]; &#125; A[low] = pivot; return low;&#125;//修改大于小于号后，从大到小排序int partion2(int A[], int low, int high)&#123; int pivot = A[low];//用第一个数作为主元 while (low &lt; high) &#123; while (low &lt; high &amp;&amp; A[high] &lt;= pivot) --high; A[low] = A[high]; while (low &lt; high&amp;&amp;A[low] &gt;= pivot) ++low; A[high] = A[low]; &#125; A[low] = pivot; return low;&#125;//调用从小到大排序的分割法，来找出第K小的数int find_k_small(int A[], int low, int high, int k)&#123; if (low &lt; high) &#123; int pivot_pos = partion1(A, low, high); if (pivot_pos + 1 == k) return A[pivot_pos]; else if (pivot_pos + 1 &gt; k) find_k_small(A, low, pivot_pos - 1, k); else find_k_small(A, pivot_pos + 1, high, k); &#125; else return -1;&#125;//找出第K大的数int find_k_big(int A[], int low, int high, int k)&#123; if (low &lt; high) &#123; int pivot_pos = partion2(A, low, high); if (pivot_pos + 1 == k) return A[pivot_pos]; else if (pivot_pos + 1 &gt; k) return find_k_big(A, low, pivot_pos - 1, k); else return find_k_big(A, pivot_pos + 1, high, k); &#125; else return -1;&#125;void quick_sort1(int A[], int low, int high)&#123; if (low &lt; high) &#123; int pivot_pos = partion1(A, low, high); quick_sort1(A, low, pivot_pos - 1); quick_sort1(A, pivot_pos + 1, high); &#125;&#125;void quick_sort2(int A[], int low, int high)&#123; if (low &lt; high) &#123; int pivot_pos = partion2(A, low, high); quick_sort2(A, low, pivot_pos - 1); quick_sort2(A, pivot_pos + 1, high); &#125;&#125;int main()&#123; int n; cout &lt;&lt; &quot;输入元素个数： &quot;; cin &gt;&gt; n; int *A = new int[n]; for (int i = 0; i &lt; n; ++i) cin &gt;&gt; A[i]; int k; cout &lt;&lt; &quot;输入要找出第几小的数： &quot; &lt;&lt; endl; cin &gt;&gt; k; cout &lt;&lt; &quot;找出第&quot; &lt;&lt; k &lt;&lt; &quot;小的数:&quot; &lt;&lt; endl; int ans = find_k_small(A, 0, n - 1, k); cout &lt;&lt; ans &lt;&lt; endl; cout &lt;&lt; &quot;排序后的结果：&quot; &lt;&lt; endl; quick_sort1(A, 0, n - 1); for (int i = 0; i &lt; n; ++i) cout &lt;&lt; A[i] &lt;&lt; &quot; &quot;; cout &lt;&lt; endl; int k2; cout &lt;&lt; &quot;输入要找出第几大的数： &quot; &lt;&lt; endl; cin &gt;&gt; k2; cout &lt;&lt; &quot;找出第&quot; &lt;&lt; k2 &lt;&lt; &quot;大的数:&quot; &lt;&lt; endl; ans = find_k_big(A, 0, n - 1, k2); cout &lt;&lt; ans &lt;&lt; endl; cout &lt;&lt; &quot;排序后的结果：&quot; &lt;&lt; endl; quick_sort2(A, 0, n - 1); for (int i = 0; i &lt; n; ++i) cout &lt;&lt; A[i] &lt;&lt; &quot; &quot;; cout &lt;&lt; endl; delete[] A; return 0;&#125;]]></content>
      <categories>
        <category>C++</category>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[new和malloc内部实现的区别]]></title>
    <url>%2Fnew%26malloc.html</url>
    <content type="text"><![CDATA[new 和 malloc 内部的实现方式有什么区别？malloc和new有以下不同:(1) new. delete 是操作符，可以重载，只能在C++中使用。 (2) malloc. free 是函数，可以覆盖，C、C++中都可以使用。 (3)new可以调用对象的构造函数，对应的delete调用相应的析构函数。 (4) malloc仅仅分配内存，free 仅仅回收内存，并不执行构造和析构函数 (5) new. delete 返回的是某种数据类型指针，malloc、 free 返回的是void指针。注意: malloc 申请的内存空间要用free释放，而new申请的内存空间要用delete释放，不要混用。因为两者实现的机理不同。 解释：new 的功能是在堆区新建一个对象，并返回该对象的指针。 所谓的【新建对象】的意思就是，将调用该类的构造函数，因为如果不构造的话，就不能称之为一个对象。 而 malloc 只是机械的分配一块内存，如果用 mallco 在堆区创建一个对象的话，是不会调用构造函数的。 严格说来用 malloc 不能算是新建了一个对象，只能说是分配了一块与该类对象匹配的内存而已，然后强行把它解释为【这是一个对象】，按这个逻辑来，也不存在构造函数什么事。 同样的，用 delete 去释放一个堆区的对象，会调用该对象的析构函数。 用 free 去释放一个堆区的对象，不会调用该对象的析构函数。 做个简单的实验即可明了: 123456789101112131415161718192021222324252627282930313233343536373839404142434445#include &lt;iostream&gt;#include &lt;malloc.h&gt;class TEST&#123;private: int num1; int num2;public: TEST() &#123; num1 = 10; num2 = 20; &#125; void Print() &#123; std::cout &lt;&lt; num1 &lt;&lt; " " &lt;&lt; num2 &lt;&lt; std::endl; &#125;&#125;;int main(void)&#123; // 用malloc()函数在堆区分配一块内存空间，然后用强制类型转换将该块内存空间 // 解释为是一个TEST类对象，这不会调用TEST的默认构造函数 TEST * pObj1 = (TEST *)malloc(sizeof(TEST)); pObj1-&gt;Print(); // 用new在堆区创建一个TEST类的对象，这会调用TEST类的默认构造函数 TEST * pObj2 = new TEST; pObj2-&gt;Print(); return 0;&#125;/*运行结果：------------------------------842150451 -842150451 |10 20 |请按任意键继续. . . |-----------------------------我们可以看到pObj1所指的对象中，字段num1与num2都是垃圾值而pObj2所指的对象中，字段num1与num2显然是经过了构造后的值*/]]></content>
  </entry>
  <entry>
    <title><![CDATA[微信防撤回脚本]]></title>
    <url>%2F3.html</url>
    <content type="text"><![CDATA[Windows微信防撤回脚本测试版本：2.6.7.57 ~ 2.6.8.51下载地址：https://pan.baiduwp.com/s/1UBpRXRyd9uXBeqDbc0DKWg 提取码: 6666使用方法：将下载的dll文件，放置在微信的安装目录（WeChat.exe所在目录）下，默认安装目录 （C:\Program Files(x86)\Tencent\WeChat），如果在安装微信时，自定义了微信安装位置，请自 行查找。（如果有问题，右下角蓝色聊天框戳我）测试结果： 组件制作过程使用工具：x32dbg调试器打开微信，并登录；打开x32dbg，文件-附加-选择“微信”，如下图； 符号-搜索关键词：“win”，选择wechatwin.dll模块，然后双击 跳转至“引用”区域 ； 右键搜索-当前模块-字符串，输入搜索关键次“revokemsg”，选择 mov.ecx.wechatwin.xxxxxx 字段结果，双击定位至详情 从定位直至上拉，第一一个je开头行，修改成jmp开头行，点确定]]></content>
      <categories>
        <category>防撤回</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[基于tensorflow的人脸识别系统]]></title>
    <url>%2F4.html</url>
    <content type="text"><![CDATA[环境搭建ubuntu16.04+Anaconda4.2.0+python3.5+opencv2的环境搭建 代码分析检验导包问题的代码12345678910111213141516import tensorflow as tf# 创建一个常量 op, 产生一个 1x2 矩阵. 这个 op 被作为一个节点# 加到默认图中.# 构造器的返回值代表该常量 op 的返回值.##matrix1 = tf.constant([[3., 3.]])# 创建另外一个常量 op, 产生一个 2x1 矩阵.##matrix2 = tf.constant([[2.],[2.]])# 创建一个矩阵乘法 matmul op , 把 'matrix1' 和 'matrix2' 作为输入.# 返回值 'product' 代表矩阵乘法的结果.##product = tf.matmul(matrix1,matrix2)from skimage import io, transformimport globimport osimport time import tensorflow as tfimport numpy as np 将训练集下的图片resize一下，伴随着打开每一个子文件夹，我们要为其设置一个labels，一个文件夹的1000应一个label，共68个abel，这是后面检验acc的唯一指标，即是否能把测试集的照片通过我们的网络输出到指定出口得到正确的label。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189path=''#将所有的图片resize成100*100w=128h=128c=3#读取图片def read_img(path): cate=[path+'/'+x for x in os.listdir(path) if os.path.isdir(path+'/'+x)] imgs=[] labels=[] for idx,folder in enumerate(cate): for im in glob.glob(folder+'/*.png'): print('reading the images:%s'%(im)) img=io.imread(im) img=transform.resize(img,(w,h,c)) imgs.append(img) labels.append(idx) return np.asarray(imgs,np.float32),np.asarray(labels,np.int32) data,label=read_img(path)# 将所有数据分为训练集和验证集ratio = 0.95#训练集占比s = np.int ( num_example * ratio )x_train = data[:s]y_train = label[:s]x_val = data[s:]y_val = label[s:]# -----------------构建网络----------------------# 占位符x = tf.placeholder ( tf.float32, shape=[None, w, h, c], name='x' )y_ = tf.placeholder ( tf.int32, shape=[None, ], name='y_' )def CNNlayer(): # 第一个卷积层（128——&gt;64) conv1 = tf.layers.conv2d ( inputs=x, filters=32, kernel_size=[5, 5], padding="same", activation=tf.nn.relu, kernel_initializer=tf.truncated_normal_initializer ( stddev=0.01 ) ) pool1 = tf.layers.max_pooling2d ( inputs=conv1, pool_size=[2, 2], strides=2 ) # 第二个卷积层(64-&gt;32) conv2 = tf.layers.conv2d ( inputs=pool1, filters=64, kernel_size=[5, 5], padding="same", activation=tf.nn.relu, kernel_initializer=tf.truncated_normal_initializer ( stddev=0.01 ) ) pool2 = tf.layers.max_pooling2d ( inputs=conv2, pool_size=[2, 2], strides=2 ) # 第三个卷积层(32-&gt;16) conv3 = tf.layers.conv2d ( inputs=pool2, filters=128, kernel_size=[3, 3], padding="same", activation=tf.nn.relu, kernel_initializer=tf.truncated_normal_initializer ( stddev=0.01 ) ) pool3 = tf.layers.max_pooling2d ( inputs=conv3, pool_size=[2, 2], strides=2 ) # 第四个卷积层(16-&gt;8) conv4 = tf.layers.conv2d ( inputs=pool3, filters=128, kernel_size=[3, 3], padding="same", activation=tf.nn.relu, kernel_initializer=tf.truncated_normal_initializer ( stddev=0.01 ) ) pool4 = tf.layers.max_pooling2d ( inputs=conv4, pool_size=[2, 2], strides=2 ) re1 = tf.reshape ( pool4, [-1, 8 * 8 * 128] ) # 全连接层 dense1 = tf.layers.dense ( inputs=re1, units=1024, activation=tf.nn.relu, kernel_initializer=tf.truncated_normal_initializer ( stddev=0.01 ), kernel_regularizer=tf.contrib.layers.l2_regularizer ( 0.003 ) ) dense2 = tf.layers.dense ( inputs=dense1, units=512, activation=tf.nn.relu, kernel_initializer=tf.truncated_normal_initializer ( stddev=0.01 ), kernel_regularizer=tf.contrib.layers.l2_regularizer ( 0.003 ) ) logits = tf.layers.dense ( inputs=dense2, units=68, activation=None, kernel_initializer=tf.truncated_normal_initializer ( stddev=0.01 ), kernel_regularizer=tf.contrib.layers.l2_regularizer ( 0.003 ) ) return logits# ----------网络结束---------------------------# 定义一个函数，按批次取数据def minibatches(inputs=None, targets=None, batch_size=None, shuffle=False): assert len ( inputs ) == len ( targets ) if shuffle: indices = np.arange ( len ( inputs ) ) np.random.shuffle ( indices ) for start_idx in range ( 0, len ( inputs ) - batch_size + 1, batch_size ): if shuffle: excerpt = indices[start_idx:start_idx + batch_size] else: excerpt = slice ( start_idx, start_idx + batch_size ) yield inputs[excerpt], targets[excerpt]# 训练和测试数据，可将n_epoch设置更大一些saver = tf.train.Saver ( max_to_keep=3 )max_acc = 0f = open ( 'ckpt1/acc.txt', 'w' )n_epoch = 10batch_size = 64sess = tf.InteractiveSession ( )sess.run ( tf.global_variables_initializer ( ) )for epoch in range ( n_epoch ): start_time = time.time ( ) # training train_loss, train_acc, n_batch = 0, 0, 0 for x_train_a, y_train_a in minibatches ( x_train, y_train, batch_size, shuffle=True ): _, err, ac = sess.run ( [train_op, loss, acc], feed_dict=&#123;x: x_train_a, y_: y_train_a&#125; ) train_loss += err; train_acc += ac; n_batch += 1 print ( " train loss: %f" % (train_loss / n_batch) ) print ( " train acc: %f" % (train_acc / n_batch) ) # validation val_loss, val_acc, n_batch = 0, 0, 0 for x_val_a, y_val_a in minibatches ( x_val, y_val, batch_size, shuffle=False ): err, ac = sess.run ( [loss, acc], feed_dict=&#123;x: x_val_a, y_: y_val_a&#125; ) val_loss += err; val_acc += ac; n_batch += 1 print ( " validation loss: %f" % (val_loss / n_batch) ) print ( " validation acc: %f" % (val_acc / n_batch) ) f.write ( str ( epoch + 1 ) + ', val_acc: ' + str ( val_acc ) + '\n' ) if val_acc &gt; max_acc: max_acc = val_acc saver.save ( sess, 'ckpt1/faces.ckpt', global_step=epoch + 1 )f.close ( )detector = dlib.get_frontal_face_detector ( ) # 获取人脸分类器ID = (1511346,1610731,1610763,1610260,1611407,1611408, 1611409,1611412,1611413,1611415,1611417,1611418, 1611419,1611420,1611421,1611424,1611425,1611426, 1611427,1611430,1611431,1611433,1611434,1611436, 1611437,1611438,1611440,1611444,1611446,1611447, 1611449,1611450,1611451,1511453,1611455,1611458, 1611459,1611460,1611461,1611462,1611470,1611471, 1611472,1611472,1611476,1611478,1611480,1611482, 1611483,1611486,1611487,1611488,1611490,1611491, 1611492,1611493,1611494,1613371,1613376,1613378, 1613550,1711459 )#两个操作是拿到dlib的人脸分类器（相当于dlib的训练代码跑完的结果存下的参数变量结构等东西），然后建个数组当输出和ID的映射#最终交互检验：user = input ( "图片（G）还是摄像头（V）:" )if user == "G": path = input ( "图片路径名是：" ) img = cv2.imread ( path ) dets = detector ( img, 1 ) print ( "Number of faces detected: &#123;&#125;".format ( len ( dets ) ) ) for index, face in enumerate ( dets ): print ( 'face &#123;&#125;; left &#123;&#125;; top &#123;&#125;; right &#123;&#125;; bottom &#123;&#125;'.format ( index, face.left ( ), face.top ( ), face.right ( ), face.bottom ( ) ) ) left = face.left ( ) top = face.top ( ) right = face.right ( ) bottom = face.bottom ( ) cv2.rectangle ( img, (left, top), (right, bottom), (0, 255, 0), 3 ) io.imsave ( 'temp.png', img ) img1 = io.imread ( 'temp.png' ) img1 = transform.resize ( img1, (w, h, c) ) cv2.imshow ( 'image', img1 ) img1 = img[top:bottom, left:right] img1 = transform.resize ( img1, (w, h, c) ) # cv2.imshow('image1',img) res = sess.run ( predict, feed_dict=&#123;x: [img1]&#125; ) print ( ID[res[0]] ) if len ( dets ) == 0: img = transform.resize ( img, (w, h, c) ) res = sess.run ( predict, feed_dict=&#123;x: [img]&#125; ) print ( ID[res[0]] ) cv2.waitKey ( 0 ) cv2.destroyAllWindows ( ) cv2.waitKey ( 0 ) cv2.destroyAllWindows ( )else: # 打开摄像头 cap = cv2.VideoCapture ( 0 ) # 视屏封装格式 while True: ret, frame = cap.read ( ) gray = cv2.cvtColor ( frame, cv2.COLOR_BGR2GRAY ) cv2.imshow ( 'frame', frame ) # 抓取图像，s画人脸框，q结束识别 if cv2.waitKey ( 1 ) &amp; 0xFF == ord ( 's' ): cv2.imwrite ( 'now.png', frame ) img = cv2.imread ( "now.png" ) dets = detector ( img, 1 ) print ( "Number of faces detected: &#123;&#125;".format ( len ( dets ) ) ) for index, face in enumerate ( dets ): print ( 'face &#123;&#125;; left &#123;&#125;; top &#123;&#125;; right &#123;&#125;; bottom &#123;&#125;'.format ( index, face.left ( ), face.top ( ), face.right ( ), face.bottom ( ) ) ) left = face.left ( ) top = face.top ( ) right = face.right ( ) bottom = face.bottom ( ) img = img[top:bottom, left:right] # img=io.imread('image/now.png') img = transform.resize ( img, (w, h, c) ) res = sess.run ( predict, feed_dict=&#123;x: [img]&#125; ) print ( ID[res[0]] ) # 退出 实验结果分析最终的训练的结果： 根据我自己的数据化的数据图： 识别过程：（拿我自己的照片做的测试）：]]></content>
      <categories>
        <category>Python</category>
        <category>人脸识别</category>
      </categories>
      <tags>
        <tag>人脸识别</tag>
      </tags>
  </entry>
</search>
